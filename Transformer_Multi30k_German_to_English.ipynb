{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Transformer_Multi30k_German_to_English.ipynb",
   "provenance": [
    {
     "file_id": "1bU3hHSQGY-MfTgfZaQWQzivJD__STGOR",
     "timestamp": 1650031322821
    },
    {
     "file_id": "1YhqP5st0yiBt4FJofOwY7g6GrzGZWQNW",
     "timestamp": 1649105742866
    },
    {
     "file_id": "1P7oU2EWQ1Qk17N9NutZv9FV1a_hMGUoR",
     "timestamp": 1647373127550
    }
   ],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, I train a transformer model for translating German to English. The model structure is the same as that of the original [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) paper."
   ],
   "metadata": {
    "id": "D23TRFotJ6bh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install sentencepiece --quiet\n",
    "!pip install sacrebleu --quiet"
   ],
   "metadata": {
    "id": "jtTpObu_cdP2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import sacrebleu\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchtext.datasets import Multi30k\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ],
   "metadata": {
    "id": "ToFDXgFP5fys",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650210134737,
     "user_tz": 240,
     "elapsed": 7,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "014af9bc-a2ec-4c2f-de9e-38773e5a4609"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "SRC = \"de\"\n",
    "TRG = \"en\""
   ],
   "metadata": {
    "id": "tlCncOUK4lUo"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get German and English tokenizers from SentencePiece"
   ],
   "metadata": {
    "id": "Jq10RHNKZTDo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_iter = Multi30k(split='train', language_pair=(SRC, TRG))\n",
    "f_de = open(\"Multi30k_de_text.txt\", \"w\")\n",
    "f_en = open(\"Multi30k_en_text.txt\", \"w\")\n",
    "for pair in train_iter:\n",
    "    f_de.write(pair[0])\n",
    "    f_en.write(pair[1])\n",
    "f_de.close()\n",
    "f_en.close()"
   ],
   "metadata": {
    "id": "hz9u_PmSdLdc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "en_vocab_size = 8200\n",
    "de_vocab_size = 10000\n",
    "vocab_sizes = {\"en\": en_vocab_size, \"de\": de_vocab_size}"
   ],
   "metadata": {
    "id": "N1eDUeBkFnea"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train sentencepiece models to get tokenizers\n",
    "spm.SentencePieceTrainer.train\\\n",
    "(f'--input=Multi30k_de_text.txt --model_prefix=Multi30k_de --user_defined_symbols=<pad> --vocab_size={de_vocab_size}')\n",
    "spm.SentencePieceTrainer.train\\\n",
    "(f'--input=Multi30k_en_text.txt --model_prefix=Multi30k_en --user_defined_symbols=<pad> --vocab_size={en_vocab_size}')\n",
    "\n",
    "# make SentencePieceProcessor instances and load the model files\n",
    "de_sp = spm.SentencePieceProcessor()\n",
    "de_sp.load('Multi30k_de.model')\n",
    "en_sp = spm.SentencePieceProcessor()\n",
    "en_sp.load('Multi30k_en.model')\n",
    "\n",
    "tokenizers = {\"en\": en_sp.encode_as_ids, \"de\": de_sp.encode_as_ids}\n",
    "detokenizers = {\"en\":en_sp.decode_ids, \"de\":de_sp.decode_ids}\n",
    "\n",
    "# encode: text => id\n",
    "print(en_sp.encode_as_pieces('This is a test'))\n",
    "print(en_sp.encode_as_ids('This is a test'))\n",
    "\n",
    "# decode: id => text\n",
    "print(en_sp.decode_pieces(['▁This', '▁is', '▁a', '▁t', 'est']))\n",
    "print(en_sp.decode_ids([302, 258, 10, 4, 2395]))"
   ],
   "metadata": {
    "id": "asaHCE3IZhrl",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650210137091,
     "user_tz": 240,
     "elapsed": 1030,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "5b51471d-df17-4541-c923-160134655373"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['▁Th', 'is', '▁is', '▁a', '▁test']\n",
      "[302, 258, 10, 4, 2395]\n",
      "▁This is a test\n",
      "This is a test\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['<unk>', '<s>', '</s>', '<pad>', '▁a', '.', '▁A', '▁in', '▁the', '▁on', '▁is', '▁man', '▁and', '▁of', '▁with', 's', 'ing', '▁', ',', '▁woman']\n",
      "['<unk>', '<s>', '</s>', '<pad>', '.', '▁eine', '▁Ein', 'm', '▁in', '▁mit', ',', '▁und', '▁auf', '▁ein', '▁Mann', '▁einer', '▁Eine', 'n', '▁der', '▁Frau']\n"
     ]
    }
   ],
   "source": [
    "print([en_sp.id_to_piece(id) for id in range(20)])\n",
    "print([de_sp.id_to_piece(id) for id in range(20)])"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "zv9Q9YyAUqoh",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650210137091,
     "user_tz": 240,
     "elapsed": 6,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "0086f39e-88ec-4840-dca1-77fec098b2a6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# indexes of special symbols\n",
    "UNK, BOS, EOS, PAD = 0, 1, 2, 3"
   ],
   "metadata": {
    "id": "8grAiF0GfmYx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data processing"
   ],
   "metadata": {
    "collapsed": false,
    "id": "OuOHh7fF5Tn8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_iter = Multi30k(split='train', language_pair=(SRC, TRG))\n",
    "valid_iter = Multi30k(split='valid', language_pair=(SRC, TRG))\n",
    "test_iter  = Multi30k(split='test',  language_pair=(SRC, TRG))\n",
    "\n",
    "train_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in train_iter]\n",
    "valid_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in valid_iter]\n",
    "test_set  = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in test_iter]\n",
    "print(len(train_set), len(valid_set), len(test_set))\n",
    "for i in range(10):\n",
    "   print(train_set[i])"
   ],
   "metadata": {
    "id": "jh3Nxm7VaHIQ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650210137091,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "922a8619-f142-42e4-a08d-322e9ee85350"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "29000 1014 1000\n",
      "('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Two young, White males are outside near many bushes.')\n",
      "('Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.', 'Several men in hard hats are operating a giant pulley system.')\n",
      "('Ein kleines Mädchen klettert in ein Spielhaus aus Holz.', 'A little girl climbing into a wooden playhouse.')\n",
      "('Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.', 'A man in a blue shirt is standing on a ladder cleaning a window.')\n",
      "('Zwei Männer stehen am Herd und bereiten Essen zu.', 'Two men are at the stove preparing food.')\n",
      "('Ein Mann in grün hält eine Gitarre, während der andere Mann sein Hemd ansieht.', 'A man in green holds a guitar while the other man observes his shirt.')\n",
      "('Ein Mann lächelt einen ausgestopften Löwen an.', 'A man is smiling at a stuffed lion')\n",
      "('Ein schickes Mädchen spricht mit dem Handy während sie langsam die Straße entlangschwebt.', 'A trendy girl talking on her cellphone while gliding slowly down the street.')\n",
      "('Eine Frau mit einer großen Geldbörse geht an einem Tor vorbei.', 'A woman with a large purse is walking by a gate.')\n",
      "('Jungen tanzen mitten in der Nacht auf Pfosten.', 'Boys dancing on poles in the middle of the night.')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_seq_len = 50\n",
    "def tokenize_dataset(dataset):\n",
    "    'tokenize a dataset and add [BOS] and [EOS] to the beginning and end of the sentences'\n",
    "    return [(torch.tensor([BOS]+tokenizers[SRC](src_text)[0:max_seq_len-2]+[EOS]),\n",
    "             torch.tensor([BOS]+tokenizers[TRG](trg_text)[0:max_seq_len-2]+[EOS]))\n",
    "            for src_text, trg_text in dataset]\n",
    "          \n",
    "train_tokenized = tokenize_dataset(train_set)\n",
    "valid_tokenized = tokenize_dataset(valid_set)\n",
    "test_tokenized  = tokenize_dataset(test_set)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "gF5sy0p65ToA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    'create a dataset for torch.utils.data.DataLoader() '\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "\n",
    "def pad_sequence(batch):\n",
    "    'collate function for padding sentences such that all \\\n",
    "    the sentences in the batch have the same length'\n",
    "    src_seqs  = [src for src, trg in batch]\n",
    "    trg_seqs  = [trg for src, trg in batch]\n",
    "    src_padded = torch.nn.utils.rnn.pad_sequence(src_seqs,\n",
    "                                batch_first=True, padding_value = PAD)\n",
    "    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_seqs,\n",
    "                                batch_first=True, padding_value = PAD)\n",
    "    return src_padded, trg_padded\n"
   ],
   "metadata": {
    "id": "8RSKKEGTHICe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 128\n",
    "\n",
    "class Dataloaders:\n",
    "    'Dataloaders contains train_loader, test_loader and valid_loader for training and evaluation '\n",
    "    def __init__(self):\n",
    "        self.train_dataset = TranslationDataset(train_tokenized)\n",
    "        self.valid_dataset = TranslationDataset(valid_tokenized)\n",
    "        self.test_dataset  = TranslationDataset(test_tokenized)\n",
    "        \n",
    "        # each batch returned by dataloader will be padded such that all the texts in\n",
    "        # that batch have the same length as the longest text in that batch\n",
    "        self.train_loader = torch.utils.data.DataLoader(self.train_dataset, batch_size=batch_size,\n",
    "                                                shuffle=True, collate_fn = pad_sequence)\n",
    "        \n",
    "        self.test_loader = torch.utils.data.DataLoader(self.test_dataset, batch_size=batch_size,\n",
    "                                                shuffle=True, collate_fn=pad_sequence)\n",
    "        \n",
    "        self.valid_loader = torch.utils.data.DataLoader(self.valid_dataset, batch_size=batch_size,\n",
    "                                                shuffle=True, collate_fn=pad_sequence)\n"
   ],
   "metadata": {
    "id": "WgeG2xQwFmIZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer Model"
   ],
   "metadata": {
    "id": "6t5Bkt_LOu0p"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_embed, dropout=0.0):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_embed % h == 0 # check the h number\n",
    "        self.d_k = d_embed//h\n",
    "        self.d_embed = d_embed\n",
    "        self.h = h\n",
    "        self.WQ = nn.Linear(d_embed, d_embed)\n",
    "        self.WK = nn.Linear(d_embed, d_embed)\n",
    "        self.WV = nn.Linear(d_embed, d_embed)\n",
    "        self.linear = nn.Linear(d_embed, d_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_query, x_key, x_value, mask=None):\n",
    "        nbatch = x_query.size(0) # get batch size\n",
    "        # 1) Linear projections to get the multi-head query, key and value tensors\n",
    "        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n",
    "        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n",
    "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        # 2) Attention\n",
    "        # scores has dimensions: nbatch * h * seq_len * seq_len\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_embed)\n",
    "        # 3) Mask out padding tokens and future tokens\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        # p_atten dimensions: nbatch * h * seq_len * seq_len\n",
    "        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        p_atten = self.dropout(p_atten)\n",
    "        # x dimensions: nbatch * h * seq_len * d_k\n",
    "        x = torch.matmul(p_atten, value)\n",
    "        # x now has dimensions:nbtach * seq_len * d_embed\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
    "        return self.linear(x) # final linear layer\n",
    "\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n",
    "  def __init__(self, dim, dropout):\n",
    "      super().__init__()\n",
    "      self.drop = nn.Dropout(dropout)\n",
    "      self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "  def forward(self, x, sublayer):\n",
    "      return x + self.drop(sublayer(self.norm(x)))\n",
    "\n",
    "# I simply let the model learn the positional embeddings in this notebook, since this \n",
    "# almost produces identital results as using sin/cosin functions embeddings, as claimed\n",
    "# in the original transformer paper. Note also that in the original paper, they multiplied \n",
    "# the token embeddings by a factor of sqrt(d_embed), which I do not do here. \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) \n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n",
    "        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "\n",
    "    def forward(self, input, mask=None):\n",
    "        x = self.tok_embed(input)\n",
    "        x_pos = self.pos_embed[:, :x.size(1), :]\n",
    "        x = self.dropout(x + x_pos)\n",
    "        for layer in self.encoder_blocks:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n",
    "    def __init__(self, config):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.atten = MultiHeadedAttention(config.h, config.d_embed, config.dropout)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n",
    "        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # self-attention\n",
    "        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n",
    "        # position-wise fully connected feed-forward layer\n",
    "        return self.residual2(x, self.feed_forward)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n",
    "    \n",
    "    def future_mask(self, seq_len):\n",
    "        '''mask out tokens at future positions'''\n",
    "        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n",
    "        return mask.view(1, 1, seq_len, seq_len)\n",
    "\n",
    "    def forward(self, memory, src_mask, trg, trg_pad_mask):\n",
    "        seq_len = trg.size(1)\n",
    "        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n",
    "        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.decoder_blocks:\n",
    "            x = layer(memory, src_mask, x, trg_mask)\n",
    "        x = self.norm(x)\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    ''' EncoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.atten1 = MultiHeadedAttention(config.h, config.d_embed)\n",
    "        self.atten2 = MultiHeadedAttention(config.h, config.d_embed)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout) \n",
    "                                       for i in range(3)])\n",
    "\n",
    "    def forward(self, memory, src_mask, decoder_layer_input, trg_mask):\n",
    "        x = memory\n",
    "        y = decoder_layer_input\n",
    "        y = self.residuals[0](y, lambda y: self.atten1(y, y, y, mask=trg_mask))\n",
    "        # keys and values are from the encoder output\n",
    "        y = self.residuals[1](y, lambda y: self.atten2(y, x, x, mask=src_mask))\n",
    "        return self.residuals[2](y, self.feed_forward)\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, src_mask, trg, trg_pad_mask):\n",
    "        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "AWvU3VeM5ToD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    encoder_vocab_size: int\n",
    "    decoder_vocab_size: int\n",
    "    d_embed: int \n",
    "    # d_ff is the dimension of the fully-connected  feed-forward layer\n",
    "    d_ff: int\n",
    "    # h is the number of attention head\n",
    "    h: int\n",
    "    N_encoder: int\n",
    "    N_decoder: int\n",
    "    max_seq_len: int\n",
    "    dropout: float\n",
    "\n",
    "def make_model(config):\n",
    "    model = Transformer(Encoder(config), Decoder(config)).to(DEVICE)\n",
    "\n",
    "    # initialize model parameters\n",
    "    # it seems that this initialization is very important!\n",
    "    for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    return model"
   ],
   "metadata": {
    "id": "gxYYnrC-FAgI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get German and English tokenizers\n",
    "\n",
    "I use [SentencePiece](https://github.com/google/sentencepiece) to get both the German and English tokenizers. "
   ],
   "metadata": {
    "id": "V7Xdzd9x8z-C"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_batch_input(x, y):\n",
    "        src = x.to(DEVICE)\n",
    "        trg_in = y[:, :-1].to(DEVICE)\n",
    "        trg_out = y[:, 1:].contiguous().view(-1).to(DEVICE)\n",
    "        src_pad_mask = (src == PAD).view(src.size(0), 1, 1, src.size(-1))\n",
    "        trg_pad_mask = (trg_in == PAD).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n",
    "        return src, trg_in, trg_out, src_pad_mask, trg_pad_mask"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "dUsGrq6fOKbC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloaders):\n",
    "    model.train()\n",
    "    grad_norm_clip = 1.0\n",
    "    losses, acc, count = [], 0, 0\n",
    "    num_batches = len(dataloaders.train_loader)\n",
    "    pbar = tqdm(enumerate(dataloaders.train_loader), total=num_batches)\n",
    "    for idx, (x, y)  in  pbar:\n",
    "        optimizer.zero_grad()\n",
    "        src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
    "        pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
    "        pred = pred.view(-1, pred.size(-1))\n",
    "        loss = loss_fn(pred, trg_out).to(DEVICE)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "        # report progress\n",
    "        if idx>0 and idx%50 == 0:\n",
    "            pbar.set_description(f'train loss={loss.item():.3f}, lr={scheduler.get_last_lr()[0]:.5f}')\n",
    "    return np.mean(losses)\n",
    "\n",
    "\n",
    "def train(model, dataloaders, epochs):\n",
    "    global early_stop_count\n",
    "    best_valid_loss = float('inf')\n",
    "    train_size = len(dataloaders.train_loader)*batch_size\n",
    "    for ep in range(epochs):\n",
    "        train_loss = train_epoch(model, dataloaders)\n",
    "        valid_loss = validate(model, dataloaders.valid_loader)\n",
    "        \n",
    "        print(f'ep: {ep}: train_loss={train_loss:.5f}, valid_loss={valid_loss:.5f}')\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "        else:\n",
    "            if scheduler.last_epoch>2*warmup_steps:\n",
    "                early_stop_count -= 1\n",
    "                if early_stop_count<=0:   \n",
    "                    return train_loss, valid_loss\n",
    "    return train_loss, valid_loss\n",
    "      \n",
    "               \n",
    "def validate(model, dataloder):\n",
    "    'compute the validation loss'\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y) in enumerate(dataloder):\n",
    "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
    "            pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n",
    "            pred = pred.view(-1, pred.size(-1))\n",
    "            losses += (loss_fn(pred, trg_out).item())\n",
    "    return losses/len(dataloder)"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "T51zR33b5ToF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def translate(model, x):\n",
    "    'translate source sentences into the target language, without looking at the answer'\n",
    "    with torch.no_grad():\n",
    "        dB = x.size(0)\n",
    "        y = torch.tensor([[BOS]*dB]).view(dB, 1).to(DEVICE)\n",
    "        x_pad_mask = (x == PAD).view(x.size(0), 1, 1, x.size(-1)).to(DEVICE)\n",
    "        memory = model.encoder(x, x_pad_mask)\n",
    "        for i in range(max_seq_len):\n",
    "            y_pad_mask = (y == PAD).view(y.size(0), 1, 1, y.size(-1)).to(DEVICE)\n",
    "            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n",
    "            last_output = logits.argmax(-1)[:, -1]\n",
    "            last_output = last_output.view(dB, 1)\n",
    "            y = torch.cat((y, last_output), 1).to(DEVICE)\n",
    "    return y"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "BSUApZ2-5ToH"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_pad(sent):\n",
    "    '''truncate the sentence if BOS is in it,\n",
    "     otherwise simply remove the padding tokens at the end'''\n",
    "    if sent.count(EOS)>0:\n",
    "      sent = sent[0:sent.index(EOS)+1]\n",
    "    while sent and sent[-1] == PAD:\n",
    "            sent = sent[:-1]\n",
    "    return sent\n",
    "\n",
    "def decode_sentence(detokenizer, sentence_ids):\n",
    "    'convert a tokenized sentence (a list of numbers) to a literal string'\n",
    "    if not isinstance(sentence_ids, list):\n",
    "        sentence_ids = sentence_ids.tolist()\n",
    "    sentence_ids = remove_pad(sentence_ids)\n",
    "    return detokenizer(sentence_ids).replace(\"<bos>\", \"\")\\\n",
    "           .replace(\"<eos>\", \"\").strip().replace(\" .\", \".\")\n",
    "\n",
    "def evaluate(model, dataloader, num_batch=None):\n",
    "    'evaluate the model, and compute the BLEU score'\n",
    "    model.eval()\n",
    "    refs, cans, bleus = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for idx, (x, y) in enumerate(dataloader):\n",
    "            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n",
    "            translation = translate(model, src)\n",
    "            trg_out = trg_out.view(x.size(0), -1)\n",
    "            refs = refs + [decode_sentence(detokenizers[TRG], trg_out[i]) for i in range(len(src))]\n",
    "            cans = cans + [decode_sentence(detokenizers[TRG], translation[i]) for i in range(len(src))] \n",
    "            if num_batch and idx>=num_batch:\n",
    "                break\n",
    "        bleus.append(sacrebleu.corpus_bleu(cans, [refs]).score)\n",
    "        # print some examples\n",
    "        for i in range(3):\n",
    "            print(f'src:  {decode_sentence(detokenizers[SRC], src[i])}')\n",
    "            print(f'trg:  {decode_sentence(detokenizers[TRG], trg_out[i])}')\n",
    "            print(f'pred: {decode_sentence(detokenizers[TRG], translation[i])}')\n",
    "        return np.mean(bleus)"
   ],
   "metadata": {
    "id": "zQtU_WoLPMwM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "id": "FtpVeM7Xzanz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "config = ModelConfig(encoder_vocab_size = vocab_sizes[SRC], \n",
    "                     decoder_vocab_size=vocab_sizes[TRG],\n",
    "                     d_embed=512, \n",
    "                     d_ff=512, \n",
    "                     h=8,\n",
    "                     N_encoder=3, \n",
    "                     N_decoder=3, \n",
    "                     max_seq_len=max_seq_len,\n",
    "                     dropout=0.1\n",
    "                     )\n",
    "\n",
    "data_loaders = Dataloaders()\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_model(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 3*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "early_stop_count = 2\n",
    "train_loss, valid_loss = train(model, data_loaders, epochs=10)\n",
    "test_loss  = validate(model, data_loaders.test_loader)\n",
    "\n",
    "print(\"train set examples:\")\n",
    "train_bleu = evaluate(model, data_loaders.train_loader, 20)\n",
    "print(\"validation set examples:\")\n",
    "valid_bleu = evaluate(model, data_loaders.valid_loader)\n",
    "print(\"test set examples:\")\n",
    "test_bleu  = evaluate(model, data_loaders.test_loader)\n",
    "print(f'train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}, test_loss: {test_loss:.4f}')\n",
    "print(f'test_bleu: {test_bleu:.4f}, valid_bleu: {valid_bleu:.4f} train_bleu: {train_bleu:.4f}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-HOapnPDtdZ",
    "outputId": "1065bc28-278a-4426-e9c6-b6481033d747",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650210446616,
     "user_tz": 240,
     "elapsed": 307091,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model_size: 26201096, train_set_size: 29056\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 0, train loss=3.910, lr=0.00025: 100%|██████████| 227/227 [00:30<00:00,  7.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 0: train_loss, 5.56953, valid_loss: 3.73589\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 1, train loss=2.842, lr=0.00053: 100%|██████████| 227/227 [00:29<00:00,  7.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 1: train_loss, 3.17847, valid_loss: 2.68794\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 2, train loss=2.180, lr=0.00082: 100%|██████████| 227/227 [00:30<00:00,  7.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 2: train_loss, 2.30726, valid_loss: 2.18694\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 3, train loss=1.657, lr=0.00074: 100%|██████████| 227/227 [00:30<00:00,  7.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 3: train_loss, 1.77496, valid_loss: 1.92097\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 4, train loss=1.503, lr=0.00066: 100%|██████████| 227/227 [00:30<00:00,  7.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 4: train_loss, 1.37660, valid_loss: 1.82722\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 5, train loss=1.081, lr=0.00060: 100%|██████████| 227/227 [00:30<00:00,  7.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 5: train_loss, 1.10612, valid_loss: 1.79904\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 6, train loss=0.922, lr=0.00056: 100%|██████████| 227/227 [00:29<00:00,  7.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 6: train_loss, 0.90342, valid_loss: 1.84004\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 7, train loss=0.760, lr=0.00052: 100%|██████████| 227/227 [00:29<00:00,  7.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep: 7: train_loss, 0.74820, valid_loss: 1.90109\n",
      "train set examples:\n",
      "src:  Eine Frau hält ein Kind und liest.\n",
      "trg:  A woman is hold a child while he reads.\n",
      "pred: A woman is holding a child while reading.\n",
      "src:  Ein Mann geht neben einem Pferd, das einen Karren durch den Wald zieht.\n",
      "trg:  Man walking next to a horse pulling a cart in forest.\n",
      "pred: A man is walking in a horse pulling a cart next to a forest.\n",
      "src:  Personen sitzen in Gruppen auf den Stufen und blicken auf Gärten und Springbrunnen.\n",
      "trg:  Groups of people sit on the steps overlooking gardens and fountains.\n",
      "pred: People sitting on the steps looking at the camera and fountains fountains.\n",
      "validation set examples:\n",
      "src:  Bauarbeiter stehen auf einer Maschine\n",
      "trg:  Construction workers standing on top of a piece of machinery.\n",
      "pred: Construction workers standing on a machine.\n",
      "src:  Kind spielt auf einem Spielplatz und hängt dabei an Stangen.\n",
      "trg:  Child playing on a playground, hanging from bars.\n",
      "pred: Child playing on a playground set with poles.\n",
      "src:  Ein einzelner Feuerwehrmann hilft bei der Bekämpfung eines großen Brandes.\n",
      "trg:  A lone firefighter helps tame a large fire.\n",
      "pred: A lone fireman helps it from the bottom of a large fire.\n",
      "test set examples:\n",
      "src:  Ein Kind planscht im Wasser.\n",
      "trg:  A child is splashing in the water\n",
      "pred: A child splashing in the water.\n",
      "src:  Eine Frau in einem roten Bikini springt beim Volleyball am Strand hoch, um einen Ball zu treffen.\n",
      "trg:  A woman in a red bikini jumping to hit a ball while playing volleyball at a beach.\n",
      "pred: A woman in a red bikini is jumping up at the beach during a game.\n",
      "src:  In einem Caf ⁇  wird von einer Spiegelreflexion ein Foto gemacht.\n",
      "trg:  A photo is taken of a mirror reflection of a cafe.\n",
      "pred: A woman is taking a picture of a mirror in a mirror.\n",
      "train_loss: 0.7482, valid_loss: 1.9011, test_loss: 1.9494\n",
      "test_bleu: 34.9039, valid_bleu: 35.0612 train_bleu: 58.1530\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "So with a transformer model of 26 million parameters, trained on a training set of 29k sentence pairs, we got a test BLEU score of 34.9. The BLEU score seems pretty high, which I think it is because the sentences in this dataset are pretty short and simple. "
   ],
   "metadata": {
    "id": "SE7RdQ57HN9J"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def translate_this_sentence(text: str):\n",
    "    'translate the source sentence in string formate into target language'\n",
    "    input = torch.tensor([[BOS] + tokenizers[SRC](text) + [EOS]]).to(DEVICE)\n",
    "    output = translate(model, input)\n",
    "    return decode_sentence(detokenizers[TRG], output[0])\n",
    "\n",
    "translate_this_sentence(\"Eine Gruppe von Menschen steht vor einem Iglu.\")"
   ],
   "metadata": {
    "id": "6DHwo3xcYmXy",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650210610270,
     "user_tz": 240,
     "elapsed": 893,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "cea886cc-61c1-4dfa-eec7-bfe30f96b8d6"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'A group of people stand in front of an exhibit.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 99
    }
   ]
  }
 ]
}