{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer_Multi30k_German_to_English.ipynb","provenance":[{"file_id":"1bU3hHSQGY-MfTgfZaQWQzivJD__STGOR","timestamp":1650031322821},{"file_id":"1YhqP5st0yiBt4FJofOwY7g6GrzGZWQNW","timestamp":1649105742866},{"file_id":"1P7oU2EWQ1Qk17N9NutZv9FV1a_hMGUoR","timestamp":1647373127550}],"collapsed_sections":["Jq10RHNKZTDo","OuOHh7fF5Tn8","6t5Bkt_LOu0p"],"machine_shape":"hm"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["In this notebook, I train a transformer model for translating German to English. The model structure is the same as the original [Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf) paper. "],"metadata":{"id":"D23TRFotJ6bh"}},{"cell_type":"code","source":["!pip install sentencepiece\n","!pip install sacrebleu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jtTpObu_cdP2","executionInfo":{"status":"ok","timestamp":1650145603174,"user_tz":240,"elapsed":3451,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"298800bf-185f-4d1e-95d6-4df6717f150b"},"execution_count":84,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"]}]},{"cell_type":"code","source":["from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torchtext.datasets import Multi30k\n","from typing import Iterable, List\n","import torchtext\n","from collections import Counter\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from tqdm import  tqdm\n","import math\n","import sentencepiece as spm\n","import sacrebleu\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)"],"metadata":{"id":"ToFDXgFP5fys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650145603174,"user_tz":240,"elapsed":5,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"46c4c991-2500-4eea-c2fe-387155e3db82"},"execution_count":85,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["# Get German and English tokenizers from SentencePiece"],"metadata":{"id":"Jq10RHNKZTDo"}},{"cell_type":"code","source":["train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","f_de = open(\"Multi30k_de_text.txt\", \"w\")\n","f_en = open(\"Multi30k_en_text.txt\", \"w\")\n","for pair in train_iter:\n","    f_de.write(pair[0])\n","    f_en.write(pair[1])\n","f_de.close()\n","f_en.close()"],"metadata":{"id":"hz9u_PmSdLdc","executionInfo":{"status":"ok","timestamp":1650145603175,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":86,"outputs":[]},{"cell_type":"code","source":["en_vocab_size = 8200\n","de_vocab_size = 10000\n","vocab_sizes = {\"en\": en_vocab_size, \"de\": de_vocab_size}"],"metadata":{"id":"N1eDUeBkFnea","executionInfo":{"status":"ok","timestamp":1650145603175,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["# train sentencepiece models to get tokenizers\n","spm.SentencePieceTrainer.train\\\n","(f'--input=Multi30k_de_text.txt --model_prefix=Multi30k_de --user_defined_symbols=<pad> --vocab_size={de_vocab_size}')\n","spm.SentencePieceTrainer.train\\\n","(f'--input=Multi30k_en_text.txt --model_prefix=Multi30k_en --user_defined_symbols=<pad> --vocab_size={en_vocab_size}')\n","\n","# makes segmenter instance and loads the model file\n","de_sp = spm.SentencePieceProcessor()\n","de_sp.load('Multi30k_de.model')\n","en_sp = spm.SentencePieceProcessor()\n","en_sp.load('Multi30k_en.model')\n","\n","# encode: text => id\n","print(en_sp.encode_as_pieces('This is a test'))\n","print(en_sp.encode_as_ids('This is a test'))\n","\n","# decode: id => text\n","print(en_sp.decode_pieces(['▁This', '▁is', '▁a', '▁t', 'est']))\n","print(en_sp.decode_ids([302, 258, 10, 4, 2395]))"],"metadata":{"id":"asaHCE3IZhrl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650145606304,"user_tz":240,"elapsed":3133,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"05e550e7-7806-4a3a-9c95-0aef1b196f71"},"execution_count":88,"outputs":[{"output_type":"stream","name":"stdout","text":["['▁Th', 'is', '▁is', '▁a', '▁test']\n","[302, 258, 10, 4, 2395]\n","▁This is a test\n","This is a test\n"]}]},{"cell_type":"code","execution_count":89,"outputs":[{"output_type":"stream","name":"stdout","text":["['<unk>', '<s>', '</s>', '<pad>', '▁a', '.', '▁A', '▁in', '▁the', '▁on', '▁is', '▁man', '▁and', '▁of', '▁with', 's', 'ing', '▁', ',', '▁woman']\n","['<unk>', '<s>', '</s>', '<pad>', '.', '▁eine', '▁Ein', 'm', '▁in', '▁mit', ',', '▁und', '▁auf', '▁ein', '▁Mann', '▁einer', '▁Eine', 'n', '▁der', '▁Frau']\n"]}],"source":["print([en_sp.id_to_piece(id) for id in range(20)])\n","print([de_sp.id_to_piece(id) for id in range(20)])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"zv9Q9YyAUqoh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650145606304,"user_tz":240,"elapsed":7,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"e1b03486-b92d-488a-fecc-3d536f7d06db"}},{"cell_type":"code","source":["# indeces of special symbols \n","UNK, BOS, EOS, PAD = 0, 1, 2, 3"],"metadata":{"id":"8grAiF0GfmYx","executionInfo":{"status":"ok","timestamp":1650145606304,"user_tz":240,"elapsed":5,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":90,"outputs":[]},{"cell_type":"markdown","source":["# Data processing"],"metadata":{"collapsed":false,"id":"OuOHh7fF5Tn8"}},{"cell_type":"code","source":["SRC = \"de\"\n","TRG = \"en\"\n","\n","train_iter = Multi30k(split='train', language_pair=(SRC, TRG))\n","valid_iter = Multi30k(split='valid', language_pair=(SRC, TRG))\n","test_iter  = Multi30k(split='test',  language_pair=(SRC, TRG))\n","\n","train_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in train_iter]\n","valid_set = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in valid_iter]\n","test_set  = [(x.rstrip('\\n'), y.rstrip('\\n')) for x, y in test_iter]\n","print(len(train_set), len(valid_set), len(test_set))\n","for i in range(10):\n","   print(train_set[i])"],"metadata":{"id":"jh3Nxm7VaHIQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650145606305,"user_tz":240,"elapsed":6,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"80cbf61b-28d9-463b-f442-73dd6cb59266"},"execution_count":91,"outputs":[{"output_type":"stream","name":"stdout","text":["29000 1014 1000\n","('Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.', 'Two young, White males are outside near many bushes.')\n","('Mehrere Männer mit Schutzhelmen bedienen ein Antriebsradsystem.', 'Several men in hard hats are operating a giant pulley system.')\n","('Ein kleines Mädchen klettert in ein Spielhaus aus Holz.', 'A little girl climbing into a wooden playhouse.')\n","('Ein Mann in einem blauen Hemd steht auf einer Leiter und putzt ein Fenster.', 'A man in a blue shirt is standing on a ladder cleaning a window.')\n","('Zwei Männer stehen am Herd und bereiten Essen zu.', 'Two men are at the stove preparing food.')\n","('Ein Mann in grün hält eine Gitarre, während der andere Mann sein Hemd ansieht.', 'A man in green holds a guitar while the other man observes his shirt.')\n","('Ein Mann lächelt einen ausgestopften Löwen an.', 'A man is smiling at a stuffed lion')\n","('Ein schickes Mädchen spricht mit dem Handy während sie langsam die Straße entlangschwebt.', 'A trendy girl talking on her cellphone while gliding slowly down the street.')\n","('Eine Frau mit einer großen Geldbörse geht an einem Tor vorbei.', 'A woman with a large purse is walking by a gate.')\n","('Jungen tanzen mitten in der Nacht auf Pfosten.', 'Boys dancing on poles in the middle of the night.')\n"]}]},{"cell_type":"code","execution_count":145,"outputs":[],"source":["tokenizers = {\"en\": en_sp.encode_as_ids, \"de\": de_sp.encode_as_ids}\n","detokenizers = {\"en\":en_sp.decode_ids, \"de\":de_sp.decode_ids}"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"IPD4eW4G5Tn_","executionInfo":{"status":"ok","timestamp":1650158679940,"user_tz":240,"elapsed":190,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":93,"outputs":[],"source":["max_seq_len = 50\n","def tokenize_dataset(dataset):\n","   return [(torch.tensor([BOS]+tokenizers[SRC](src_text)[0:max_seq_len-2]+[EOS]),\n","            torch.tensor([BOS]+tokenizers[TRG](trg_text)[0:max_seq_len-2]+[EOS]))\n","            for src_text, trg_text in dataset\n","          ]\n","          \n","train_tokenized = tokenize_dataset(train_set)\n","valid_tokenized = tokenize_dataset(valid_set)\n","test_tokenized  = tokenize_dataset(test_set)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"gF5sy0p65ToA","executionInfo":{"status":"ok","timestamp":1650145608643,"user_tz":240,"elapsed":2342,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","source":["class TranslationDataset:\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","batch_size = 128\n","def pad_sequence(batch):\n","    'collate function for padding setences such that all \\\n","    the sentences in the batch have the same lence'\n","    src_seqs  = [src for src, trg in batch]\n","    trg_seqs  = [trg for src, trg in batch]\n","    src_padded = torch.nn.utils.rnn.pad_sequence(src_seqs,\n","                                batch_first=True, padding_value = PAD)\n","    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_seqs,\n","                                batch_first=True, padding_value = PAD)\n","    return src_padded, trg_padded\n"],"metadata":{"id":"8RSKKEGTHICe","executionInfo":{"status":"ok","timestamp":1650145608643,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["from dataclasses import dataclass\n","@dataclass\n","class Dataloaders:\n","    def __init__(self):\n","        self.train_dataset = TranslationDataset(train_tokenized)\n","        self.valid_dataset = TranslationDataset(valid_tokenized)\n","        self.test_dataset  = TranslationDataset(test_tokenized)\n","        \n","        # each batch returned by dataloader will be padded such that all the texts in\n","        # that batch have the same length as the longest text in that batch\n","        self.train_loader = torch.utils.data.DataLoader(self.train_dataset, batch_size=batch_size,\n","                                                shuffle=True, collate_fn = pad_sequence\n","                                            )\n","        \n","        self.test_loader = torch.utils.data.DataLoader(self.test_dataset, batch_size=batch_size,\n","                                                shuffle=True, collate_fn=pad_sequence)\n","        \n","        self.valid_loader = torch.utils.data.DataLoader(self.valid_dataset, batch_size=batch_size,\n","                                                shuffle=True, collate_fn=pad_sequence)\n"],"metadata":{"id":"WgeG2xQwFmIZ","executionInfo":{"status":"ok","timestamp":1650145608644,"user_tz":240,"elapsed":5,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":95,"outputs":[]},{"cell_type":"markdown","source":["# Transformer Model"],"metadata":{"id":"6t5Bkt_LOu0p"}},{"cell_type":"code","execution_count":96,"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, h, d_embed, dropout=0.1):\n","        super(MultiHeadedAttention, self).__init__()\n","        assert d_embed % h == 0 # check the h number\n","        self.d_k = d_embed//h\n","        self.d_embed = d_embed\n","        self.h = h\n","        self.WQ = nn.Linear(d_embed, d_embed)\n","        self.WK = nn.Linear(d_embed, d_embed)\n","        self.WV = nn.Linear(d_embed, d_embed)\n","        self.linear = nn.Linear(d_embed, d_embed)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x_query, x_key, x_value, mask=None):\n","        nbatch = x_query.size(0) # get batch size\n","        # 1) Linear projections to get the multi-head query, key and value\n","        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n","        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n","        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        # 2) Attention\n","        # scores has dimensions: nbatch * h * seq_len * seq_len\n","        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_embed)\n","        # 3) Mask out padding tokens and future tokens\n","        if mask is not None:\n","            scores = scores.masked_fill(mask, float('-inf'))\n","        # p_atten dimensions: nbatch * h * seq_len * seq_len\n","        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n","        # x dimensions: nbatch * h * seq_len * d_k\n","        x = torch.matmul(p_atten, value)\n","        # x now has dimensions:nbtach * seq_len * d_embed\n","        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n","        return self.linear(x) # final linear layer\n","\n","\n","class ResidualConnection(nn.Module):\n","  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n","  def __init__(self, dim, dropout):\n","      super().__init__()\n","      self.drop = nn.Dropout(dropout)\n","      self.norm = nn.LayerNorm(dim)\n","\n","  def forward(self, x, sublayer):\n","      return x + self.drop(sublayer(self.norm(x)))\n","\n","\n","class Encoder(nn.Module):\n","    '''Encoder = words embedding + position embedding -> N stack of EncoderBlock -> layer_norm'''\n","    def __init__(self, config):\n","        super().__init__()\n","        self.d_embed = config.d_embed\n","        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) \n","        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n","        self.encoder_layers = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n","        self.dropout = nn.Dropout(config.dropout)\n","        self.norm = nn.LayerNorm(config.d_embed)\n","\n","    def forward(self, input, mask=None):\n","        x = self.tok_embed(input)\n","        x_pos = self.pos_embed[:, :x.size(1), :]\n","        x = self.dropout(x + x_pos)\n","        for layer in self.encoder_layers:\n","            x = layer(x, mask)\n","        return self.norm(x)\n","\n","\n","class EncoderBlock(nn.Module):\n","    '''EncoderBlock: self-attention -> positionalwise feed-forward (fully connected) layer'''\n","    def __init__(self, config):\n","        super(EncoderBlock, self).__init__()\n","        self.attn = MultiHeadedAttention(config.h, config.d_embed, config.dropout)\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(config.d_embed, config.d_ff),\n","            nn.ReLU(),\n","            nn.Dropout(config.dropout),\n","            nn.Linear(config.d_ff, config.d_embed)\n","        )\n","        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n","        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n","\n","    def forward(self, x, mask=None):\n","        # self-attention\n","        x = self.residual1(x, lambda x: self.attn(x, x, x, mask =mask))\n","        # positionwise feed-forwad\n","        return self.residual2(x, lambda x: self.feed_forward(x))\n","\n","\n","class Decoder(nn.Module):\n","    '''Decoder = words embedding + position embedding -> N stack of DecoderBlock -> fully-connected layer'''\n","    def __init__(self, config):\n","        super().__init__()\n","        self.d_embed = config.d_embed\n","        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n","        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n","        self.dropout = nn.Dropout(config.dropout)\n","        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n","        self.norm = nn.LayerNorm(config.d_embed)\n","        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n","    \n","    def future_mask(self, seq_len):\n","        '''mask out tokens at future positions'''\n","        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n","        return mask.view(1, 1, seq_len, seq_len)\n","\n","    def forward(self, encoder_out, src_mask, trg, trg_pad_mask):\n","        seq_len = trg.size(1)\n","        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n","        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n","        x = self.dropout(x)\n","        for layer in self.decoder_blocks:\n","            x = layer(encoder_out, src_mask, x, trg_mask)\n","        x = self.norm(x)\n","        logits = self.linear(x)\n","        return logits\n","\n","\n","class DecoderBlock(nn.Module):\n","    ''' EncoderBlock: self-attention -> positionalwise feed-forward (fully connected) layer'''\n","    def __init__(self, config):\n","        super().__init__()\n","        self.atten1 = MultiHeadedAttention(config.h, config.d_embed)\n","        self.atten2 = MultiHeadedAttention(config.h, config.d_embed)\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(config.d_embed, config.d_ff),\n","            nn.ReLU(),\n","            nn.Linear(config.d_ff, config.d_embed),\n","            nn.Dropout(config.dropout)\n","        )\n","        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout) \n","                                       for i in range(3)])\n","\n","    def forward(self, encoder_output, src_mask, decoder_layer_input, trg_mask):\n","        x = encoder_output\n","        y = decoder_layer_input\n","        y = self.residuals[0](y, lambda y: self.atten1(y, y, y, mask=trg_mask))\n","        # keys and values are from the encoder output\n","        y = self.residuals[1](y, lambda y: self.atten2(y, x, x, mask=src_mask))\n","        return self.residuals[2](y, self.feed_forward)\n","\n","\n","class Transformer(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, src_mask, trg, trg_pad_mask):\n","        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"AWvU3VeM5ToD","executionInfo":{"status":"ok","timestamp":1650145608644,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"V7Xdzd9x8z-C"}},{"cell_type":"code","source":["@dataclass\n","class ModelConfig:\n","    encoder_vocab_size: int\n","    decoder_vocab_size: int\n","    d_embed: int \n","    # d_ff is the dimension of the fully-connected layer\n","    d_ff: int\n","    # h is the number of attention head\n","    h: int\n","    N_encoder: int\n","    N_decoder: int\n","    max_seq_len: int\n","    dropout: float\n","\n","def make_model(config):\n","    model = Transformer(Encoder(config), Decoder(config)).to(DEVICE)\n","\n","    # initialize model parameters\n","    # it seems that this initialization is very important!\n","    for p in model.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","    return model"],"metadata":{"id":"gxYYnrC-FAgI","executionInfo":{"status":"ok","timestamp":1650145608644,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","execution_count":98,"outputs":[],"source":["def make_batch_input(x, y):\n","        src = x.to(DEVICE)\n","        trg_in = y[:, :-1].to(DEVICE)\n","        trg_out = y[:, 1:].contiguous().view(-1).to(DEVICE)\n","        src_pad_mask = (src == PAD).view(src.size(0), 1, 1, src.size(-1))\n","        trg_pad_mask = (trg_in == PAD).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n","        return src, trg_in, trg_out, src_pad_mask, trg_pad_mask"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"dUsGrq6fOKbC","executionInfo":{"status":"ok","timestamp":1650145608644,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":138,"outputs":[],"source":["def train_epoch(model, dataloaders):\n","    model.train()\n","    grad_norm_clip = 1.0\n","    losses, acc, count = [], 0, 0\n","    num_batches = len(dataloaders.train_loader)\n","    pbar = tqdm(enumerate(dataloaders.train_loader), total=num_batches)\n","    for idx, (x, y)  in  pbar:\n","        optimizer.zero_grad()\n","        src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n","        pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n","        pred = pred.view(-1, pred.size(-1))\n","        loss = loss_fn(pred, trg_out).to(DEVICE)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n","        optimizer.step()\n","        scheduler.step()\n","        losses.append(loss.item())\n","        # report progress\n","        if idx>0 and idx%50 == 0:\n","            pbar.set_description(f'''ep: {scheduler.last_epoch//num_batches}, \n","                                train loss={loss.item():.3f}, lr={scheduler.get_last_lr()[0]:.5f}''')\n","    return np.mean(losses)\n","\n","\n","def train(model, dataloaders, epochs):\n","    global early_stop_count\n","    best_valid_loss = float('inf')\n","    train_size = len(dataloaders.train_loader)*batch_size\n","    for ep in range(epochs):\n","        train_loss = train_epoch(model, dataloaders)\n","        valid_loss = validate(model, dataloaders.valid_loader)\n","        \n","        print(f'ep: {ep}: train_loss, {train_loss:.5f}, valid_loss: {valid_loss:.5f}')\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","        else:\n","            if scheduler.last_epoch>2*warmup_steps:\n","                early_stop_count -= 1\n","                if early_stop_count<=0:   \n","                    #torch.save(model, f'saved_embeds/{SRC}_to_{TRG}_train_size_{train_size}_model_size_{model_size}.pt')\n","            #f = open(\"save_model/{SRC}_to_{TRG}_dataset_size_{dataset_size}.txt\", 'w'):\n","            #f.write()\n","                    return train_loss, valid_loss\n","    return train_loss, valid_loss\n","      \n","               \n","def validate(model, dataloder):\n","    'compute the validation loss'\n","    model.eval()\n","    losses = 0\n","    with torch.no_grad():\n","        for i, (x, y) in enumerate(dataloder):\n","            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n","            pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n","            pred = pred.view(-1, pred.size(-1))\n","            losses += (loss_fn(pred, trg_out).item())\n","    return losses/len(dataloder)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"T51zR33b5ToF","executionInfo":{"status":"ok","timestamp":1650156964613,"user_tz":240,"elapsed":205,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":102,"outputs":[],"source":["def translate(model, x):\n","    'translate source sentences into the target language, without looking at the answer'\n","    with torch.no_grad():\n","        dB = x.size(0)\n","        y = torch.tensor([[BOS]*dB]).view(dB, 1).to(DEVICE)\n","        x_pad_mask = (x == PAD).view(x.size(0), 1, 1, x.size(-1)).to(DEVICE)\n","        memory = model.encoder(x, x_pad_mask)\n","        for i in range(max_seq_len):\n","            y_pad_mask = (y == PAD).view(y.size(0), 1, 1, y.size(-1)).to(DEVICE)\n","            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n","            last_output = logits.argmax(-1)[:, -1]\n","            last_output = last_output.view(dB, 1)\n","            y = torch.cat((y, last_output), 1).to(DEVICE)\n","    return y"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"BSUApZ2-5ToH","executionInfo":{"status":"ok","timestamp":1650145611854,"user_tz":240,"elapsed":6,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","source":["def remove_pad(sent):\n","    '''truncate the sentence if BOS is in it,\n","     otherwise simply remove the padding tokens at the end'''\n","    if sent.count(EOS)>0:\n","      sent = sent[0:sent.index(EOS)+1]\n","    while sent and sent[-1] == PAD:\n","            sent = sent[:-1]\n","    return sent\n","\n","def decode_sentence(detokenizer, sentence_ids):\n","    'convert a tokenized sentence (a list of numbers) to a literal string'\n","    if not isinstance(sentence_ids, list):\n","        sentence_ids = sentence_ids.tolist()\n","    sentence_ids = remove_pad(sentence_ids)\n","    return detokenizer(sentence_ids).replace(\"<bos>\", \"\")\\\n","           .replace(\"<eos>\", \"\").strip().replace(\" .\", \".\")\n","\n","def evaluate(model, dataloader, num_batch=None):\n","    'evaluate the model, and compute the BLEU score'\n","    model.eval()\n","    refs, cans, bleus = [], [], []\n","    with torch.no_grad():\n","        for idx, (x, y) in enumerate(dataloader):\n","            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n","            translation = translate(model, src)\n","            trg_out = trg_out.view(x.size(0), -1)\n","            refs = refs + [decode_sentence(detokenizers[TRG], trg_out[i]) for i in range(len(src))]\n","            cans = cans + [decode_sentence(detokenizers[TRG], translation[i]) for i in range(len(src))] \n","            if num_batch and idx>=num_batch:\n","                break\n","        bleus.append(sacrebleu.corpus_bleu(cans, [refs]).score)\n","        # print some examples\n","        for i in range(3):\n","            print(f'src:  {decode_sentence(detokenizers[SRC], src[i])}')\n","            print(f'trg:  {decode_sentence(detokenizers[TRG], trg_out[i])}')\n","            print(f'pred: {decode_sentence(detokenizers[TRG], translation[i])}')\n","        return np.mean(bleus)"],"metadata":{"id":"zQtU_WoLPMwM","executionInfo":{"status":"ok","timestamp":1650158833898,"user_tz":240,"elapsed":518,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":146,"outputs":[]},{"cell_type":"code","source":["config = ModelConfig(encoder_vocab_size = vocab_sizes[SRC], \n","                     decoder_vocab_size=vocab_sizes[TRG],\n","                     d_embed=512, \n","                     d_ff=512, \n","                     h=8,\n","                     N_encoder=3, \n","                     N_decoder=3, \n","                     max_seq_len=max_seq_len,\n","                     dropout=0.1\n","                     )\n","\n","data_loaders = Dataloaders()\n","train_size = len(data_loaders.train_loader)*batch_size\n","model = make_model(config)\n","model_size = sum([p.numel() for p in model.parameters()])\n","print(f'model_size: {model_size}, train_set_size: {train_size}')\n","warmup_steps = 3*len(data_loaders.train_loader)\n","# lr first increases in the warmup steps, and then descreases\n","lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.5, betas=(0.9, 0.98), eps=1e-9)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n","early_stop_count = 2\n","train_loss, valid_loss = train(model, data_loaders, epochs=5)\n","test_loss  = validate(model, data_loaders.test_loader)\n","print(\"train set examples:\")\n","train_bleu = evaluate(model, data_loaders.train_loader, 40)\n","print(\"validation set examples:\")\n","valid_bleu = evaluate(model, data_loaders.valid_loader)\n","print(\"test set examples:\")\n","test_bleu  = evaluate(model, data_loaders.test_loader)\n","print(f'train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}, test_loss: {test_loss:.4f}')\n","print(f'test_bleu: {test_bleu:.4f}, valid_bleu: {valid_bleu:.4f} train_bleu: {train_bleu:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K-HOapnPDtdZ","executionInfo":{"status":"ok","timestamp":1650159045456,"user_tz":240,"elapsed":209646,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"320e7ae4-4704-401c-9e12-9501f92d51bc"},"execution_count":147,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size: 26201096, train_set_size: 29056\n"]},{"output_type":"stream","name":"stderr","text":["ep: 0, train loss=3.875,lr=0.00025: 100%|██████████| 227/227 [00:29<00:00,  7.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 5.54912, valid_loss: 3.71897\n"]},{"output_type":"stream","name":"stderr","text":["ep: 1, train loss=2.648,lr=0.00053: 100%|██████████| 227/227 [00:29<00:00,  7.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 3.12507, valid_loss: 2.65317\n"]},{"output_type":"stream","name":"stderr","text":["ep: 2, train loss=2.012,lr=0.00082: 100%|██████████| 227/227 [00:29<00:00,  7.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 2.25551, valid_loss: 2.13430\n"]},{"output_type":"stream","name":"stderr","text":["ep: 3, train loss=1.711,lr=0.00074: 100%|██████████| 227/227 [00:29<00:00,  7.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 1.71772, valid_loss: 1.86473\n"]},{"output_type":"stream","name":"stderr","text":["ep: 4, train loss=1.352,lr=0.00066: 100%|██████████| 227/227 [00:29<00:00,  7.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 1.31952, valid_loss: 1.79312\n","train set examples:\n","src:  Eine ruhige Straßenecke mit einem Mann der auf einem Hocker sitzt und auf eine kleine Bühne starrt.\n","trg:  A calm street corner with a man sitting on a stool looking at something on a small platform.\n","pred: A calm corner with a man sitting on a stool on a stool looking at a small small rock.\n","src:  Ein Hund geht auf einen Pfad umgeben von Bäumen, spazieren.\n","trg:  A dog walks on a path surrounded by trees.\n","pred: A dog walks on a path surrounded by trees.\n","src:  Ein Mann und ein Junge singen zusammen mit Mikrofonen.\n","trg:  Man and young boy singing together using microphones.\n","pred: A man and a boy singing together with microphones.\n","validation set examples:\n","src:  Ein Baby in einer Wippe und ein stehender Junge, die von Spielzeug umgeben sind.\n","trg:  A baby in a bouncy seat and a standing boy surrounded by toys.\n","pred: A baby in a seesaw and a young boy surrounded by toy.\n","src:  Ein braun gekleideter Mann hält ein Lichtschwert.\n","trg:  A man dressed in brown holding a light saber.\n","pred: A man in brown holds a light blue toy.\n","src:  Zwei Mädchen sitzen an einem Tisch und arbeiten an kunsthandwerklichen Projekten.\n","trg:  Two girls are seated at a table and working on craft projects.\n","pred: Two girls are sitting at a table working on a project.\n","test set examples:\n","src:  Ein Mann mit einer Zigarette im Mund fixiert einen Teller mit Essen.\n","trg:  A man with a cigarette in his mouth fixing a plate of food.\n","pred: A man with a cigarette in his mouth is being food.\n","src:  Ein Kran arbeitet mitten in einem Schutthaufen.\n","trg:  A crane operates amidst piles of rubble.\n","pred: A crane is working on a pile of rubble.\n","src:  Eine Person surft auf einer brechenden Welle auf dem Ozean.\n","trg:  A person surfing through a crashing wave in the ocean.\n","pred: A person surfing on a crashing wave.\n","train_loss: 1.3195, valid_loss: 1.7931, test_loss: 1.8281\n","test_bleu: 34.9180, valid_bleu: 34.9746 train_bleu: 44.1510\n"]}]},{"cell_type":"markdown","source":["So with a transformer model of 26 million parameters, trained on a training set of 29k sentence pairs, we got a test BLEU score of 34.9180."],"metadata":{"id":"SE7RdQ57HN9J"}},{"cell_type":"code","source":["def translate_this_sentence(text: str):\n","    'translate the source sentence in string formate into target language'\n","    input = torch.tensor([[BOS] + tokenizers[SRC](text) + [EOS]]).to(DEVICE)\n","    output = translate(model, input)\n","    return decode_sentence(sps[TRG].decode_ids, output[0])\n","\n","translate_this_sentence(\"Eine Gruppe von Menschen steht vor einem Iglu.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":38},"id":"6DHwo3xcYmXy","executionInfo":{"status":"ok","timestamp":1650158607513,"user_tz":240,"elapsed":969,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"1432021e-d3c8-4621-a447-adca6b3eece2"},"execution_count":144,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'A group of people are standing in front of an indoor fountain.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":144}]}]}