{"cells":[{"cell_type":"markdown","metadata":{"id":"_gRJme0w5nh7"},"source":["# Train a decoder-only transformer (GPT-like) to do addition\n","\n","I learned a lot from https://github.com/karpathy/minGPT, but I have rewritten all the code based on my own understanding.\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"qjFkasZb5niB","executionInfo":{"status":"ok","timestamp":1649521346589,"user_tz":240,"elapsed":6389,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"outputs":[],"source":["import math\n","from dataclasses import dataclass\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data.dataset import Dataset\n","from tqdm import tqdm\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","source":["## Data processing\n","### Generate an addition dataset"],"metadata":{"collapsed":false,"id":"xDSK1sxiIdfU"}},{"cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["([tensor([15,  7, 10,  8,  7, 13,  9,  4, 14]), tensor([15,  8,  7, 10,  7,  0, 13,  1,  5,  7, 14]), tensor([15,  8,  5, 10,  4,  4, 13,  1,  2,  9, 14]), tensor([15,  6,  7, 10,  7,  0, 13,  1,  3,  7, 14]), tensor([15,  0, 10,  1,  7, 13,  1,  7, 14]), tensor([15,  1,  6, 10,  5,  1, 13,  6,  7, 14]), tensor([15,  2,  1, 10,  9,  7, 13,  1,  1,  8, 14]), tensor([15,  5,  9, 10,  6,  9, 13,  1,  2,  8, 14]), tensor([15,  7,  3, 10,  1,  3, 13,  8,  6, 14]), tensor([15,  7,  4, 10,  7,  5, 13,  1,  4,  9, 14]), tensor([15,  5,  7, 10,  7,  8, 13,  1,  3,  5, 14]), tensor([15,  6,  9, 10,  1,  4, 13,  8,  3, 14]), tensor([15,  2,  9, 10,  1, 13,  3,  0, 14]), tensor([15,  6,  3, 10,  3,  4, 13,  9,  7, 14]), tensor([15,  5,  9, 10,  4,  3, 13,  1,  0,  2, 14]), tensor([15,  2,  2, 10,  9,  2, 13,  1,  1,  4, 14]), tensor([15,  8,  5, 10,  8,  4, 13,  1,  6,  9, 14]), tensor([15,  6,  4, 10,  2,  4, 13,  8,  8, 14]), tensor([15,  6,  3, 10,  6, 13,  6,  9, 14]), tensor([15,  1,  5, 10,  2,  1, 13,  3,  6, 14])], ['7+87=94', '87+70=157', '85+44=129', '67+70=137', '0+17=17', '16+51=67', '21+97=118', '59+69=128', '73+13=86', '74+75=149', '57+78=135', '69+14=83', '29+1=30', '63+34=97', '59+43=102', '22+92=114', '85+84=169', '64+24=88', '63+6=69', '15+21=36'])\n","([tensor([15,  8,  3, 10,  0,  9, 13,  9,  2, 14]), tensor([15,  7,  1, 10,  4,  7, 13,  1,  1,  8, 14]), tensor([15,  3,  5, 10,  9,  9, 13,  1,  3,  4, 14]), tensor([15,  9,  1, 10,  6,  6, 13,  1,  5,  7, 14]), tensor([15,  3,  4, 10,  2,  0, 13,  5,  4, 14]), tensor([15,  0,  9, 10,  2,  1, 13,  3,  0, 14]), tensor([15,  5,  3, 10,  5,  4, 13,  1,  0,  7, 14]), tensor([15,  7,  4, 10,  0,  7, 13,  8,  1, 14]), tensor([15,  9,  8, 10,  9,  3, 13,  1,  9,  1, 14]), tensor([15,  3,  7, 10,  0,  8, 13,  4,  5, 14]), tensor([15,  9,  6, 10,  2,  0, 13,  1,  1,  6, 14]), tensor([15,  0,  6, 10,  4,  0, 13,  4,  6, 14]), tensor([15,  2,  0, 10,  5,  9, 13,  7,  9, 14]), tensor([15,  0,  8, 10,  9,  3, 13,  1,  0,  1, 14]), tensor([15,  1,  9, 10,  9,  4, 13,  1,  1,  3, 14]), tensor([15,  5,  3, 10,  0,  4, 13,  5,  7, 14]), tensor([15,  9,  3, 10,  3,  7, 13,  1,  3,  0, 14]), tensor([15,  8,  9, 10,  6,  9, 13,  1,  5,  8, 14]), tensor([15,  6,  9, 10,  4,  8, 13,  1,  1,  7, 14]), tensor([15,  0,  9, 10,  8,  9, 13,  9,  8, 14])], ['83+09=92', '71+47=118', '35+99=134', '91+66=157', '34+20=54', '09+21=30', '53+54=107', '74+07=81', '98+93=191', '37+08=45', '96+20=116', '06+40=46', '20+59=79', '08+93=101', '19+94=113', '53+04=57', '93+37=130', '89+69=158', '69+48=117', '09+89=98'])\n"]}],"source":["PLUS_SIGN = 10\n","MUL_SIGN  = 11\n","MINUS_SIGN = 12\n","EQUAL_SIGN = 13\n","EOS = 14\n","BOS = 15\n","PAD = 16\n","UNK = 17\n","\n","symbol_to_int_dict = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4,\n","                      \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9,\n","                      \"+\": PLUS_SIGN, \"*\": MUL_SIGN, \"-\": MINUS_SIGN,\n","                      \"=\": EQUAL_SIGN,  \"<EOS>\": EOS, \"<BOS>\": BOS,\n","                      \"<pad>\": PAD, \"??\": UNK\n","                      }\n","\n","int_to_symbol_dict = {y:x for (x,y) in symbol_to_int_dict.items()}\n","vocab_size = len(symbol_to_int_dict)\n","\n","def decode_equation(equation):\n","    '''convert an equation in list format to string format '''\n","    res = \"\".join([str(int_to_symbol_dict.get(x, UNK)) for x in equation.tolist()])\n","    return res.replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\")\n","\n","def encode_equation(equation, max_ndigits, padQ=True):\n","    '''convert an equation(up to the equal sign in it) in string format to a list'''\n","    equal_size_loc = equation.index('=')\n","    plus_size_loc = equation.index('+')\n","    num1 = pad_number(equation[0:plus_size_loc], max_ndigits)\n","    num2 = pad_number(equation[plus_size_loc+1:equal_size_loc], max_ndigits)\n","    new_equation = num1 + \"+\" + num2 + \"=\"\n","    return torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in new_equation]).to(DEVICE)\n","\n","\n","def pad_number(num, max_ndigits)->str:\n","    s = str(num)\n","    while len(s)<max_ndigits:\n","      s = \"0\"+s\n","    return s\n","\n","def create_add_dataset(max_ndigits, dataset_size, padQ=True):\n","    ''' Function for creating an addition dataset.\n","    if padQ=True, pre-padding of 0s will be added on the numbers such that all the \n","    numbers has the same length max_ndigits, for example, with max_ndigits=3,  \n","    32 will be represented 032.\n","    '''\n","    dataset_str = []\n","    for i in range(dataset_size):\n","        num1, num2 = np.random.randint(0, 10**max_ndigits, 2)\n","        ans = num1 + num2\n","        if padQ:\n","            equation = pad_number(num1, max_ndigits) + '+' + pad_number(num2, max_ndigits) + \"=\" + pad_number(ans, max_ndigits)\n","        else:\n","            equation = str(num1) + '+' + str(num2) + \"=\" + str(ans)\n","        dataset_str.append(equation)\n","\n","    dataset = [torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in x]+[EOS])\n","               for x in dataset_str]\n","    return dataset, dataset_str\n","\n","print(create_add_dataset(2,20, padQ=False))\n","print(create_add_dataset(2, 20, padQ=True))"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"JlYks0a55niC","executionInfo":{"status":"ok","timestamp":1649521346742,"user_tz":240,"elapsed":155,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"2a48daf9-155e-484c-8f40-34afccabc981"}},{"cell_type":"markdown","source":["### Create dataloders for the train, validation and test sets"],"metadata":{"collapsed":false,"id":"4AaG4J3CIdfW"}},{"cell_type":"code","execution_count":3,"outputs":[],"source":["class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","batch_size = 256\n","def pad_sequence(batch):\n","    input_padded = torch.nn.utils.rnn.pad_sequence(batch,\n","                                batch_first=True, padding_value = PAD)\n","    return input_padded\n","\n","@dataclass\n","class DataLoaders:\n","    max_ndigits: int\n","    dataset_size: int\n","    padQ: bool = True\n","    val_loader = None\n","    test_loader = None\n","    train_loader = None\n","\n","    def split_data(self, split=[0.7, 0.1, 0.2]):\n","        if isinstance(split[0], float):\n","            train_size  = round(self.dataset_size*split[0])\n","            val_size = round(self.dataset_size*split[1])\n","            test_size = self.dataset_size - train_size - val_size\n","        elif isinstance(split[0], int):\n","            val_size = split[0]\n","            test_size = split[1]\n","            train_size  = dataset_size - test_size - val_size\n","\n","\n","        dataset, _ = create_add_dataset(self.max_ndigits, self.dataset_size, padQ=self.padQ)\n","        train_set, val_set, test_set = torch.utils.data.random_split(dataset,\n","                                                             [train_size, val_size, test_size],\n","                                                    generator=torch.Generator().manual_seed(42) )\n","\n","        self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                           shuffle=True, collate_fn = pad_sequence)\n","        self.test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n","                                           shuffle=True, collate_fn=pad_sequence)\n","        self.val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n","                                           shuffle=True, collate_fn=pad_sequence)\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"XNDapFsq5niE","executionInfo":{"status":"ok","timestamp":1649521346743,"user_tz":240,"elapsed":2,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["## GPT model\n","Here is my implementation of the GPT model, including the multi-headed self-attention module."],"metadata":{"collapsed":false,"id":"IIjLRLXGIdfX"}},{"cell_type":"code","execution_count":4,"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, h, d_model, dropout=0.1):\n","        super(MultiHeadedAttention, self).__init__()\n","        assert d_model % h == 0 # check the h number\n","        self.d_k = d_model//h\n","        self.d_model = d_model\n","        self.h = h\n","        self.WQ = nn.Linear(d_model, d_model)\n","        self.WK = nn.Linear(d_model, d_model)\n","        self.WV = nn.Linear(d_model, d_model)\n","        self.linear = nn.Linear(d_model, d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x_query, x_key, x_value, mask=None):\n","        nbatch = x_query.size(0) # get batch size\n","        # 1) Linear projections to get the multi-head query, key and value\n","        # x_query, x_key, x_value dimension: nbatch * seq_len * d_model\n","        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n","        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        # 2) Attention\n","        # scores has dimensions: nbatch * h * seq_len * seq_len\n","        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_model)\n","        # 3) Mask out padding tokens and future tokens\n","        if mask is not None:\n","            scores = scores.masked_fill(mask, float('-inf'))\n","        # p_atten dimensions: nbatch * h * seq_len * seq_len\n","        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n","        # x dimensions: nbatch * h * seq_len * d_k\n","        x = torch.matmul(p_atten, value)\n","        # x now has dimensions:nbtach * seq_len * d_model\n","        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_model)\n","\n","        return self.linear(x) # final linear layer\n","\n","\n","class ResidualConnection(nn.Module):\n","  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n","  def __init__(self, dim, dropout):\n","      super().__init__()\n","      self.drop = nn.Dropout(dropout)\n","      self.norm = nn.LayerNorm(dim)\n","\n","  def forward(self, x, sublayer):\n","      return x + self.drop(sublayer(self.norm(x)))\n","\n","\n","class Decoder(nn.Module):\n","\n","    def __init__(self, vocab_size, h, d_embed, max_len, N=4, drop_rate=0.1):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size, d_embed)\n","        self.pos_embed = nn.Embedding(max_len, d_embed)\n","        self.dropout = nn.Dropout(drop_rate)\n","        self.decoder_blocks = nn.Sequential(*[DecoderBlock(h, d_embed) for _ in range(N)])\n","        self.norm = nn.LayerNorm(d_embed)\n","        self.linear = nn.Linear(d_embed, vocab_size)\n","\n","    def forward(self, trg, trg_pad_mask):\n","        pos_embedding = self.pos_embed(torch.tensor(range(trg.size(-1))).to(DEVICE))\n","        x = self.embed(trg) + pos_embedding\n","        x = self.dropout(x)\n","        for layer in self.decoder_blocks:\n","            x = layer( x, trg_pad_mask)\n","        x = self.norm(x)\n","        logits = self.linear(x)\n","        return logits\n","\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, h, d_embed, dropout=0.1):\n","        super().__init__()\n","        self.atten1 = MultiHeadedAttention(h, d_embed)\n","        self.atten2 = MultiHeadedAttention(h, d_embed)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(d_embed, 4*d_embed),\n","            nn.GELU(),\n","            nn.Linear(4*d_embed, d_embed),\n","            nn.Dropout(dropout)\n","        )\n","        self.residual1 = ResidualConnection(d_embed, dropout)\n","        self.residual2 = ResidualConnection(d_embed, dropout)\n","        self.residual3 = ResidualConnection(d_embed, dropout)\n","\n","    def future_mask(self, seq_len):\n","        '''mask for masking out tokens at future positions'''\n","        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n","        return mask.view(1, 1, seq_len, seq_len)\n","\n","    def forward(self,  decoder_layer_input, decoder_pad_mask):\n","        y = decoder_layer_input\n","        seq_len = y.size(-2)\n","        decoder_mask = torch.logical_or(decoder_pad_mask, self.future_mask(seq_len))\n","        y = self.residual1(y, lambda y: self.atten1(y, y, y, mask=decoder_mask))\n","\n","        return self.residual3(y, self.ffn)\n","\n","class GPT(nn.Module):\n","    def __init__(self, decoder):\n","        super().__init__()\n","        self.decoder = decoder\n","\n","    def forward(self, input, pad_mask):\n","        return self.decoder(input, pad_mask)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"FuNdAglk5niF","executionInfo":{"status":"ok","timestamp":1649521346899,"user_tz":240,"elapsed":158,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["### Let's creat a GPT!"],"metadata":{"collapsed":false,"id":"GsVpY8RnIdfY"}},{"cell_type":"code","execution_count":5,"metadata":{"id":"A_BE7bIS5niG","executionInfo":{"status":"ok","timestamp":1649521346899,"user_tz":240,"elapsed":2,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"outputs":[],"source":["@dataclass\n","class ModelConfig:\n","  d_embed: int\n","  # d_ff is the dimension of the fully-connected layer\n","  d_ff: int\n","  # h is the number of attention head\n","  h: int\n","  N_decoder: int\n","  max_len: int\n","  dropout: float\n","\n","\n","def make_GPT(config):\n","    model = GPT(Decoder(vocab_size, config.h, config.d_embed, config.max_len,\n","                        config.N_decoder)).to(DEVICE)\n","    # initialize model parameters\n","    # it seems that this initialization is very important!\n","    for p in model.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","    return model"]},{"cell_type":"markdown","source":["## Functions for training and input/output processing"],"metadata":{"collapsed":false,"id":"zzrr1eoYIdfY"}},{"cell_type":"code","execution_count":6,"outputs":[],"source":["def make_batch_input(x):\n","        'function for generating model input, target and pad_mask from raw input x'\n","        input = x[:, :-1].to(DEVICE)\n","        equal_sign_loc = [(equation==EQUAL_SIGN).nonzero().item() for equation in x]\n","        target = [torch.cat((torch.tensor([PAD]*equal_sign_loc[i]), x[i][equal_sign_loc[i]+1:])) for i in range(len(x))]\n","        target = torch.cat(target, 0).contiguous().view(-1).to(DEVICE)\n","        pad_mask = (input == PAD).view(input.size(0), 1, 1, input.size(-1))\n","        return input, target, pad_mask"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VO4h4nKG5niH","executionInfo":{"status":"ok","timestamp":1649521346900,"user_tz":240,"elapsed":3,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":34,"outputs":[],"source":["def train_epoch(model, dataloader):\n","    model.train()\n","    grad_norm_clip = 1.0\n","    losses, acc, count = [], 0, 0\n","    num_batches = len(dataloader)\n","    pbar = tqdm(enumerate(dataloader), total=num_batches)\n","    for idx, x  in  pbar:\n","        optimizer.zero_grad()\n","        input, target, pad_mask = make_batch_input(x)\n","        pred = model(input, pad_mask).to(DEVICE)\n","        pred = pred.view(-1, pred.size(-1))\n","        loss = loss_fn(pred, target).to(DEVICE)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n","        optimizer.step()\n","        scheduler.step()\n","        losses.append(loss.item())\n","        # report progress\n","        if idx>0 and idx%50 == 0:\n","            pbar.set_description(f\"ep: {scheduler.last_epoch//num_batches}, train loss={loss.item():.3f},lr={scheduler.get_last_lr()[0]:.5f}\")\n","    return np.mean(losses)\n","\n","def train(model, dataloaders, epochs):\n","    best_val_loss = float('inf')\n","    global early_stop_count\n","    train_size = len(dataloaders.train_loader)*batch_size\n","    for ep in range(epochs):\n","        train_loss = train_epoch(model, dataloaders.train_loader)\n","        val_loss = validate(model, dataloaders.val_loader)\n","        print(f'ep {ep}: train_loss: {train_loss:.5f}, val_loss: {val_loss:.5f}')\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","        else:\n","            if scheduler.last_epoch>2*warmup_steps:\n","                early_stop_count -= 1\n","                if early_stop_count<=0:\n","                    #torch.save(model, f'saved_models/{SRC}_to_{TRG}_train_size_{train_size}_model_size_{model_size}.pt')\n","            #f = open(\"save_model/{SRC}_to_{TRG}_dataset_size_{dataset_size}.txt\", 'w'):\n","            #f.write()\n","                    return train_loss, val_loss\n","    return train_loss, val_loss\n","\n","\n","def validate(model, dataloder):\n","    'function for computing the loss on the validation set'\n","    model.eval()\n","    losses = []\n","    with torch.no_grad():\n","        for i, x in enumerate(dataloder):\n","            input, target, pad_mask = make_batch_input(x)\n","            pred = model(input, pad_mask).to(DEVICE)\n","            pred = pred.view(-1, pred.size(-1))\n","            losses.append(loss_fn(pred, target).item())\n","    return np.mean(losses)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"0dVrqAIW5niH","executionInfo":{"status":"ok","timestamp":1649522424286,"user_tz":240,"elapsed":3,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","source":["@torch.no_grad()\n","def compute_sum(model, x):\n","    'Function for computing the sum of two numbers.'\n","    for i in range(max_ndigits+2):\n","        pad_mask = (x == PAD).view(1, 1, 1, x.size(-1)).to(DEVICE)\n","        logits = model(x, pad_mask)\n","        last_output = logits.argmax(-1)[:,-1].view(1,1)\n","        x = torch.cat((x, last_output), 1).to(DEVICE)\n","        if last_output.item() == EOS:\n","            break\n","    return x[0]\n","\n","def evaluate(model, dataloader, num_batch=None):\n","    '''Function for evaluation the model.\n","    This function take equations, and truncate them up to the equal-sign, and feed them to the\n","    model to get the predictions, compare them with the correct answers, and output the accuracy.\n","    '''\n","    model.eval()\n","    acc, count = 0, 0\n","    num_wrong_to_display = 5\n","    for idx, x in enumerate(dataloader):\n","        for equation in x:\n","            loc_equal_sign = equation.tolist().index(EQUAL_SIGN)\n","            loc_EOS = equation.tolist().index(EOS)\n","            input = equation[0:loc_equal_sign+1].view(1, -1).to(DEVICE)\n","            ans = equation[:loc_EOS+1].tolist()\n","            ans_pred = compute_sum(model, input)\n","            count += 1\n","\n","            if ans == ans_pred.tolist():\n","                acc +=1\n","            else:\n","                if num_wrong_to_display > 0:\n","                    print(f'correct equation: {decode_equation(equation).replace(\"<pad>\",\"\")}')\n","                    print(f'predicted:        {decode_equation(ans_pred)}')\n","                    num_wrong_to_display -= 1\n","        if num_batch and idx>num_batch:\n","            break\n","    return acc/count\n","\n","def what_is(question:str)->str:\n","    'function for computing the sum of two numbers with input in literal string format'\n","    pred = compute_sum(model, encode_equation(question, max_ndigits).view(1,-1))\n","    pred = decode_equation(pred)\n","    pred = pred[pred.index(\"=\")+1:]\n","    return question+pred\n"],"metadata":{"id":"yCQBQ19TVpuc","executionInfo":{"status":"ok","timestamp":1649521968601,"user_tz":240,"elapsed":115,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## 2-digit addition"],"metadata":{"id":"a7J0GgUrfZ6W"}},{"cell_type":"code","source":["max_ndigits = 2\n","# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n","max_len = 3*max_ndigits + 6\n","config = ModelConfig(d_embed=128, d_ff=256, h=4, N_decoder=2, max_len= max_len,\n","                           dropout=0.1)\n","dataset_size = 10000\n","data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n","data_loaders.split_data(split=[1000, 2000])\n","train_size = len(data_loaders.train_loader)*batch_size\n","model = make_GPT(config)\n","model_size = sum([p.numel() for p in model.parameters()])\n","print(f'model_size: {model_size}, train_set_size: {train_size}')\n","warmup_steps = 3*len(data_loaders.train_loader)\n","# lr first increases in the warmup steps, and then descreases\n","#lr_fn = lambda step: 3*min([(step+1)/(3*len(data_loaders.train_loader)), (step+1)**(-0.5)])\n","lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n","early_stop_count = 10 # Setting early_stop_count to a large number, that is, I'm not implementing early_stop here\n","\n","train_loss, val_loss = train(model, data_loaders, epochs=30)\n"],"metadata":{"id":"fpBEDpznfmzn","executionInfo":{"status":"ok","timestamp":1649522370461,"user_tz":240,"elapsed":13846,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f11dd5bb-6cee-4320-886d-469ac48225c4"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size: 535570, train_set_size: 7168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 65.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 2.08625, val_loss: 1.45997\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 69.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 1.37422, val_loss: 1.19786\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 69.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 1.16191, val_loss: 1.03280\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 66.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 1.01763, val_loss: 0.90767\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 67.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.93689, val_loss: 0.85948\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 70.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.87691, val_loss: 0.77854\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 68.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.72052, val_loss: 0.43769\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 69.17it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.42631, val_loss: 0.20224\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 69.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.26190, val_loss: 0.09397\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 69.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.17282, val_loss: 0.06079\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 68.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.12881, val_loss: 0.02600\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 67.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.09225, val_loss: 0.01808\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 65.06it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.07763, val_loss: 0.01069\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 68.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.06313, val_loss: 0.00614\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 67.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.05309, val_loss: 0.00383\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 66.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.04832, val_loss: 0.00399\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 70.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.04199, val_loss: 0.00221\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 64.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.03559, val_loss: 0.00253\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 66.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.02993, val_loss: 0.00191\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 69.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.02842, val_loss: 0.00102\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 71.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.02615, val_loss: 0.00168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 67.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.02490, val_loss: 0.00071\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 67.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.02042, val_loss: 0.00046\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 70.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.01498, val_loss: 0.00053\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 70.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.01445, val_loss: 0.00057\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 69.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.01646, val_loss: 0.00098\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 60.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.01500, val_loss: 0.00033\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 62.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.01418, val_loss: 0.00034\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 67.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.01468, val_loss: 0.00029\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 61.46it/s]"]},{"output_type":"stream","name":"stdout","text":["train_loss: 0.01221, val_loss: 0.00023\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["test_loss = validate(model, data_loaders.test_loader)\n","test_acc = evaluate(model, data_loaders.test_loader)\n","val_acc = evaluate(model, data_loaders.test_loader)\n","train_acc = evaluate(model, data_loaders.train_loader, 20)\n","current_result = f'''train_size: {train_size}, train_loss: {train_loss},\n","                val_loss: {val_loss}, test_loss: {test_loss},\n","                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n","                '''\n","print(current_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ma5l95RJtmV","executionInfo":{"status":"ok","timestamp":1649522424286,"user_tz":240,"elapsed":49081,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"ea58156b-5637-4302-9851-9abb1fc74b31"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["train_size: 7168, train_loss: 0.012206953301626657,\n","                val_loss: 0.0002306888454768341, test_loss: 0.0003604226258175913,\n","                test_acc: 1.0, val_acc: 1.0, train_acc: 1.0\n","                \n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"GPT_Addition.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}