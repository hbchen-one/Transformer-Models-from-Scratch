{"cells":[{"cell_type":"markdown","metadata":{"id":"_gRJme0w5nh7"},"source":["# Train a decoder-only transformer (GPT-like) to do addition\n","\n","I learned a lot from https://github.com/karpathy/minGPT, but I have rewritten all the code based on my own understanding.\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"qjFkasZb5niB","executionInfo":{"status":"ok","timestamp":1649539431932,"user_tz":240,"elapsed":5826,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"outputs":[],"source":["import math\n","from dataclasses import dataclass\n","\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data.dataset import Dataset\n","from tqdm import tqdm\n","\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","source":["## Data processing\n","### Generate an addition dataset"],"metadata":{"collapsed":false,"id":"xDSK1sxiIdfU"}},{"cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["([tensor([15,  4,  9, 10,  7,  8, 13,  1,  2,  7, 14]), tensor([15,  9,  7, 10,  4,  5, 13,  1,  4,  2, 14]), tensor([15,  7, 10,  2,  1, 13,  2,  8, 14]), tensor([15,  6,  6, 10,  7,  4, 13,  1,  4,  0, 14]), tensor([15,  5,  4, 10,  9,  8, 13,  1,  5,  2, 14]), tensor([15,  7,  7, 10,  3,  3, 13,  1,  1,  0, 14]), tensor([15,  4,  0, 10,  2,  5, 13,  6,  5, 14]), tensor([15,  1,  5, 10,  7,  6, 13,  9,  1, 14]), tensor([15,  8,  3, 10,  4,  7, 13,  1,  3,  0, 14]), tensor([15,  2,  0, 10,  4,  9, 13,  6,  9, 14]), tensor([15,  9,  3, 10,  4, 13,  9,  7, 14]), tensor([15,  5, 10,  5, 13,  1,  0, 14]), tensor([15,  4,  2, 10,  6,  0, 13,  1,  0,  2, 14]), tensor([15,  7,  9, 10,  2,  9, 13,  1,  0,  8, 14]), tensor([15,  9, 10,  7,  3, 13,  8,  2, 14]), tensor([15,  9, 10,  8, 13,  1,  7, 14]), tensor([15,  1,  8, 10,  9,  8, 13,  1,  1,  6, 14]), tensor([15,  3,  9, 10,  9,  6, 13,  1,  3,  5, 14]), tensor([15,  1,  5, 10,  6,  9, 13,  8,  4, 14]), tensor([15,  6,  1, 10,  7,  3, 13,  1,  3,  4, 14])], ['49+78=127', '97+45=142', '7+21=28', '66+74=140', '54+98=152', '77+33=110', '40+25=65', '15+76=91', '83+47=130', '20+49=69', '93+4=97', '5+5=10', '42+60=102', '79+29=108', '9+73=82', '9+8=17', '18+98=116', '39+96=135', '15+69=84', '61+73=134'])\n","([tensor([15,  6,  7, 10,  7,  2, 13,  1,  3,  9, 14]), tensor([15,  4,  2, 10,  0,  0, 13,  4,  2, 14]), tensor([15,  8,  7, 10,  4,  2, 13,  1,  2,  9, 14]), tensor([15,  8,  6, 10,  8,  1, 13,  1,  6,  7, 14]), tensor([15,  1,  7, 10,  6,  4, 13,  8,  1, 14]), tensor([15,  4,  7, 10,  1,  5, 13,  6,  2, 14]), tensor([15,  2,  6, 10,  3,  2, 13,  5,  8, 14]), tensor([15,  2,  0, 10,  4,  4, 13,  6,  4, 14]), tensor([15,  8,  4, 10,  1,  7, 13,  1,  0,  1, 14]), tensor([15,  4,  2, 10,  8,  0, 13,  1,  2,  2, 14]), tensor([15,  1,  8, 10,  0,  5, 13,  2,  3, 14]), tensor([15,  3,  2, 10,  2,  9, 13,  6,  1, 14]), tensor([15,  0,  1, 10,  7,  4, 13,  7,  5, 14]), tensor([15,  2,  5, 10,  3,  1, 13,  5,  6, 14]), tensor([15,  8,  6, 10,  6,  3, 13,  1,  4,  9, 14]), tensor([15,  2,  6, 10,  9,  4, 13,  1,  2,  0, 14]), tensor([15,  2,  2, 10,  2,  9, 13,  5,  1, 14]), tensor([15,  5,  5, 10,  3,  5, 13,  9,  0, 14]), tensor([15,  1,  6, 10,  9,  2, 13,  1,  0,  8, 14]), tensor([15,  2,  4, 10,  8,  1, 13,  1,  0,  5, 14])], ['67+72=139', '42+00=42', '87+42=129', '86+81=167', '17+64=81', '47+15=62', '26+32=58', '20+44=64', '84+17=101', '42+80=122', '18+05=23', '32+29=61', '01+74=75', '25+31=56', '86+63=149', '26+94=120', '22+29=51', '55+35=90', '16+92=108', '24+81=105'])\n"]}],"source":["PLUS_SIGN = 10\n","MUL_SIGN  = 11\n","MINUS_SIGN = 12\n","EQUAL_SIGN = 13\n","EOS = 14\n","BOS = 15\n","PAD = 16\n","UNK = 17\n","\n","symbol_to_int_dict = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4,\n","                      \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9,\n","                      \"+\": PLUS_SIGN, \"*\": MUL_SIGN, \"-\": MINUS_SIGN,\n","                      \"=\": EQUAL_SIGN,  \"<EOS>\": EOS, \"<BOS>\": BOS,\n","                      \"<pad>\": PAD, \"??\": UNK\n","                      }\n","\n","int_to_symbol_dict = {y:x for (x,y) in symbol_to_int_dict.items()}\n","vocab_size = len(symbol_to_int_dict)\n","\n","def decode_equation(equation):\n","    '''convert an equation in list format to string format '''\n","    res = \"\".join([str(int_to_symbol_dict.get(x, UNK)) for x in equation.tolist()])\n","    return res.replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\")\n","\n","def encode_equation(equation, max_ndigits, padQ=True):\n","    '''convert an equation(up to the equal sign in it) in string format to a list'''\n","    equal_size_loc = equation.index('=')\n","    plus_size_loc = equation.index('+')\n","    num1 = pad_number(equation[0:plus_size_loc], max_ndigits)\n","    num2 = pad_number(equation[plus_size_loc+1:equal_size_loc], max_ndigits)\n","    new_equation = num1 + \"+\" + num2 + \"=\"\n","    return torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in new_equation]).to(DEVICE)\n","\n","\n","def pad_number(num, max_ndigits)->str:\n","    s = str(num)\n","    while len(s)<max_ndigits:\n","      s = \"0\"+s\n","    return s\n","\n","def create_add_dataset(max_ndigits, dataset_size, padQ=True):\n","    ''' Function for creating an addition dataset.\n","    if padQ=True, pre-padding of 0s will be added on the numbers such that all the \n","    numbers has the same length max_ndigits, for example, with max_ndigits=3,  \n","    32 will be represented 032.\n","    '''\n","    dataset_str = []\n","    for i in range(dataset_size):\n","        num1, num2 = np.random.randint(0, 10**max_ndigits, 2)\n","        ans = num1 + num2\n","        if padQ:\n","            equation = pad_number(num1, max_ndigits) + '+' + pad_number(num2, max_ndigits) + \"=\" + pad_number(ans, max_ndigits)\n","        else:\n","            equation = str(num1) + '+' + str(num2) + \"=\" + str(ans)\n","        dataset_str.append(equation)\n","\n","    dataset = [torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in x]+[EOS])\n","               for x in dataset_str]\n","    return dataset, dataset_str\n","\n","print(create_add_dataset(2,20, padQ=False))\n","print(create_add_dataset(2, 20, padQ=True))"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"JlYks0a55niC","executionInfo":{"status":"ok","timestamp":1649539432076,"user_tz":240,"elapsed":147,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"509fb79d-4024-4dc3-d4cd-070bdfbe4d73"}},{"cell_type":"markdown","source":["### Create dataloders for the train, validation and test sets"],"metadata":{"collapsed":false,"id":"4AaG4J3CIdfW"}},{"cell_type":"code","execution_count":4,"outputs":[],"source":["class TranslationDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","batch_size = 256\n","def pad_sequence(batch):\n","    input_padded = torch.nn.utils.rnn.pad_sequence(batch,\n","                                batch_first=True, padding_value = PAD)\n","    return input_padded\n","\n","@dataclass\n","class DataLoaders:\n","    max_ndigits: int\n","    dataset_size: int\n","    padQ: bool = True\n","    val_loader = None\n","    test_loader = None\n","    train_loader = None\n","\n","    def split_data(self, split=[0.7, 0.1, 0.2]):\n","        if isinstance(split[0], float):\n","            train_size  = round(self.dataset_size*split[0])\n","            val_size = round(self.dataset_size*split[1])\n","            test_size = self.dataset_size - train_size - val_size\n","        elif isinstance(split[0], int):\n","            val_size = split[0]\n","            test_size = split[1]\n","            train_size  = dataset_size - test_size - val_size\n","\n","\n","        dataset, _ = create_add_dataset(self.max_ndigits, self.dataset_size, padQ=self.padQ)\n","        train_set, val_set, test_set = torch.utils.data.random_split(dataset,\n","                                                             [train_size, val_size, test_size],\n","                                                    generator=torch.Generator().manual_seed(42) )\n","\n","        self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n","                                           shuffle=True, collate_fn = pad_sequence)\n","        self.test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n","                                           shuffle=True, collate_fn=pad_sequence)\n","        self.val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n","                                           shuffle=True, collate_fn=pad_sequence)\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"XNDapFsq5niE","executionInfo":{"status":"ok","timestamp":1649539432076,"user_tz":240,"elapsed":2,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["## GPT model\n","Here is my implementation of the GPT model, including the multi-headed self-attention module."],"metadata":{"collapsed":false,"id":"IIjLRLXGIdfX"}},{"cell_type":"code","execution_count":5,"outputs":[],"source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, h, d_model, dropout=0.1):\n","        super(MultiHeadedAttention, self).__init__()\n","        assert d_model % h == 0 # check the h number\n","        self.d_k = d_model//h\n","        self.d_model = d_model\n","        self.h = h\n","        self.WQ = nn.Linear(d_model, d_model)\n","        self.WK = nn.Linear(d_model, d_model)\n","        self.WV = nn.Linear(d_model, d_model)\n","        self.linear = nn.Linear(d_model, d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x_query, x_key, x_value, mask=None):\n","        nbatch = x_query.size(0) # get batch size\n","        # 1) Linear projections to get the multi-head query, key and value\n","        # x_query, x_key, x_value dimension: nbatch * seq_len * d_model\n","        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n","        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        # 2) Attention\n","        # scores has dimensions: nbatch * h * seq_len * seq_len\n","        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_model)\n","        # 3) Mask out padding tokens and future tokens\n","        if mask is not None:\n","            scores = scores.masked_fill(mask, float('-inf'))\n","        # p_atten dimensions: nbatch * h * seq_len * seq_len\n","        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n","        # x dimensions: nbatch * h * seq_len * d_k\n","        x = torch.matmul(p_atten, value)\n","        # x now has dimensions:nbtach * seq_len * d_model\n","        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_model)\n","\n","        return self.linear(x) # final linear layer\n","\n","\n","class ResidualConnection(nn.Module):\n","  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n","  def __init__(self, dim, dropout):\n","      super().__init__()\n","      self.drop = nn.Dropout(dropout)\n","      self.norm = nn.LayerNorm(dim)\n","\n","  def forward(self, x, sublayer):\n","      return x + self.drop(sublayer(self.norm(x)))\n","\n","\n","class Decoder(nn.Module):\n","\n","    def __init__(self, vocab_size, h, d_embed, max_len, N=4, drop_rate=0.1):\n","        super().__init__()\n","        self.embed = nn.Embedding(vocab_size, d_embed)\n","        self.pos_embed = nn.Embedding(max_len, d_embed)\n","        self.dropout = nn.Dropout(drop_rate)\n","        self.decoder_blocks = nn.Sequential(*[DecoderBlock(h, d_embed) for _ in range(N)])\n","        self.norm = nn.LayerNorm(d_embed)\n","        self.linear = nn.Linear(d_embed, vocab_size)\n","\n","    def forward(self, trg, trg_pad_mask):\n","        pos_embedding = self.pos_embed(torch.tensor(range(trg.size(-1))).to(DEVICE))\n","        x = self.embed(trg) + pos_embedding\n","        x = self.dropout(x)\n","        for layer in self.decoder_blocks:\n","            x = layer( x, trg_pad_mask)\n","        x = self.norm(x)\n","        logits = self.linear(x)\n","        return logits\n","\n","\n","class DecoderBlock(nn.Module):\n","    def __init__(self, h, d_embed, dropout=0.1):\n","        super().__init__()\n","        self.atten1 = MultiHeadedAttention(h, d_embed)\n","        self.atten2 = MultiHeadedAttention(h, d_embed)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(d_embed, 4*d_embed),\n","            nn.GELU(),\n","            nn.Linear(4*d_embed, d_embed),\n","            nn.Dropout(dropout)\n","        )\n","        self.residual1 = ResidualConnection(d_embed, dropout)\n","        self.residual2 = ResidualConnection(d_embed, dropout)\n","        self.residual3 = ResidualConnection(d_embed, dropout)\n","\n","    def future_mask(self, seq_len):\n","        '''mask for masking out tokens at future positions'''\n","        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n","        return mask.view(1, 1, seq_len, seq_len)\n","\n","    def forward(self,  decoder_layer_input, decoder_pad_mask):\n","        y = decoder_layer_input\n","        seq_len = y.size(-2)\n","        decoder_mask = torch.logical_or(decoder_pad_mask, self.future_mask(seq_len))\n","        y = self.residual1(y, lambda y: self.atten1(y, y, y, mask=decoder_mask))\n","\n","        return self.residual3(y, self.ffn)\n","\n","class GPT(nn.Module):\n","    def __init__(self, decoder):\n","        super().__init__()\n","        self.decoder = decoder\n","\n","    def forward(self, input, pad_mask):\n","        return self.decoder(input, pad_mask)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"FuNdAglk5niF","executionInfo":{"status":"ok","timestamp":1649539432202,"user_tz":240,"elapsed":128,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["### Let's creat a GPT!"],"metadata":{"collapsed":false,"id":"GsVpY8RnIdfY"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"A_BE7bIS5niG","executionInfo":{"status":"ok","timestamp":1649539435685,"user_tz":240,"elapsed":150,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"outputs":[],"source":["@dataclass\n","class ModelConfig:\n","  d_embed: int\n","  # d_ff is the dimension of the fully-connected layer\n","  d_ff: int\n","  # h is the number of attention head\n","  h: int\n","  N_decoder: int\n","  max_len: int\n","  dropout: float\n","\n","\n","def make_GPT(config):\n","    model = GPT(Decoder(vocab_size, config.h, config.d_embed, config.max_len,\n","                        config.N_decoder)).to(DEVICE)\n","    # initialize model parameters\n","    # it seems that this initialization is very important!\n","    for p in model.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","    return model"]},{"cell_type":"markdown","source":["## Functions for training and input/output processing"],"metadata":{"collapsed":false,"id":"zzrr1eoYIdfY"}},{"cell_type":"code","execution_count":7,"outputs":[],"source":["def make_batch_input(x):\n","        'function for generating model input, target and pad_mask from raw input x'\n","        input = x[:, :-1].to(DEVICE)\n","        equal_sign_loc = [(equation==EQUAL_SIGN).nonzero().item() for equation in x]\n","        target = [torch.cat((torch.tensor([PAD]*equal_sign_loc[i]), x[i][equal_sign_loc[i]+1:])) for i in range(len(x))]\n","        target = torch.cat(target, 0).contiguous().view(-1).to(DEVICE)\n","        pad_mask = (input == PAD).view(input.size(0), 1, 1, input.size(-1))\n","        return input, target, pad_mask"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VO4h4nKG5niH","executionInfo":{"status":"ok","timestamp":1649539437549,"user_tz":240,"elapsed":2,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":8,"outputs":[],"source":["def train_epoch(model, dataloader):\n","    model.train()\n","    grad_norm_clip = 1.0\n","    losses, acc, count = [], 0, 0\n","    num_batches = len(dataloader)\n","    pbar = tqdm(enumerate(dataloader), total=num_batches)\n","    for idx, x  in  pbar:\n","        optimizer.zero_grad()\n","        input, target, pad_mask = make_batch_input(x)\n","        pred = model(input, pad_mask).to(DEVICE)\n","        pred = pred.view(-1, pred.size(-1))\n","        loss = loss_fn(pred, target).to(DEVICE)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n","        optimizer.step()\n","        scheduler.step()\n","        losses.append(loss.item())\n","        # report progress\n","        if idx>0 and idx%50 == 0:\n","            pbar.set_description(f\"ep: {scheduler.last_epoch//num_batches}, train loss={loss.item():.3f},lr={scheduler.get_last_lr()[0]:.5f}\")\n","    return np.mean(losses)\n","\n","def train(model, dataloaders, epochs):\n","    best_val_loss = float('inf')\n","    global early_stop_count\n","    train_size = len(dataloaders.train_loader)*batch_size\n","    for ep in range(epochs):\n","        train_loss = train_epoch(model, dataloaders.train_loader)\n","        val_loss = validate(model, dataloaders.val_loader)\n","        print(f'ep {ep}: train_loss: {train_loss:.5f}, val_loss: {val_loss:.5f}')\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","        else:\n","            if scheduler.last_epoch>2*warmup_steps:\n","                early_stop_count -= 1\n","                if early_stop_count<=0:\n","                    #torch.save(model, f'saved_models/{SRC}_to_{TRG}_train_size_{train_size}_model_size_{model_size}.pt')\n","            #f = open(\"save_model/{SRC}_to_{TRG}_dataset_size_{dataset_size}.txt\", 'w'):\n","            #f.write()\n","                    return train_loss, val_loss\n","    return train_loss, val_loss\n","\n","\n","def validate(model, dataloder):\n","    'function for computing the loss on the validation set'\n","    model.eval()\n","    losses = []\n","    with torch.no_grad():\n","        for i, x in enumerate(dataloder):\n","            input, target, pad_mask = make_batch_input(x)\n","            pred = model(input, pad_mask).to(DEVICE)\n","            pred = pred.view(-1, pred.size(-1))\n","            losses.append(loss_fn(pred, target).item())\n","    return np.mean(losses)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"0dVrqAIW5niH","executionInfo":{"status":"ok","timestamp":1649539438635,"user_tz":240,"elapsed":106,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","source":["@torch.no_grad()\n","def compute_sum(model, x):\n","    'Function for computing the sum of two numbers.'\n","    for i in range(max_ndigits+2):\n","        pad_mask = (x == PAD).view(1, 1, 1, x.size(-1)).to(DEVICE)\n","        logits = model(x, pad_mask)\n","        last_output = logits.argmax(-1)[:,-1].view(1,1)\n","        x = torch.cat((x, last_output), 1).to(DEVICE)\n","        if last_output.item() == EOS:\n","            break\n","    return x[0]\n","\n","def evaluate(model, dataloader, num_batch=None):\n","    '''Function for evaluation the model.\n","    This function take equations, and truncate them up to the equal-sign, and feed them to the\n","    model to get the predictions, compare them with the correct answers, and output the accuracy.\n","    '''\n","    model.eval()\n","    acc, count = 0, 0\n","    num_wrong_to_display = 5\n","    for idx, x in enumerate(dataloader):\n","        for equation in x:\n","            loc_equal_sign = equation.tolist().index(EQUAL_SIGN)\n","            loc_EOS = equation.tolist().index(EOS)\n","            input = equation[0:loc_equal_sign+1].view(1, -1).to(DEVICE)\n","            ans = equation[:loc_EOS+1].tolist()\n","            ans_pred = compute_sum(model, input)\n","            count += 1\n","\n","            if ans == ans_pred.tolist():\n","                acc +=1\n","            else:\n","                if num_wrong_to_display > 0:\n","                    print(f'correct equation: {decode_equation(equation).replace(\"<pad>\",\"\")}')\n","                    print(f'predicted:        {decode_equation(ans_pred)}')\n","                    num_wrong_to_display -= 1\n","        if num_batch and idx>num_batch:\n","            break\n","    return acc/count\n","\n","def what_is(question:str)->str:\n","    'function for computing the sum of two numbers with input in literal string format'\n","    pred = compute_sum(model, encode_equation(question, max_ndigits).view(1,-1))\n","    pred = decode_equation(pred)\n","    pred = pred[pred.index(\"=\")+1:]\n","    return question+pred\n"],"metadata":{"id":"yCQBQ19TVpuc","executionInfo":{"status":"ok","timestamp":1649539441096,"user_tz":240,"elapsed":132,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["## 2-digit addition"],"metadata":{"id":"a7J0GgUrfZ6W"}},{"cell_type":"code","source":["max_ndigits = 2\n","# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n","max_len = 3*max_ndigits + 6\n","config = ModelConfig(d_embed=128, d_ff=256, h=4, N_decoder=2, max_len= max_len,\n","                           dropout=0.1)\n","dataset_size = 10000\n","data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n","data_loaders.split_data(split=[1000, 2000])\n","train_size = len(data_loaders.train_loader)*batch_size\n","model = make_GPT(config)\n","model_size = sum([p.numel() for p in model.parameters()])\n","print(f'model_size: {model_size}, train_set_size: {train_size}')\n","warmup_steps = 3*len(data_loaders.train_loader)\n","# lr first increases in the warmup steps, and then descreases\n","lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n","early_stop_count = 10 # Setting early_stop_count to a large number, that is, I'm not implementing early_stop here\n","\n","train_loss, val_loss = train(model, data_loaders, epochs=30)\n"],"metadata":{"id":"fpBEDpznfmzn","executionInfo":{"status":"ok","timestamp":1649539471895,"user_tz":240,"elapsed":28270,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"aaafde86-29cb-4b3c-9681-0f3e4dbe4bbd"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size: 535570, train_set_size: 7168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 38.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 0: train_loss: 2.08677, val_loss: 1.45922\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 1: train_loss: 1.37419, val_loss: 1.21162\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.86it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 2: train_loss: 1.19457, val_loss: 1.10961\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 3: train_loss: 1.06580, val_loss: 0.90669\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 51.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 4: train_loss: 0.93853, val_loss: 0.84697\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 5: train_loss: 0.88191, val_loss: 0.80651\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 6: train_loss: 0.83542, val_loss: 0.76162\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 7: train_loss: 0.71996, val_loss: 0.49947\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 8: train_loss: 0.51262, val_loss: 0.28390\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 9: train_loss: 0.28996, val_loss: 0.09254\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 10: train_loss: 0.14584, val_loss: 0.04050\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 11: train_loss: 0.08972, val_loss: 0.02177\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 12: train_loss: 0.05284, val_loss: 0.01480\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 13: train_loss: 0.03300, val_loss: 0.01189\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 14: train_loss: 0.02405, val_loss: 0.00869\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 15: train_loss: 0.01790, val_loss: 0.00767\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 16: train_loss: 0.01319, val_loss: 0.00147\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 51.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 17: train_loss: 0.01326, val_loss: 0.00359\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.09it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 18: train_loss: 0.01185, val_loss: 0.00208\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 19: train_loss: 0.00792, val_loss: 0.00277\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 20: train_loss: 0.00556, val_loss: 0.00295\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 52.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 21: train_loss: 0.00670, val_loss: 0.00063\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 22: train_loss: 0.00831, val_loss: 0.00057\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 49.95it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 23: train_loss: 0.00627, val_loss: 0.00050\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 47.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 24: train_loss: 0.00443, val_loss: 0.00095\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 25: train_loss: 0.00398, val_loss: 0.00024\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 26: train_loss: 0.00273, val_loss: 0.00004\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 50.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 27: train_loss: 0.00409, val_loss: 0.00176\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 28: train_loss: 0.00368, val_loss: 0.00007\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28/28 [00:00<00:00, 48.43it/s]"]},{"output_type":"stream","name":"stdout","text":["ep 29: train_loss: 0.00388, val_loss: 0.00079\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["test_loss = validate(model, data_loaders.test_loader)\n","print('training set examples the model gives an incorrect result:')\n","train_acc = evaluate(model, data_loaders.train_loader, 20)\n","print('validataion set examples the model gives an incorrect result:')\n","val_acc = evaluate(model, data_loaders.test_loader)\n","print('test set examples the model gives an incorrect result:')\n","test_acc = evaluate(model, data_loaders.test_loader)\n","current_result = f'''train_size: {train_size}, train_loss: {train_loss},\n","                val_loss: {val_loss}, test_loss: {test_loss},\n","                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n","                '''\n","print(current_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_ma5l95RJtmV","executionInfo":{"status":"ok","timestamp":1649539548226,"user_tz":240,"elapsed":76339,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"ae5e4d67-30de-41e7-d57d-7022a3ceb3b5"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["training set examples the model gives an incorrect result:\n","correct equation: 09+09=18\n","predicted:        09+09=16\n","correct equation: 19+00=19\n","predicted:        19+00=10\n","correct equation: 09+10=19\n","predicted:        09+10=109\n","validataion set examples the model gives an incorrect result:\n","correct equation: 19+00=19\n","predicted:        19+00=10\n","test set examples the model gives an incorrect result:\n","correct equation: 19+00=19\n","predicted:        19+00=10\n","train_size: 7168, train_loss: 0.003877029294796687,\n","                val_loss: 0.0007883256266723038, test_loss: 0.0004133981838094769,\n","                test_acc: 0.9995, val_acc: 0.9995, train_acc: 0.9994673295454546\n","                \n"]}]},{"cell_type":"markdown","source":["## 5-digit addition \n","<!-- and scaling laws\n","For 5-digit addition, there are 10<sup>10</sup> possible data points, so we will have enough data to study the scaling laws. For example, we can study how the performance of the model (with fixed number of parameters) improves as we increase the training set size.   -->"],"metadata":{"id":"l2-A-cu8fdNV"}},{"cell_type":"code","source":["max_ndigits = 5\n","# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n","max_len = 3*max_ndigits + 6\n","config = ModelConfig(d_embed=128, d_ff=256, h=4, N_decoder=2, max_len= max_len,\n","                           dropout=0.1)\n","\n","dataset_size = 100000\n","data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n","data_loaders.split_data(split=[10000, 20000])\n","train_size = len(data_loaders.train_loader)*batch_size\n","model = make_GPT(config)\n","model_size = sum([p.numel() for p in model.parameters()])\n","print(f'model_size: {model_size}, train_set_size: {train_size}')\n","warmup_steps = 3*len(data_loaders.train_loader)\n","# lr first increases in the warmup steps, and then descreases\n","lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n","early_stop_count = 10 # Setting early_stop_count to a large number, that is, I'm not implementing early_stop here\n","\n","train_loss, val_loss = train(model, data_loaders, epochs=30)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XhwiqB5xfd6J","executionInfo":{"status":"ok","timestamp":1649543510017,"user_tz":240,"elapsed":210172,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"9fc0802c-8f8b-4035-d2dc-215b8e522921"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size: 536722, train_set_size: 70144\n"]},{"output_type":"stream","name":"stderr","text":["ep: 0, train loss=1.814,lr=0.00019: 100%|██████████| 274/274 [00:06<00:00, 42.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 0: train_loss: 2.18202, val_loss: 1.75309\n"]},{"output_type":"stream","name":"stderr","text":["ep: 1, train loss=1.580,lr=0.00039: 100%|██████████| 274/274 [00:06<00:00, 42.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 1: train_loss: 1.67661, val_loss: 1.46803\n"]},{"output_type":"stream","name":"stderr","text":["ep: 2, train loss=0.869,lr=0.00060: 100%|██████████| 274/274 [00:06<00:00, 42.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 2: train_loss: 1.11583, val_loss: 0.77282\n"]},{"output_type":"stream","name":"stderr","text":["ep: 3, train loss=0.425,lr=0.00054: 100%|██████████| 274/274 [00:06<00:00, 42.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 3: train_loss: 0.62263, val_loss: 0.28733\n"]},{"output_type":"stream","name":"stderr","text":["ep: 4, train loss=0.265,lr=0.00048: 100%|██████████| 274/274 [00:06<00:00, 42.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 4: train_loss: 0.31493, val_loss: 0.21190\n"]},{"output_type":"stream","name":"stderr","text":["ep: 5, train loss=0.228,lr=0.00044: 100%|██████████| 274/274 [00:06<00:00, 42.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 5: train_loss: 0.24592, val_loss: 0.18460\n"]},{"output_type":"stream","name":"stderr","text":["ep: 6, train loss=0.214,lr=0.00041: 100%|██████████| 274/274 [00:06<00:00, 42.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 6: train_loss: 0.20722, val_loss: 0.14593\n"]},{"output_type":"stream","name":"stderr","text":["ep: 7, train loss=0.141,lr=0.00038: 100%|██████████| 274/274 [00:06<00:00, 42.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 7: train_loss: 0.17520, val_loss: 0.11357\n"]},{"output_type":"stream","name":"stderr","text":["ep: 8, train loss=0.121,lr=0.00036: 100%|██████████| 274/274 [00:06<00:00, 42.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 8: train_loss: 0.14217, val_loss: 0.08053\n"]},{"output_type":"stream","name":"stderr","text":["ep: 9, train loss=0.097,lr=0.00034: 100%|██████████| 274/274 [00:06<00:00, 41.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 9: train_loss: 0.11092, val_loss: 0.04565\n"]},{"output_type":"stream","name":"stderr","text":["ep: 10, train loss=0.074,lr=0.00032: 100%|██████████| 274/274 [00:06<00:00, 42.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 10: train_loss: 0.08129, val_loss: 0.02878\n"]},{"output_type":"stream","name":"stderr","text":["ep: 11, train loss=0.055,lr=0.00031: 100%|██████████| 274/274 [00:06<00:00, 41.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 11: train_loss: 0.06424, val_loss: 0.02101\n"]},{"output_type":"stream","name":"stderr","text":["ep: 12, train loss=0.043,lr=0.00030: 100%|██████████| 274/274 [00:06<00:00, 41.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 12: train_loss: 0.05352, val_loss: 0.01927\n"]},{"output_type":"stream","name":"stderr","text":["ep: 13, train loss=0.039,lr=0.00029: 100%|██████████| 274/274 [00:06<00:00, 41.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 13: train_loss: 0.04568, val_loss: 0.01477\n"]},{"output_type":"stream","name":"stderr","text":["ep: 14, train loss=0.030,lr=0.00028: 100%|██████████| 274/274 [00:06<00:00, 42.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 14: train_loss: 0.03856, val_loss: 0.01376\n"]},{"output_type":"stream","name":"stderr","text":["ep: 15, train loss=0.047,lr=0.00027: 100%|██████████| 274/274 [00:06<00:00, 42.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 15: train_loss: 0.03354, val_loss: 0.01147\n"]},{"output_type":"stream","name":"stderr","text":["ep: 16, train loss=0.043,lr=0.00026: 100%|██████████| 274/274 [00:06<00:00, 42.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 16: train_loss: 0.02981, val_loss: 0.01097\n"]},{"output_type":"stream","name":"stderr","text":["ep: 17, train loss=0.034,lr=0.00025: 100%|██████████| 274/274 [00:06<00:00, 42.57it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 17: train_loss: 0.02661, val_loss: 0.00887\n"]},{"output_type":"stream","name":"stderr","text":["ep: 18, train loss=0.030,lr=0.00025: 100%|██████████| 274/274 [00:06<00:00, 42.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 18: train_loss: 0.02475, val_loss: 0.00821\n"]},{"output_type":"stream","name":"stderr","text":["ep: 19, train loss=0.018,lr=0.00024: 100%|██████████| 274/274 [00:06<00:00, 42.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 19: train_loss: 0.02194, val_loss: 0.00830\n"]},{"output_type":"stream","name":"stderr","text":["ep: 20, train loss=0.021,lr=0.00023: 100%|██████████| 274/274 [00:06<00:00, 42.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 20: train_loss: 0.02112, val_loss: 0.00789\n"]},{"output_type":"stream","name":"stderr","text":["ep: 21, train loss=0.024,lr=0.00023: 100%|██████████| 274/274 [00:06<00:00, 42.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 21: train_loss: 0.01965, val_loss: 0.00774\n"]},{"output_type":"stream","name":"stderr","text":["ep: 22, train loss=0.016,lr=0.00022: 100%|██████████| 274/274 [00:06<00:00, 42.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 22: train_loss: 0.01800, val_loss: 0.00703\n"]},{"output_type":"stream","name":"stderr","text":["ep: 23, train loss=0.015,lr=0.00022: 100%|██████████| 274/274 [00:06<00:00, 42.89it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 23: train_loss: 0.01712, val_loss: 0.00635\n"]},{"output_type":"stream","name":"stderr","text":["ep: 24, train loss=0.015,lr=0.00021: 100%|██████████| 274/274 [00:06<00:00, 42.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 24: train_loss: 0.01637, val_loss: 0.00637\n"]},{"output_type":"stream","name":"stderr","text":["ep: 25, train loss=0.018,lr=0.00021: 100%|██████████| 274/274 [00:06<00:00, 42.74it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 25: train_loss: 0.01552, val_loss: 0.00598\n"]},{"output_type":"stream","name":"stderr","text":["ep: 26, train loss=0.020,lr=0.00021: 100%|██████████| 274/274 [00:06<00:00, 41.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 26: train_loss: 0.01490, val_loss: 0.00619\n"]},{"output_type":"stream","name":"stderr","text":["ep: 27, train loss=0.018,lr=0.00020: 100%|██████████| 274/274 [00:06<00:00, 42.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 27: train_loss: 0.01415, val_loss: 0.00571\n"]},{"output_type":"stream","name":"stderr","text":["ep: 28, train loss=0.018,lr=0.00020: 100%|██████████| 274/274 [00:06<00:00, 41.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 28: train_loss: 0.01363, val_loss: 0.00689\n"]},{"output_type":"stream","name":"stderr","text":["ep: 29, train loss=0.024,lr=0.00020: 100%|██████████| 274/274 [00:06<00:00, 42.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 29: train_loss: 0.01355, val_loss: 0.00567\n"]}]},{"cell_type":"code","source":["test_loss = validate(model, data_loaders.test_loader)\n","print('training set examples the model gives an incorrect result:')\n","train_acc = evaluate(model, data_loaders.train_loader, 20)\n","print('validataion set examples the model gives an incorrect result:')\n","val_acc = evaluate(model, data_loaders.test_loader)\n","print('test set examples the model gives an incorrect result:')\n","test_acc = evaluate(model, data_loaders.test_loader)\n","current_result = f'''train_size: {train_size}, train_loss: {train_loss},\n","                val_loss: {val_loss}, test_loss: {test_loss},\n","                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n","                '''\n","print(current_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeCO8-I2g6DF","executionInfo":{"status":"ok","timestamp":1649544171072,"user_tz":240,"elapsed":661064,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"671ca4eb-a846-419b-b5f2-b92da4e1fe6a"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["training set examples the model gives an incorrect result:\n","correct equation: 36244+68755=104999\n","predicted:        36244+68755=105999\n","correct equation: 13653+00497=14150\n","predicted:        13653+00497=14050\n","correct equation: 50263+13737=64000\n","predicted:        50263+13737=64900\n","correct equation: 33117+04884=38001\n","predicted:        33117+04884=38901\n","correct equation: 04469+06649=11118\n","predicted:        04469+06649=11018\n","validataion set examples the model gives an incorrect result:\n","correct equation: 22566+52033=74599\n","predicted:        22566+52033=74699\n","correct equation: 17208+42391=59599\n","predicted:        17208+42391=59699\n","correct equation: 11594+01964=13558\n","predicted:        11594+01964=13458\n","correct equation: 64352+20748=85100\n","predicted:        64352+20748=85000\n","correct equation: 05543+10259=15802\n","predicted:        05543+10259=15702\n","test set examples the model gives an incorrect result:\n","correct equation: 42114+48986=91100\n","predicted:        42114+48986=91000\n","correct equation: 07537+10087=17624\n","predicted:        07537+10087=17524\n","correct equation: 13749+00996=14745\n","predicted:        13749+00996=14735\n","correct equation: 00385+07918=08303\n","predicted:        00385+07918=08203\n","correct equation: 12205+00558=12763\n","predicted:        12205+00558=12773\n","train_size: 70144, train_loss: 0.013546454322517571,\n","                val_loss: 0.005666703291808517, test_loss: 0.0055890035545866044,\n","                test_acc: 0.9843, val_acc: 0.9843, train_acc: 0.9889914772727273\n","                \n"]}]},{"cell_type":"markdown","source":["# 10-digit addition"],"metadata":{"id":"F-Rpw3VZrDv-"}},{"cell_type":"code","source":["max_ndigits = 10\n","# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n","max_len = 3*max_ndigits + 6\n","config = ModelConfig(d_embed=128, d_ff=256, h=4, N_decoder=2, max_len= max_len,\n","                           dropout=0.1)\n","\n","dataset_size = 100000\n","data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n","data_loaders.split_data(split=[10000, 20000])\n","train_size = len(data_loaders.train_loader)*batch_size\n","model = make_GPT(config)\n","model_size = sum([p.numel() for p in model.parameters()])\n","print(f'model_size: {model_size}, train_set_size: {train_size}')\n","warmup_steps = 3*len(data_loaders.train_loader)\n","# lr first increases in the warmup steps, and then descreases\n","lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n","early_stop_count = 10 # Setting early_stop_count to a large number, that is, I'm not implementing early_stop here\n","\n","train_loss, val_loss = train(model, data_loaders, epochs=30)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MxqeGxzCmcdN","executionInfo":{"status":"ok","timestamp":1649529403592,"user_tz":240,"elapsed":217617,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"c3a17dbf-9a3e-4273-9e4b-034d3412962d"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size: 538642, train_set_size: 70144\n"]},{"output_type":"stream","name":"stderr","text":["ep: 0, train loss=2.071,lr=0.00019: 100%|██████████| 274/274 [00:06<00:00, 40.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 0: train_loss: 2.39638, val_loss: 2.03156\n"]},{"output_type":"stream","name":"stderr","text":["ep: 1, train loss=1.918,lr=0.00039: 100%|██████████| 274/274 [00:06<00:00, 40.83it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 1: train_loss: 1.98073, val_loss: 1.87417\n"]},{"output_type":"stream","name":"stderr","text":["ep: 2, train loss=1.859,lr=0.00060: 100%|██████████| 274/274 [00:06<00:00, 40.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 2: train_loss: 1.86913, val_loss: 1.82903\n"]},{"output_type":"stream","name":"stderr","text":["ep: 3, train loss=1.295,lr=0.00054: 100%|██████████| 274/274 [00:06<00:00, 40.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 3: train_loss: 1.55404, val_loss: 1.20452\n"]},{"output_type":"stream","name":"stderr","text":["ep: 4, train loss=0.885,lr=0.00048: 100%|██████████| 274/274 [00:06<00:00, 40.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 4: train_loss: 1.00704, val_loss: 0.76884\n"]},{"output_type":"stream","name":"stderr","text":["ep: 5, train loss=0.599,lr=0.00044: 100%|██████████| 274/274 [00:06<00:00, 39.96it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 5: train_loss: 0.71838, val_loss: 0.45213\n"]},{"output_type":"stream","name":"stderr","text":["ep: 6, train loss=0.347,lr=0.00041: 100%|██████████| 274/274 [00:06<00:00, 40.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 6: train_loss: 0.43668, val_loss: 0.22178\n"]},{"output_type":"stream","name":"stderr","text":["ep: 7, train loss=0.256,lr=0.00038: 100%|██████████| 274/274 [00:06<00:00, 40.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 7: train_loss: 0.28587, val_loss: 0.14779\n"]},{"output_type":"stream","name":"stderr","text":["ep: 8, train loss=0.186,lr=0.00036: 100%|██████████| 274/274 [00:06<00:00, 40.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 8: train_loss: 0.21654, val_loss: 0.11472\n"]},{"output_type":"stream","name":"stderr","text":["ep: 9, train loss=0.172,lr=0.00034: 100%|██████████| 274/274 [00:06<00:00, 40.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 9: train_loss: 0.17819, val_loss: 0.09592\n"]},{"output_type":"stream","name":"stderr","text":["ep: 10, train loss=0.135,lr=0.00032: 100%|██████████| 274/274 [00:06<00:00, 40.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 10: train_loss: 0.15577, val_loss: 0.07628\n"]},{"output_type":"stream","name":"stderr","text":["ep: 11, train loss=0.127,lr=0.00031: 100%|██████████| 274/274 [00:06<00:00, 40.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 11: train_loss: 0.13799, val_loss: 0.06478\n"]},{"output_type":"stream","name":"stderr","text":["ep: 12, train loss=0.104,lr=0.00030: 100%|██████████| 274/274 [00:06<00:00, 40.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 12: train_loss: 0.12080, val_loss: 0.05944\n"]},{"output_type":"stream","name":"stderr","text":["ep: 13, train loss=0.094,lr=0.00029: 100%|██████████| 274/274 [00:06<00:00, 40.75it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 13: train_loss: 0.10662, val_loss: 0.04405\n"]},{"output_type":"stream","name":"stderr","text":["ep: 14, train loss=0.079,lr=0.00028: 100%|██████████| 274/274 [00:06<00:00, 40.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 14: train_loss: 0.09135, val_loss: 0.02853\n"]},{"output_type":"stream","name":"stderr","text":["ep: 15, train loss=0.068,lr=0.00027: 100%|██████████| 274/274 [00:06<00:00, 40.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 15: train_loss: 0.07558, val_loss: 0.02282\n"]},{"output_type":"stream","name":"stderr","text":["ep: 16, train loss=0.055,lr=0.00026: 100%|██████████| 274/274 [00:06<00:00, 40.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 16: train_loss: 0.06361, val_loss: 0.01646\n"]},{"output_type":"stream","name":"stderr","text":["ep: 17, train loss=0.061,lr=0.00025: 100%|██████████| 274/274 [00:06<00:00, 40.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 17: train_loss: 0.05339, val_loss: 0.01214\n"]},{"output_type":"stream","name":"stderr","text":["ep: 18, train loss=0.033,lr=0.00025: 100%|██████████| 274/274 [00:06<00:00, 40.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 18: train_loss: 0.04383, val_loss: 0.00939\n"]},{"output_type":"stream","name":"stderr","text":["ep: 19, train loss=0.034,lr=0.00024: 100%|██████████| 274/274 [00:06<00:00, 40.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 19: train_loss: 0.03760, val_loss: 0.00838\n"]},{"output_type":"stream","name":"stderr","text":["ep: 20, train loss=0.029,lr=0.00023: 100%|██████████| 274/274 [00:06<00:00, 40.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 20: train_loss: 0.03244, val_loss: 0.00670\n"]},{"output_type":"stream","name":"stderr","text":["ep: 21, train loss=0.024,lr=0.00023: 100%|██████████| 274/274 [00:06<00:00, 40.80it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 21: train_loss: 0.02837, val_loss: 0.00551\n"]},{"output_type":"stream","name":"stderr","text":["ep: 22, train loss=0.020,lr=0.00022: 100%|██████████| 274/274 [00:06<00:00, 40.87it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 22: train_loss: 0.02580, val_loss: 0.00462\n"]},{"output_type":"stream","name":"stderr","text":["ep: 23, train loss=0.020,lr=0.00022: 100%|██████████| 274/274 [00:06<00:00, 40.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 23: train_loss: 0.02276, val_loss: 0.00408\n"]},{"output_type":"stream","name":"stderr","text":["ep: 24, train loss=0.012,lr=0.00021: 100%|██████████| 274/274 [00:06<00:00, 40.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 24: train_loss: 0.02092, val_loss: 0.00346\n"]},{"output_type":"stream","name":"stderr","text":["ep: 25, train loss=0.020,lr=0.00021: 100%|██████████| 274/274 [00:06<00:00, 40.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 25: train_loss: 0.01939, val_loss: 0.00361\n"]},{"output_type":"stream","name":"stderr","text":["ep: 26, train loss=0.017,lr=0.00021: 100%|██████████| 274/274 [00:06<00:00, 40.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 26: train_loss: 0.01773, val_loss: 0.00292\n"]},{"output_type":"stream","name":"stderr","text":["ep: 27, train loss=0.020,lr=0.00020: 100%|██████████| 274/274 [00:06<00:00, 40.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 27: train_loss: 0.01665, val_loss: 0.00288\n"]},{"output_type":"stream","name":"stderr","text":["ep: 28, train loss=0.018,lr=0.00020: 100%|██████████| 274/274 [00:06<00:00, 40.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 28: train_loss: 0.01523, val_loss: 0.00296\n"]},{"output_type":"stream","name":"stderr","text":["ep: 29, train loss=0.013,lr=0.00020: 100%|██████████| 274/274 [00:06<00:00, 40.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 29: train_loss: 0.01442, val_loss: 0.00251\n"]}]},{"cell_type":"code","source":["test_loss = validate(model, data_loaders.test_loader)\n","print('training set examples the model gives an incorrect result:')\n","train_acc = evaluate(model, data_loaders.train_loader, 20)\n","print('validataion set examples the model gives an incorrect result:')\n","val_acc = evaluate(model, data_loaders.test_loader)\n","print('test set examples the model gives an incorrect result:')\n","test_acc = evaluate(model, data_loaders.test_loader)\n","current_result = f'''train_size: {train_size}, train_loss: {train_loss},\n","                val_loss: {val_loss}, test_loss: {test_loss},\n","                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n","                '''\n","print(current_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Xe2aR9BmeSE","executionInfo":{"status":"ok","timestamp":1649530518558,"user_tz":240,"elapsed":728360,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"4fdb126e-910d-4296-f387-d248345a5660"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["training set examples the model gives an incorrect result:\n","correct equation: 7468304691+0498295053=7966599744\n","predicted:        7468304691+0498295053=7966699744\n","correct equation: 1590708383+0049128964=1639837347\n","predicted:        1590708383+0049128964=1649837347\n","correct equation: 5194315098+0451784052=5646099150\n","predicted:        5194315098+0451784052=5646199150\n","correct equation: 2108145275+5358904716=7467049991\n","predicted:        2108145275+5358904716=7467050991\n","correct equation: 3729454603+4687952393=8417406996\n","predicted:        3729454603+4687952393=8417407996\n","validataion set examples the model gives an incorrect result:\n","correct equation: 5312000192+0444699376=5756699568\n","predicted:        5312000192+0444699376=5756799568\n","correct equation: 6904736627+4050463343=10955199970\n","predicted:        6904736627+4050463343=10955299970\n","correct equation: 0334270341+7341929505=7676199846\n","predicted:        0334270341+7341929505=7676299846\n","correct equation: 3115063951+2261932871=5376996822\n","predicted:        3115063951+2261932871=5377996822\n","correct equation: 1710888046+7997311113=9708199159\n","predicted:        1710888046+7997311113=9708299159\n","test set examples the model gives an incorrect result:\n","correct equation: 7488258718+6601841180=14090099898\n","predicted:        7488258718+6601841180=14090199898\n","correct equation: 1270182381+0110845714=1381028095\n","predicted:        1270182381+0110845714=1381028195\n","correct equation: 2116750553+5220241888=7336992441\n","predicted:        2116750553+5220241888=7337992441\n","correct equation: 4842817240+2119151292=6961968532\n","predicted:        4842817240+2119151292=7961968532\n","correct equation: 0897952009+0438833391=1336785400\n","predicted:        0897952009+0438833391=1336785300\n","train_size: 70144, train_loss: 0.014424149635295471,\n","                val_loss: 0.0025095835009778964, test_loss: 0.002196088347796209,\n","                test_acc: 0.9908, val_acc: 0.9908, train_acc: 0.9918323863636364\n","                \n"]}]},{"cell_type":"markdown","source":["# 30-digit addition"],"metadata":{"id":"pDcry9eArLx6"}},{"cell_type":"code","source":["max_ndigits = 18\n","# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n","max_len = 3*max_ndigits + 6\n","config = ModelConfig(d_embed=128, d_ff=256, h=4, N_decoder=2, max_len= max_len,\n","                           dropout=0.1)\n","\n","dataset_size = 100000\n","data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n","data_loaders.split_data(split=[10000, 20000])\n","train_size = len(data_loaders.train_loader)*batch_size\n","model = make_GPT(config)\n","model_size = sum([p.numel() for p in model.parameters()])\n","print(f'model_size: {model_size}, train_set_size: {train_size}')\n","warmup_steps = 3*len(data_loaders.train_loader)\n","# lr first increases in the warmup steps, and then descreases\n","lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n","early_stop_count = 10 # Setting early_stop_count to a large number, that is, I'm not implementing early_stop here\n","\n","train_loss, val_loss = train(model, data_loaders, epochs=30)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-8QY2kMrN5o","executionInfo":{"status":"ok","timestamp":1649531160782,"user_tz":240,"elapsed":289778,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"219ec39f-ec2c-4f2a-ca29-972a71c40da8"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size: 541714, train_set_size: 70144\n"]},{"output_type":"stream","name":"stderr","text":["ep: 0, train loss=2.207,lr=0.00019: 100%|██████████| 274/274 [00:09<00:00, 30.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 0: train_loss: 2.47354, val_loss: 2.17260\n"]},{"output_type":"stream","name":"stderr","text":["ep: 1, train loss=2.100,lr=0.00039: 100%|██████████| 274/274 [00:09<00:00, 30.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 1: train_loss: 2.13935, val_loss: 2.08373\n"]},{"output_type":"stream","name":"stderr","text":["ep: 2, train loss=2.047,lr=0.00060: 100%|██████████| 274/274 [00:08<00:00, 30.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 2: train_loss: 2.06390, val_loss: 2.03688\n"]},{"output_type":"stream","name":"stderr","text":["ep: 3, train loss=1.969,lr=0.00054: 100%|██████████| 274/274 [00:09<00:00, 30.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 3: train_loss: 2.01141, val_loss: 1.94423\n"]},{"output_type":"stream","name":"stderr","text":["ep: 4, train loss=1.929,lr=0.00048: 100%|██████████| 274/274 [00:09<00:00, 30.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 4: train_loss: 1.94031, val_loss: 1.90746\n"]},{"output_type":"stream","name":"stderr","text":["ep: 5, train loss=1.771,lr=0.00044: 100%|██████████| 274/274 [00:09<00:00, 30.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 5: train_loss: 1.86322, val_loss: 1.62660\n"]},{"output_type":"stream","name":"stderr","text":["ep: 6, train loss=1.424,lr=0.00041: 100%|██████████| 274/274 [00:09<00:00, 30.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 6: train_loss: 1.52318, val_loss: 1.35436\n"]},{"output_type":"stream","name":"stderr","text":["ep: 7, train loss=0.992,lr=0.00038: 100%|██████████| 274/274 [00:08<00:00, 30.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 7: train_loss: 1.16957, val_loss: 0.90167\n"]},{"output_type":"stream","name":"stderr","text":["ep: 8, train loss=0.813,lr=0.00036: 100%|██████████| 274/274 [00:08<00:00, 30.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 8: train_loss: 0.89238, val_loss: 0.65972\n"]},{"output_type":"stream","name":"stderr","text":["ep: 9, train loss=0.709,lr=0.00034: 100%|██████████| 274/274 [00:09<00:00, 30.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 9: train_loss: 0.73878, val_loss: 0.59970\n"]},{"output_type":"stream","name":"stderr","text":["ep: 10, train loss=0.663,lr=0.00032: 100%|██████████| 274/274 [00:08<00:00, 30.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 10: train_loss: 0.67888, val_loss: 0.56699\n"]},{"output_type":"stream","name":"stderr","text":["ep: 11, train loss=0.641,lr=0.00031: 100%|██████████| 274/274 [00:08<00:00, 30.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 11: train_loss: 0.64554, val_loss: 0.55776\n"]},{"output_type":"stream","name":"stderr","text":["ep: 12, train loss=0.615,lr=0.00030: 100%|██████████| 274/274 [00:09<00:00, 30.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 12: train_loss: 0.62287, val_loss: 0.55029\n"]},{"output_type":"stream","name":"stderr","text":["ep: 13, train loss=0.613,lr=0.00029: 100%|██████████| 274/274 [00:09<00:00, 30.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 13: train_loss: 0.60661, val_loss: 0.54972\n"]},{"output_type":"stream","name":"stderr","text":["ep: 14, train loss=0.579,lr=0.00028: 100%|██████████| 274/274 [00:09<00:00, 30.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 14: train_loss: 0.59472, val_loss: 0.52087\n"]},{"output_type":"stream","name":"stderr","text":["ep: 15, train loss=0.519,lr=0.00027: 100%|██████████| 274/274 [00:09<00:00, 30.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 15: train_loss: 0.56482, val_loss: 0.45223\n"]},{"output_type":"stream","name":"stderr","text":["ep: 16, train loss=0.487,lr=0.00026: 100%|██████████| 274/274 [00:09<00:00, 30.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 16: train_loss: 0.49745, val_loss: 0.42000\n"]},{"output_type":"stream","name":"stderr","text":["ep: 17, train loss=0.453,lr=0.00025: 100%|██████████| 274/274 [00:09<00:00, 30.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 17: train_loss: 0.47427, val_loss: 0.40193\n"]},{"output_type":"stream","name":"stderr","text":["ep: 18, train loss=0.453,lr=0.00025: 100%|██████████| 274/274 [00:08<00:00, 30.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 18: train_loss: 0.45598, val_loss: 0.39469\n"]},{"output_type":"stream","name":"stderr","text":["ep: 19, train loss=0.427,lr=0.00024: 100%|██████████| 274/274 [00:09<00:00, 30.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 19: train_loss: 0.44702, val_loss: 0.38294\n"]},{"output_type":"stream","name":"stderr","text":["ep: 20, train loss=0.366,lr=0.00023: 100%|██████████| 274/274 [00:08<00:00, 30.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 20: train_loss: 0.38175, val_loss: 0.30720\n"]},{"output_type":"stream","name":"stderr","text":["ep: 21, train loss=0.337,lr=0.00023: 100%|██████████| 274/274 [00:08<00:00, 30.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 21: train_loss: 0.34885, val_loss: 0.27962\n"]},{"output_type":"stream","name":"stderr","text":["ep: 22, train loss=0.309,lr=0.00022: 100%|██████████| 274/274 [00:09<00:00, 30.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 22: train_loss: 0.32068, val_loss: 0.26575\n"]},{"output_type":"stream","name":"stderr","text":["ep: 23, train loss=0.311,lr=0.00022: 100%|██████████| 274/274 [00:09<00:00, 30.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 23: train_loss: 0.30826, val_loss: 0.25557\n"]},{"output_type":"stream","name":"stderr","text":["ep: 24, train loss=0.294,lr=0.00021: 100%|██████████| 274/274 [00:08<00:00, 30.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 24: train_loss: 0.30131, val_loss: 0.25781\n"]},{"output_type":"stream","name":"stderr","text":["ep: 25, train loss=0.288,lr=0.00021: 100%|██████████| 274/274 [00:08<00:00, 30.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 25: train_loss: 0.29493, val_loss: 0.24835\n"]},{"output_type":"stream","name":"stderr","text":["ep: 26, train loss=0.299,lr=0.00021: 100%|██████████| 274/274 [00:08<00:00, 30.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 26: train_loss: 0.28961, val_loss: 0.24591\n"]},{"output_type":"stream","name":"stderr","text":["ep: 27, train loss=0.286,lr=0.00020: 100%|██████████| 274/274 [00:09<00:00, 30.39it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 27: train_loss: 0.28261, val_loss: 0.23941\n"]},{"output_type":"stream","name":"stderr","text":["ep: 28, train loss=0.271,lr=0.00020: 100%|██████████| 274/274 [00:08<00:00, 30.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 28: train_loss: 0.27736, val_loss: 0.23904\n"]},{"output_type":"stream","name":"stderr","text":["ep: 29, train loss=0.269,lr=0.00020: 100%|██████████| 274/274 [00:09<00:00, 30.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep 29: train_loss: 0.27249, val_loss: 0.22960\n"]}]},{"cell_type":"code","source":["test_loss = validate(model, data_loaders.test_loader)\n","print('training set examples the model gives an incorrect result:')\n","train_acc = evaluate(model, data_loaders.train_loader, 20)\n","print('validataion set examples the model gives an incorrect result:')\n","val_acc = evaluate(model, data_loaders.test_loader)\n","print('test set examples the model gives an incorrect result:')\n","test_acc = evaluate(model, data_loaders.test_loader)\n","current_result = f'''train_size: {train_size}, train_loss: {train_loss},\n","                val_loss: {val_loss}, test_loss: {test_loss},\n","                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n","                '''\n","print(current_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"usZg_i57ra9g","executionInfo":{"status":"ok","timestamp":1649532400535,"user_tz":240,"elapsed":680195,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"3b0af627-323a-4e8d-8ee2-1c49c756be6b"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["training set examples the model gives an incorrect result:\n","correct equation: 263630793199099197+351592269863556326=615223063062655523\n","predicted:        263630793199099197+351592269863556326=615222063062655523\n","correct equation: 042020288389593022+134950025848508040=176970314238101062\n","predicted:        042020288389593022+134950025848508040=176960314238101062\n","correct equation: 462120657002111403+236865303396658690=698985960398770093\n","predicted:        462120657002111403+236865303396658690=698985950398770093\n","correct equation: 672081886656355429+704570885523208255=1376652772179563684\n","predicted:        672081886656355429+704570885523208255=1376657722179563584\n","correct equation: 100762936102229398+485330265878666867=586093201980896265\n","predicted:        100762936102229398+485330265878666867=586093201971896265\n","validataion set examples the model gives an incorrect result:\n","correct equation: 468935121562377068+621520603948631902=1090455725511008970\n","predicted:        468935121562377068+621520603948631902=1090455755511008170\n","correct equation: 561607557257673014+990485687623417408=1552093244881090422\n","predicted:        561607557257673014+990485687623417408=1552091254881090122\n","correct equation: 648417920479962273+863327336025233699=1511745256505195972\n","predicted:        648417920479962273+863327336025233699=1511745256505195172\n","correct equation: 346262102775280563+984832623597581606=1331094726372862169\n","predicted:        346262102775280563+984832623597581606=1331095726372862669\n","correct equation: 500636966371308168+861101366025908830=1361738332397216998\n","predicted:        500636966371308168+861101366025908830=1361735352397216098\n","test set examples the model gives an incorrect result:\n","correct equation: 858770824081685938+617705085644529870=1476475909726215808\n","predicted:        858770824081685938+617705085644529870=1476471959726215108\n","correct equation: 020484675006899102+906413668834404457=926898343841303559\n","predicted:        020484675006899102+906413668834404457=926898343831303559\n","correct equation: 528740003418345433+083961608994651140=612701612412996573\n","predicted:        528740003418345433+083961608994651140=612701602413996573\n","correct equation: 984840271857566407+777435732795829242=1762276004653395649\n","predicted:        984840271857566407+777435732795829242=1762275054653395049\n","correct equation: 757598910792106306+789233132544402110=1546832043336508416\n","predicted:        757598910792106306+789233132544402110=1546831023336508516\n","train_size: 70144, train_loss: 0.2724853630592353,\n","                val_loss: 0.22960049696266652, test_loss: 0.23323656920390792,\n","                test_acc: 0.20145, val_acc: 0.20145, train_acc: 0.21342329545454544\n","                \n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"GPT_Addition.ipynb","provenance":[],"collapsed_sections":["xDSK1sxiIdfU","IIjLRLXGIdfX","zzrr1eoYIdfY","a7J0GgUrfZ6W","l2-A-cu8fdNV","F-Rpw3VZrDv-","pDcry9eArLx6"],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}