{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gRJme0w5nh7"
   },
   "source": [
    "# Train a decoder-only transformer (GPT-like) to do addition\n",
    "\n",
    "In this notebook I train a GPT model to do n-digit addition.\n",
    "\n",
    "I learned a lot from https://github.com/karpathy/minGPT, but I have rewritten all the code based on my own understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qjFkasZb5niB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650975271512,
     "user_tz": 240,
     "elapsed": 2904,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "xDSK1sxiIdfU"
   },
   "source": [
    "## Data processing\n",
    "### Generate an addition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1650975271512,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "JlYks0a55niC",
    "outputId": "8222625c-1741-4d87-9dfb-92d26feaefb0"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "([tensor([15,  5,  1, 10,  9,  2, 13,  1,  4,  3, 14]), tensor([15,  1,  4, 10,  7,  1, 13,  8,  5, 14]), tensor([15,  6,  0, 10,  2,  0, 13,  8,  0, 14]), tensor([15,  8,  2, 10,  8,  6, 13,  1,  6,  8, 14])], ['51+92=143', '14+71=85', '60+20=80', '82+86=168'])\n",
      "([tensor([15,  7,  4, 10,  7,  4, 13,  1,  4,  8, 14]), tensor([15,  8,  7, 10,  9,  9, 13,  1,  8,  6, 14]), tensor([15,  2,  3, 10,  0,  2, 13,  2,  5, 14]), tensor([15,  2,  1, 10,  5,  2, 13,  7,  3, 14])], ['74+74=148', '87+99=186', '23+02=25', '21+52=73'])\n"
     ]
    }
   ],
   "source": [
    "PLUS_SIGN = 10\n",
    "MUL_SIGN  = 11\n",
    "MINUS_SIGN = 12\n",
    "EQUAL_SIGN = 13\n",
    "EOS = 14\n",
    "BOS = 15\n",
    "PAD = 16\n",
    "UNK = 17\n",
    "\n",
    "symbol_to_int_dict = {\"0\": 0, \"1\": 1, \"2\": 2, \"3\": 3, \"4\": 4,\n",
    "                      \"5\": 5, \"6\": 6, \"7\": 7, \"8\": 8, \"9\": 9,\n",
    "                      \"+\": PLUS_SIGN, \"*\": MUL_SIGN, \"-\": MINUS_SIGN,\n",
    "                      \"=\": EQUAL_SIGN,  \"<EOS>\": EOS, \"<BOS>\": BOS,\n",
    "                      \"<pad>\": PAD, \"??\": UNK\n",
    "                      }\n",
    "\n",
    "int_to_symbol_dict = {y:x for (x,y) in symbol_to_int_dict.items()}\n",
    "vocab_size = len(symbol_to_int_dict)\n",
    "\n",
    "def decode_equation(equation):\n",
    "    '''convert an equation in list format to string format '''\n",
    "    res = \"\".join([str(int_to_symbol_dict.get(x, UNK)) for x in equation.tolist()])\n",
    "    return res.replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\")\n",
    "\n",
    "def encode_equation(equation, max_ndigits, padQ=True):\n",
    "    '''convert an equation(up to the equal sign in it) in string format to a list'''\n",
    "    equal_size_loc = equation.index('=')\n",
    "    plus_size_loc = equation.index('+')\n",
    "    num1 = pad_number(equation[0:plus_size_loc], max_ndigits)\n",
    "    num2 = pad_number(equation[plus_size_loc+1:equal_size_loc], max_ndigits)\n",
    "    new_equation = num1 + \"+\" + num2 + \"=\"\n",
    "    return torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in new_equation]).to(DEVICE)\n",
    "\n",
    "\n",
    "def pad_number(num, max_ndigits)->str:\n",
    "    'pad numbers with zeros in front so that they have the same length max_ndigits'\n",
    "    s = str(num)\n",
    "    while len(s)<max_ndigits:\n",
    "      s = \"0\"+s\n",
    "    return s\n",
    "\n",
    "def create_add_dataset(max_ndigits, dataset_size, padQ=True):\n",
    "    ''' Function for creating an addition dataset.\n",
    "    if padQ=True, pre-padding of 0s will be added on the numbers such that all the \n",
    "    numbers has the same length max_ndigits, for example, with max_ndigits=3,  \n",
    "    32 will be represented 032.\n",
    "    '''\n",
    "    dataset_str = []\n",
    "    for i in range(dataset_size):\n",
    "        num1, num2 = np.random.randint(0, 10**max_ndigits, 2)\n",
    "        ans = num1 + num2\n",
    "        # If padQ=True, we pad all the numbers with '0' in front\n",
    "        # such that they all have length max_ndigits\n",
    "        if padQ:\n",
    "            equation = pad_number(num1, max_ndigits) + '+' + pad_number(num2, max_ndigits) + \"=\" + pad_number(ans, max_ndigits)\n",
    "        else:\n",
    "            equation = str(num1) + '+' + str(num2) + \"=\" + str(ans)\n",
    "        dataset_str.append(equation)\n",
    "\n",
    "    dataset = [torch.tensor([BOS]+[symbol_to_int_dict.get(n, UNK) for n in x]+[EOS])\n",
    "               for x in dataset_str]\n",
    "    return dataset, dataset_str\n",
    "\n",
    "print(create_add_dataset(2, 4, padQ=False))\n",
    "print(create_add_dataset(2, 4, padQ=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "4AaG4J3CIdfW"
   },
   "source": [
    "### Create dataloders for the train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XNDapFsq5niE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650975271674,
     "user_tz": 240,
     "elapsed": 4,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "def pad_sequence(batch):\n",
    "    input_padded = torch.nn.utils.rnn.pad_sequence(batch,\n",
    "                                batch_first=True, padding_value = PAD)\n",
    "    return input_padded\n",
    "\n",
    "@dataclass\n",
    "class DataLoaders:\n",
    "    max_ndigits: int\n",
    "    dataset_size: int\n",
    "    padQ: bool = True\n",
    "    val_loader = None\n",
    "    test_loader = None\n",
    "    train_loader = None\n",
    "\n",
    "    def split_data(self, split=[0.7, 0.1, 0.2]):\n",
    "        # If split consists of floats whose sum is equal to 1 then we split the\n",
    "        # dataset by the percentages given by split. If split contains integers, then\n",
    "        # it is understood that the two first integers in split are the number of examples\n",
    "        # in the validation and test sets.\n",
    "        if isinstance(split[0], float):\n",
    "            train_size  = round(self.dataset_size * split[0])\n",
    "            val_size = round(self.dataset_size * split[1])\n",
    "            test_size = self.dataset_size - train_size - val_size\n",
    "\n",
    "        elif isinstance(split[0], int):\n",
    "            val_size = split[0]\n",
    "            test_size = split[1]\n",
    "            train_size  = dataset_size - test_size - val_size\n",
    "\n",
    "\n",
    "        dataset, _ = create_add_dataset(self.max_ndigits, self.dataset_size, padQ=self.padQ)\n",
    "        train_set, val_set, test_set = torch.utils.data.random_split(dataset,\n",
    "                                                             [train_size, val_size, test_size],\n",
    "                                                    generator=torch.Generator().manual_seed(42) )\n",
    "\n",
    "        self.train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
    "                                           shuffle=True, collate_fn = pad_sequence)\n",
    "        self.test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,\n",
    "                                           shuffle=True, collate_fn=pad_sequence)\n",
    "        self.val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
    "                                           shuffle=True, collate_fn=pad_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "IIjLRLXGIdfX"
   },
   "source": [
    "## GPT model\n",
    "Here is my implementation of the GPT model, including the multi-headed self-attention module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FuNdAglk5niF",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650975271674,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_embed, dropout=0.0):\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_embed % h == 0 # check the h number\n",
    "        self.d_k = d_embed//h\n",
    "        self.d_embed = d_embed\n",
    "        self.h = h\n",
    "        self.WQ = nn.Linear(d_embed, d_embed)\n",
    "        self.WK = nn.Linear(d_embed, d_embed)\n",
    "        self.WV = nn.Linear(d_embed, d_embed)\n",
    "        self.linear = nn.Linear(d_embed, d_embed)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_query, x_key, x_value, mask=None):\n",
    "        nbatch = x_query.size(0) # get batch size\n",
    "        # 1) Linear projections to get the multi-head query, key and value tensors\n",
    "        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n",
    "        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n",
    "        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n",
    "        # 2) Attention\n",
    "        # scores has dimensions: nbatch * h * seq_len * seq_len\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n",
    "        # 3) Mask out padding tokens and future tokens\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask, float('-inf'))\n",
    "        # p_atten dimensions: nbatch * h * seq_len * seq_len\n",
    "        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n",
    "        p_atten = self.dropout(p_atten)\n",
    "        # x dimensions: nbatch * h * seq_len * d_k\n",
    "        x = torch.matmul(p_atten, value)\n",
    "        # x now has dimensions:nbtach * seq_len * d_embed\n",
    "        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n",
    "        return self.linear(x) # final linear layer\n",
    "\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n",
    "  def __init__(self, dim, dropout):\n",
    "      super().__init__()\n",
    "      self.drop = nn.Dropout(dropout)\n",
    "      self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "  def forward(self, x, sublayer):\n",
    "      return x + self.drop(sublayer(self.norm(x)))\n",
    "\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.d_embed = config.d_embed\n",
    "        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed))\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n",
    "        self.norm = nn.LayerNorm(config.d_embed)\n",
    "        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n",
    "\n",
    "    def future_mask(self, seq_len):\n",
    "        '''mask out tokens at future positions'''\n",
    "        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n",
    "        return mask.view(1, 1, seq_len, seq_len)\n",
    "\n",
    "    def forward(self, input, pad_mask):\n",
    "        seq_len = input.size(1)\n",
    "        trg_mask = torch.logical_or(pad_mask, self.future_mask(seq_len))\n",
    "        x = self.tok_embed(input) + self.pos_embed[:, :input.size(1), :]\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.decoder_blocks:\n",
    "            x = layer( x, trg_mask)\n",
    "        x = self.norm(x)\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    ''' EncoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.atten = MultiHeadedAttention(config.h, config.d_embed)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(config.d_embed, config.d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout),\n",
    "            nn.Linear(config.d_ff, config.d_embed)\n",
    "        )\n",
    "        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout)\n",
    "                                       for i in range(2)])\n",
    "\n",
    "    def forward(self, decoder_layer_input, trg_mask):\n",
    "        y = decoder_layer_input\n",
    "        y = self.residuals[0](y, lambda y: self.atten(y, y, y, mask=trg_mask))\n",
    "        return self.residuals[1](y, self.feed_forward)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "GsVpY8RnIdfY"
   },
   "source": [
    "### Let's creat a GPT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A_BE7bIS5niG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650975271674,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    decoder_vocab_size: int\n",
    "    d_embed: int\n",
    "    # d_ff is the dimension of the fully-connected  feed-forward layer\n",
    "    d_ff: int\n",
    "    # h is the number of attention head\n",
    "    h: int\n",
    "    N_decoder: int\n",
    "    max_seq_len: int\n",
    "    dropout: float\n",
    "\n",
    "\n",
    "def make_GPT(config):\n",
    "    model = Decoder(config).to(DEVICE)\n",
    "    # initialize model parameters\n",
    "    # it seems that this initialization is very important!\n",
    "    for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "zzrr1eoYIdfY"
   },
   "source": [
    "## Functions for training and input/output processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VO4h4nKG5niH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650975271675,
     "user_tz": 240,
     "elapsed": 3,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [],
   "source": [
    "def make_batch_input(x):\n",
    "        'function for generating model input, target and pad_mask from raw input x'\n",
    "        input = x[:, :-1].to(DEVICE)\n",
    "        equal_sign_loc = [(equation==EQUAL_SIGN).nonzero().item() for equation in x]\n",
    "        # for the target, we mask out the tokens before the equal sign (including the equal sign)\n",
    "        target = [torch.cat(\n",
    "            (torch.tensor([PAD]*equal_sign_loc[i]), x[i][equal_sign_loc[i]+1:])) for i in range(len(x))]\n",
    "        target = torch.cat(target, 0).contiguous().view(-1).to(DEVICE)\n",
    "        pad_mask = (input == PAD).view(input.size(0), 1, 1, input.size(-1))\n",
    "        return input, target, pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0dVrqAIW5niH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650975271788,
     "user_tz": 240,
     "elapsed": 2,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader):\n",
    "    model.train()\n",
    "    grad_norm_clip = 1.0\n",
    "    losses, acc, count = [], 0, 0\n",
    "    num_batches = len(dataloader)\n",
    "    pbar = tqdm(enumerate(dataloader), total=num_batches)\n",
    "    for idx, x  in  pbar:\n",
    "        optimizer.zero_grad()\n",
    "        input, target, pad_mask = make_batch_input(x)\n",
    "        pred = model(input, pad_mask).to(DEVICE)\n",
    "        pred = pred.view(-1, pred.size(-1))\n",
    "        loss = loss_fn(pred, target).to(DEVICE)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        losses.append(loss.item())\n",
    "        # report progress\n",
    "        if idx>0 and idx%50 == 0:\n",
    "            pbar.set_description(f\"ep: {scheduler.last_epoch//num_batches}, train loss={loss.item():.3f},lr={scheduler.get_last_lr()[0]:.5f}\")\n",
    "    return np.mean(losses)\n",
    "\n",
    "def train(model, dataloaders, epochs):\n",
    "    global early_stop_count\n",
    "    train_size = len(dataloaders.train_loader)*batch_size\n",
    "    for ep in range(epochs):\n",
    "        train_loss = train_epoch(model, dataloaders.train_loader)\n",
    "        val_loss = validate(model, dataloaders.val_loader)\n",
    "        print(f'ep {ep}: train_loss: {train_loss:.5f}, val_loss: {val_loss:.5f}')\n",
    "\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def validate(model, dataloder):\n",
    "    'function for computing the loss on the validation set'\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(dataloder):\n",
    "            input, target, pad_mask = make_batch_input(x)\n",
    "            pred = model(input, pad_mask).to(DEVICE)\n",
    "            pred = pred.view(-1, pred.size(-1))\n",
    "            losses.append(loss_fn(pred, target).item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yCQBQ19TVpuc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650977388281,
     "user_tz": 240,
     "elapsed": 185,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def compute_sum(model, x):\n",
    "    'Function for computing the sum of two numbers.'\n",
    "    for i in range(max_ndigits+2):\n",
    "        pad_mask = (x == PAD).view(1, 1, 1, x.size(-1)).to(DEVICE)\n",
    "        logits = model(x, pad_mask)\n",
    "        last_output = logits.argmax(-1)[:,-1].view(1,1)\n",
    "        x = torch.cat((x, last_output), 1).to(DEVICE)\n",
    "        if last_output.item() == EOS:\n",
    "            break\n",
    "    return x[0]\n",
    "\n",
    "def evaluate(model, dataloader, num_batch=None):\n",
    "    '''Function for evaluation the model.\n",
    "    This function take equations, and truncate them up to the equal-sign, and feed them to the\n",
    "    model to get the predictions, compare them with the correct answers, and output the accuracy.\n",
    "    '''\n",
    "    model.eval()\n",
    "    acc, count = 0, 0\n",
    "    num_wrong_to_display = 5\n",
    "    for idx, x in enumerate(dataloader):\n",
    "        for equation in x:\n",
    "            loc_equal_sign = equation.tolist().index(EQUAL_SIGN)\n",
    "            loc_EOS = equation.tolist().index(EOS)\n",
    "            input = equation[0:loc_equal_sign+1].view(1, -1).to(DEVICE)\n",
    "            ans = equation[:loc_EOS+1].tolist()\n",
    "            ans_pred = compute_sum(model, input)\n",
    "            count += 1\n",
    "\n",
    "            if ans == ans_pred.tolist():\n",
    "                acc +=1\n",
    "            else:\n",
    "                if num_wrong_to_display > 0:\n",
    "                    print(f'correct equation: {decode_equation(equation).replace(\"<pad>\",\"\")}')\n",
    "                    print(f'predicted:        {decode_equation(ans_pred)}')\n",
    "                    num_wrong_to_display -= 1\n",
    "        if num_batch and idx>num_batch:\n",
    "            break\n",
    "    return acc/count\n",
    "\n",
    "def what_is(question:str)->str:\n",
    "    'function for computing the sum of two numbers with input in literal string format'\n",
    "    pred = compute_sum(model, encode_equation(question, max_ndigits).view(1,-1))\n",
    "    pred = decode_equation(pred)\n",
    "    pred = pred[pred.index(\"=\")+1:]\n",
    "    return question+pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7J0GgUrfZ6W"
   },
   "source": [
    "## 2-digit addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23754,
     "status": "ok",
     "timestamp": 1650937733454,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "fpBEDpznfmzn",
    "outputId": "d67b802d-4067-4bd1-b20d-f8855f979114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_size: 271378, train_set_size: 7168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: train_loss: 2.33063, val_loss: 1.71811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: train_loss: 1.50895, val_loss: 1.26140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: train_loss: 1.20016, val_loss: 1.02070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 44.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: train_loss: 1.00823, val_loss: 0.92573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: train_loss: 0.91627, val_loss: 0.82485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: train_loss: 0.79150, val_loss: 0.60109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 46.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: train_loss: 0.57075, val_loss: 0.37401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 43.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: train_loss: 0.40913, val_loss: 0.25278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 44.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: train_loss: 0.31168, val_loss: 0.15657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: train_loss: 0.23823, val_loss: 0.10147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 46.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: train_loss: 0.18537, val_loss: 0.07394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: train_loss: 0.14428, val_loss: 0.03609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: train_loss: 0.11255, val_loss: 0.03152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 44.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: train_loss: 0.09997, val_loss: 0.01707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 44.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: train_loss: 0.08343, val_loss: 0.01232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: train_loss: 0.06938, val_loss: 0.00635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 44.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: train_loss: 0.06354, val_loss: 0.00647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: train_loss: 0.05574, val_loss: 0.00519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 46.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: train_loss: 0.04978, val_loss: 0.00308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: train_loss: 0.04401, val_loss: 0.00269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 46.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: train_loss: 0.03893, val_loss: 0.00346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 43.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: train_loss: 0.03643, val_loss: 0.00188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: train_loss: 0.02607, val_loss: 0.00110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: train_loss: 0.02838, val_loss: 0.00131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: train_loss: 0.02957, val_loss: 0.00150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: train_loss: 0.02499, val_loss: 0.00124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 46.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: train_loss: 0.02530, val_loss: 0.00088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: train_loss: 0.02412, val_loss: 0.00053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 46.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: train_loss: 0.02042, val_loss: 0.00068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 45.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: train_loss: 0.01903, val_loss: 0.00057\n"
     ]
    }
   ],
   "source": [
    "max_ndigits = 2\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits + 1 + 1\n",
    "# where the 1s represent BOS, Plus sign, Equal sign, the extra digit in the sum, EOS, respectively.\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "dataset_size = 10000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[1000, 2000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 3*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 77347,
     "status": "ok",
     "timestamp": 1650937810955,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "_ma5l95RJtmV",
    "outputId": "b5e62187-7696-4aa9-b1d2-c0af181e7332"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set examples the model gives an incorrect result:\n",
      "validataion set examples the model gives an incorrect result:\n",
      "test set examples the model gives an incorrect result:\n",
      "train_size: 7168, train_loss: 0.019029294240421483,\n",
      "                val_loss: 0.0005657454748870805, test_loss: 0.0006502777905552648,\n",
      "                test_acc: 1.0, val_acc: 1.0, train_acc: 1.0\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(model, data_loaders.test_loader)\n",
    "print('training set examples the model gives an incorrect result:')\n",
    "train_acc = evaluate(model, data_loaders.train_loader, 20)\n",
    "print('validataion set examples the model gives an incorrect result:')\n",
    "val_acc = evaluate(model, data_loaders.test_loader)\n",
    "print('test set examples the model gives an incorrect result:')\n",
    "test_acc = evaluate(model, data_loaders.test_loader)\n",
    "result = f'''train_size: {train_size}, train_loss: {train_loss},\n",
    "                val_loss: {val_loss}, test_loss: {test_loss},\n",
    "                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
    "                '''\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "-YOiQdH4pO4N"
   },
   "source": [
    "No wrong example shown. The model got all the 2-digit addition right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2-A-cu8fdNV"
   },
   "source": [
    "## 5-digit addition \n",
    "<!-- and scaling laws\n",
    "For 5-digit addition, there are 10<sup>10</sup> possible data points, so we will have enough data to study the scaling laws. For example, we can study how the performance of the model (with fixed number of parameters) improves as we increase the training set size.   -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502659,
     "status": "ok",
     "timestamp": 1650941655813,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "VQaJvSq4GC0U",
    "outputId": "e04783c5-88ff-4b4b-fd1c-4780db60c73d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_size: 272530, train_set_size: 170240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 0, train loss=1.600,lr=0.00030: 100%|██████████| 665/665 [00:16<00:00, 41.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: train_loss: 2.04759, val_loss: 1.55023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 1, train loss=1.195,lr=0.00061: 100%|██████████| 665/665 [00:16<00:00, 40.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: train_loss: 1.42975, val_loss: 1.11064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 2, train loss=0.497,lr=0.00091: 100%|██████████| 665/665 [00:16<00:00, 41.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: train_loss: 0.84462, val_loss: 0.33478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 3, train loss=0.211,lr=0.00122: 100%|██████████| 665/665 [00:16<00:00, 41.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: train_loss: 0.31756, val_loss: 0.15157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 4, train loss=0.108,lr=0.00153: 100%|██████████| 665/665 [00:16<00:00, 41.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: train_loss: 0.16307, val_loss: 0.06498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 5, train loss=0.057,lr=0.00140: 100%|██████████| 665/665 [00:16<00:00, 41.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: train_loss: 0.09666, val_loss: 0.03029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 6, train loss=0.050,lr=0.00130: 100%|██████████| 665/665 [00:16<00:00, 41.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: train_loss: 0.06794, val_loss: 0.03451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 7, train loss=0.055,lr=0.00121: 100%|██████████| 665/665 [00:15<00:00, 41.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: train_loss: 0.05177, val_loss: 0.01648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 8, train loss=0.052,lr=0.00114: 100%|██████████| 665/665 [00:16<00:00, 41.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: train_loss: 0.04194, val_loss: 0.01408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 9, train loss=0.040,lr=0.00108: 100%|██████████| 665/665 [00:16<00:00, 41.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: train_loss: 0.03560, val_loss: 0.01517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 10, train loss=0.036,lr=0.00103: 100%|██████████| 665/665 [00:15<00:00, 41.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: train_loss: 0.03015, val_loss: 0.01296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 11, train loss=0.020,lr=0.00099: 100%|██████████| 665/665 [00:16<00:00, 41.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: train_loss: 0.02715, val_loss: 0.01153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 12, train loss=0.016,lr=0.00095: 100%|██████████| 665/665 [00:16<00:00, 41.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: train_loss: 0.02448, val_loss: 0.01027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 13, train loss=0.025,lr=0.00092: 100%|██████████| 665/665 [00:16<00:00, 41.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: train_loss: 0.02179, val_loss: 0.01033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 14, train loss=0.018,lr=0.00089: 100%|██████████| 665/665 [00:16<00:00, 41.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: train_loss: 0.01895, val_loss: 0.00714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 15, train loss=0.007,lr=0.00086: 100%|██████████| 665/665 [00:16<00:00, 41.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: train_loss: 0.01562, val_loss: 0.00556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 16, train loss=0.007,lr=0.00083: 100%|██████████| 665/665 [00:16<00:00, 41.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: train_loss: 0.01351, val_loss: 0.00463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 17, train loss=0.012,lr=0.00081: 100%|██████████| 665/665 [00:16<00:00, 41.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: train_loss: 0.01164, val_loss: 0.00386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 18, train loss=0.013,lr=0.00079: 100%|██████████| 665/665 [00:16<00:00, 41.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: train_loss: 0.01060, val_loss: 0.00386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 19, train loss=0.008,lr=0.00077: 100%|██████████| 665/665 [00:16<00:00, 41.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: train_loss: 0.00987, val_loss: 0.00347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 20, train loss=0.002,lr=0.00075: 100%|██████████| 665/665 [00:15<00:00, 41.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: train_loss: 0.00926, val_loss: 0.00350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 21, train loss=0.004,lr=0.00073: 100%|██████████| 665/665 [00:16<00:00, 41.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: train_loss: 0.00867, val_loss: 0.00303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 22, train loss=0.006,lr=0.00071: 100%|██████████| 665/665 [00:16<00:00, 41.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: train_loss: 0.00811, val_loss: 0.00279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 23, train loss=0.007,lr=0.00070: 100%|██████████| 665/665 [00:16<00:00, 41.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: train_loss: 0.00764, val_loss: 0.00257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 24, train loss=0.004,lr=0.00069: 100%|██████████| 665/665 [00:16<00:00, 41.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: train_loss: 0.00741, val_loss: 0.00224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 25, train loss=0.010,lr=0.00067: 100%|██████████| 665/665 [00:16<00:00, 41.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: train_loss: 0.00696, val_loss: 0.00216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 26, train loss=0.003,lr=0.00066: 100%|██████████| 665/665 [00:16<00:00, 40.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: train_loss: 0.00677, val_loss: 0.00213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 27, train loss=0.003,lr=0.00065: 100%|██████████| 665/665 [00:16<00:00, 41.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: train_loss: 0.00620, val_loss: 0.00177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 28, train loss=0.006,lr=0.00064: 100%|██████████| 665/665 [00:16<00:00, 41.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: train_loss: 0.00581, val_loss: 0.00175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 29, train loss=0.004,lr=0.00063: 100%|██████████| 665/665 [00:16<00:00, 41.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: train_loss: 0.00580, val_loss: 0.00191\n"
     ]
    }
   ],
   "source": [
    "max_ndigits = 5\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "\n",
    "dataset_size = 200000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[10000, 20000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 5*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 680791,
     "status": "ok",
     "timestamp": 1650942336594,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     },
     "user_tz": 240
    },
    "id": "IeCO8-I2g6DF",
    "outputId": "4774ddfa-6524-40b7-e747-a4d11d15a9a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set examples the model gives an incorrect result:\n",
      "correct equation: 08062+11419=19481\n",
      "predicted:        08062+11419=19471\n",
      "correct equation: 00654+18876=19530\n",
      "predicted:        00654+18876=19520\n",
      "correct equation: 08899+01130=10029\n",
      "predicted:        08899+01130=10039\n",
      "correct equation: 04796+09763=14559\n",
      "predicted:        04796+09763=14569\n",
      "correct equation: 05801+07910=13711\n",
      "predicted:        05801+07910=13721\n",
      "validataion set examples the model gives an incorrect result:\n",
      "correct equation: 07726+09569=17295\n",
      "predicted:        07726+09569=17285\n",
      "correct equation: 05021+14164=19185\n",
      "predicted:        05021+14164=19175\n",
      "correct equation: 09069+04551=13620\n",
      "predicted:        09069+04551=13610\n",
      "correct equation: 01863+17203=19066\n",
      "predicted:        01863+17203=19076\n",
      "correct equation: 03907+14952=18859\n",
      "predicted:        03907+14952=18869\n",
      "test set examples the model gives an incorrect result:\n",
      "correct equation: 01863+17203=19066\n",
      "predicted:        01863+17203=19076\n",
      "correct equation: 09089+09305=18394\n",
      "predicted:        09089+09305=18384\n",
      "correct equation: 07629+03165=10794\n",
      "predicted:        07629+03165=10784\n",
      "correct equation: 09069+04551=13620\n",
      "predicted:        09069+04551=13610\n",
      "correct equation: 00458+15065=15523\n",
      "predicted:        00458+15065=15503\n",
      "train_size: 170240, train_loss: 0.005803392585226916,\n",
      "                val_loss: 0.0019068418136157562, test_loss: 0.0014604358151631505,\n",
      "                test_acc: 0.99645, val_acc: 0.99645, train_acc: 0.9976917613636364\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(model, data_loaders.test_loader)\n",
    "print('training set examples the model gives an incorrect result:')\n",
    "train_acc = evaluate(model, data_loaders.train_loader, 20)\n",
    "print('validataion set examples the model gives an incorrect result:')\n",
    "val_acc = evaluate(model, data_loaders.test_loader)\n",
    "print('test set examples the model gives an incorrect result:')\n",
    "test_acc = evaluate(model, data_loaders.test_loader)\n",
    "result = f'''train_size: {train_size}, train_loss: {train_loss},\n",
    "                val_loss: {val_loss}, test_loss: {test_loss},\n",
    "                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
    "                '''\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzabJ1kKs7oV"
   },
   "source": [
    "The model got a very small fraction of the 5-digit addition wrong, and the answers the model gave are mostly one or two digits off. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F-Rpw3VZrDv-"
   },
   "source": [
    "# 10-digit addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxqeGxzCmcdN",
    "outputId": "5348b1d5-596e-45cd-8320-f7c5a812cad0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650977168812,
     "user_tz": 240,
     "elapsed": 1143025,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model_size: 274450, train_set_size: 270080\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 0, train loss=1.908,lr=0.00024: 100%|██████████| 1055/1055 [00:22<00:00, 47.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 0: train_loss: 2.21616, val_loss: 1.87900\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 1, train loss=1.679,lr=0.00049: 100%|██████████| 1055/1055 [00:22<00:00, 47.27it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 1: train_loss: 1.81667, val_loss: 1.65460\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 2, train loss=0.640,lr=0.00073: 100%|██████████| 1055/1055 [00:22<00:00, 47.31it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 2: train_loss: 1.05677, val_loss: 0.51183\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 3, train loss=0.391,lr=0.00097: 100%|██████████| 1055/1055 [00:22<00:00, 47.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 3: train_loss: 0.47011, val_loss: 0.31277\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 4, train loss=0.322,lr=0.00122: 100%|██████████| 1055/1055 [00:22<00:00, 47.28it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 4: train_loss: 0.35374, val_loss: 0.27067\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 5, train loss=0.103,lr=0.00111: 100%|██████████| 1055/1055 [00:22<00:00, 47.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 5: train_loss: 0.24741, val_loss: 0.05725\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 6, train loss=0.041,lr=0.00103: 100%|██████████| 1055/1055 [00:22<00:00, 47.40it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 6: train_loss: 0.07131, val_loss: 0.02209\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 7, train loss=0.032,lr=0.00096: 100%|██████████| 1055/1055 [00:22<00:00, 47.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 7: train_loss: 0.04485, val_loss: 0.01444\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 8, train loss=0.036,lr=0.00091: 100%|██████████| 1055/1055 [00:22<00:00, 47.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 8: train_loss: 0.03369, val_loss: 0.01287\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 9, train loss=0.019,lr=0.00086: 100%|██████████| 1055/1055 [00:22<00:00, 47.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 9: train_loss: 0.02758, val_loss: 0.01087\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 10, train loss=0.016,lr=0.00082: 100%|██████████| 1055/1055 [00:22<00:00, 47.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 10: train_loss: 0.02359, val_loss: 0.00935\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 11, train loss=0.018,lr=0.00079: 100%|██████████| 1055/1055 [00:22<00:00, 47.18it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 11: train_loss: 0.02068, val_loss: 0.00832\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 12, train loss=0.018,lr=0.00075: 100%|██████████| 1055/1055 [00:22<00:00, 47.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 12: train_loss: 0.01868, val_loss: 0.00753\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 13, train loss=0.018,lr=0.00073: 100%|██████████| 1055/1055 [00:22<00:00, 47.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 13: train_loss: 0.01724, val_loss: 0.00702\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 14, train loss=0.023,lr=0.00070: 100%|██████████| 1055/1055 [00:22<00:00, 47.14it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 14: train_loss: 0.01598, val_loss: 0.00725\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 15, train loss=0.014,lr=0.00068: 100%|██████████| 1055/1055 [00:22<00:00, 47.19it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 15: train_loss: 0.01453, val_loss: 0.00695\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 16, train loss=0.015,lr=0.00066: 100%|██████████| 1055/1055 [00:22<00:00, 47.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 16: train_loss: 0.01377, val_loss: 0.00677\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 17, train loss=0.015,lr=0.00064: 100%|██████████| 1055/1055 [00:22<00:00, 47.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 17: train_loss: 0.01291, val_loss: 0.00653\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 18, train loss=0.008,lr=0.00062: 100%|██████████| 1055/1055 [00:22<00:00, 47.11it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 18: train_loss: 0.01233, val_loss: 0.00611\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 19, train loss=0.009,lr=0.00061: 100%|██████████| 1055/1055 [00:22<00:00, 47.38it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 19: train_loss: 0.01209, val_loss: 0.00643\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 20, train loss=0.009,lr=0.00059: 100%|██████████| 1055/1055 [00:22<00:00, 47.15it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 20: train_loss: 0.01146, val_loss: 0.00556\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 21, train loss=0.015,lr=0.00058: 100%|██████████| 1055/1055 [00:22<00:00, 47.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 21: train_loss: 0.01100, val_loss: 0.00580\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 22, train loss=0.005,lr=0.00057: 100%|██████████| 1055/1055 [00:22<00:00, 46.88it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 22: train_loss: 0.01079, val_loss: 0.00531\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 23, train loss=0.009,lr=0.00056: 100%|██████████| 1055/1055 [00:22<00:00, 47.06it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 23: train_loss: 0.01037, val_loss: 0.00574\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 24, train loss=0.011,lr=0.00054: 100%|██████████| 1055/1055 [00:22<00:00, 47.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 24: train_loss: 0.00996, val_loss: 0.00505\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 25, train loss=0.008,lr=0.00053: 100%|██████████| 1055/1055 [00:22<00:00, 47.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 25: train_loss: 0.00974, val_loss: 0.00512\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 26, train loss=0.009,lr=0.00052: 100%|██████████| 1055/1055 [00:22<00:00, 47.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 26: train_loss: 0.00937, val_loss: 0.00487\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 27, train loss=0.008,lr=0.00051: 100%|██████████| 1055/1055 [00:22<00:00, 47.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 27: train_loss: 0.00915, val_loss: 0.00511\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 28, train loss=0.007,lr=0.00051: 100%|██████████| 1055/1055 [00:22<00:00, 47.04it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 28: train_loss: 0.00894, val_loss: 0.00481\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 29, train loss=0.010,lr=0.00050: 100%|██████████| 1055/1055 [00:22<00:00, 47.14it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 29: train_loss: 0.00880, val_loss: 0.00476\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 30, train loss=0.006,lr=0.00049: 100%|██████████| 1055/1055 [00:22<00:00, 47.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 30: train_loss: 0.00858, val_loss: 0.00537\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 31, train loss=0.006,lr=0.00048: 100%|██████████| 1055/1055 [00:22<00:00, 47.36it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 31: train_loss: 0.00851, val_loss: 0.00455\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 32, train loss=0.008,lr=0.00047: 100%|██████████| 1055/1055 [00:22<00:00, 47.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 32: train_loss: 0.00837, val_loss: 0.00451\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 33, train loss=0.009,lr=0.00047: 100%|██████████| 1055/1055 [00:22<00:00, 47.39it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 33: train_loss: 0.00805, val_loss: 0.00445\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 34, train loss=0.011,lr=0.00046: 100%|██████████| 1055/1055 [00:22<00:00, 47.46it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 34: train_loss: 0.00802, val_loss: 0.00424\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 35, train loss=0.008,lr=0.00045: 100%|██████████| 1055/1055 [00:22<00:00, 47.21it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 35: train_loss: 0.00790, val_loss: 0.00427\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 36, train loss=0.013,lr=0.00045: 100%|██████████| 1055/1055 [00:22<00:00, 47.27it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 36: train_loss: 0.00770, val_loss: 0.00390\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 37, train loss=0.008,lr=0.00044: 100%|██████████| 1055/1055 [00:22<00:00, 47.12it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 37: train_loss: 0.00769, val_loss: 0.00397\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 38, train loss=0.005,lr=0.00044: 100%|██████████| 1055/1055 [00:22<00:00, 47.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 38: train_loss: 0.00738, val_loss: 0.00424\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 39, train loss=0.007,lr=0.00043: 100%|██████████| 1055/1055 [00:22<00:00, 47.33it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 39: train_loss: 0.00733, val_loss: 0.00387\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 40, train loss=0.007,lr=0.00043: 100%|██████████| 1055/1055 [00:22<00:00, 47.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 40: train_loss: 0.00737, val_loss: 0.00409\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 41, train loss=0.008,lr=0.00042: 100%|██████████| 1055/1055 [00:22<00:00, 47.67it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 41: train_loss: 0.00709, val_loss: 0.00403\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 42, train loss=0.007,lr=0.00042: 100%|██████████| 1055/1055 [00:22<00:00, 47.22it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 42: train_loss: 0.00704, val_loss: 0.00373\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 43, train loss=0.007,lr=0.00041: 100%|██████████| 1055/1055 [00:22<00:00, 47.24it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 43: train_loss: 0.00688, val_loss: 0.00379\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 44, train loss=0.006,lr=0.00041: 100%|██████████| 1055/1055 [00:22<00:00, 47.13it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 44: train_loss: 0.00693, val_loss: 0.00388\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 45, train loss=0.005,lr=0.00040: 100%|██████████| 1055/1055 [00:22<00:00, 47.25it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 45: train_loss: 0.00690, val_loss: 0.00365\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 46, train loss=0.007,lr=0.00040: 100%|██████████| 1055/1055 [00:22<00:00, 47.14it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 46: train_loss: 0.00667, val_loss: 0.00426\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 47, train loss=0.009,lr=0.00039: 100%|██████████| 1055/1055 [00:22<00:00, 47.20it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 47: train_loss: 0.00662, val_loss: 0.00391\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 48, train loss=0.008,lr=0.00039: 100%|██████████| 1055/1055 [00:22<00:00, 47.33it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 48: train_loss: 0.00658, val_loss: 0.00423\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 49, train loss=0.009,lr=0.00038: 100%|██████████| 1055/1055 [00:22<00:00, 47.30it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 49: train_loss: 0.00651, val_loss: 0.00356\n"
     ]
    }
   ],
   "source": [
    "max_ndigits = 10\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "dataset_size = 300000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[10000, 20000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 5*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8Xe2aR9BmeSE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650978052428,
     "user_tz": 240,
     "elapsed": 653958,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "0a657e90-72a2-4192-ebca-db47ca82cc26"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training set examples the model gives an incorrect result:\n",
      "correct equation: 5588619202+3569680742=9158299944\n",
      "predicted:        5588619202+3569680742=9158309944\n",
      "correct equation: 2246603235+4520943775=6767547010\n",
      "predicted:        2246603235+4520943775=6767546010\n",
      "correct equation: 0633806046+2337190109=2970996155\n",
      "predicted:        0633806046+2337190109=2971996155\n",
      "correct equation: 0400816738+2163010270=2563827008\n",
      "predicted:        0400816738+2163010270=2563826008\n",
      "correct equation: 0247470421+0862429184=1109899605\n",
      "predicted:        0247470421+0862429184=1109999605\n",
      "validataion set examples the model gives an incorrect result:\n",
      "correct equation: 4205217864+3893393129=8098610993\n",
      "predicted:        4205217864+3893393129=8098611993\n",
      "correct equation: 8752428096+0517770891=9270198987\n",
      "predicted:        8752428096+0517770891=9270298987\n",
      "correct equation: 3015532723+6457643298=9473176021\n",
      "predicted:        3015532723+6457643298=9473175021\n",
      "correct equation: 0600963084+0001658910=0602621994\n",
      "predicted:        0600963084+0001658910=0602622994\n",
      "correct equation: 1011052902+8496942678=9507995580\n",
      "predicted:        1011052902+8496942678=9508995580\n",
      "test set examples the model gives an incorrect result:\n",
      "correct equation: 2953303873+3571182115=6524485988\n",
      "predicted:        2953303873+3571182115=6524486988\n",
      "correct equation: 0406308843+7015263129=7421571972\n",
      "predicted:        0406308843+7015263129=7421572972\n",
      "correct equation: 2578485281+4197512624=6775997905\n",
      "predicted:        2578485281+4197512624=6776997905\n",
      "correct equation: 0961716364+8715083522=9676799886\n",
      "predicted:        0961716364+8715083522=9676899886\n",
      "correct equation: 2280915007+1037597994=3318513001\n",
      "predicted:        2280915007+1037597994=3318512001\n",
      "train_size: 270080, train_loss: 0.006505303087719314,\n",
      "                val_loss: 0.0035584326746175067, test_loss: 0.003260334373062736,\n",
      "                test_acc: 0.9831, val_acc: 0.9831, train_acc: 0.984375\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(model, data_loaders.test_loader)\n",
    "print('training set examples the model gives an incorrect result:')\n",
    "train_acc = evaluate(model, data_loaders.train_loader, 20)\n",
    "print('validataion set examples the model gives an incorrect result:')\n",
    "val_acc = evaluate(model, data_loaders.test_loader)\n",
    "print('test set examples the model gives an incorrect result:')\n",
    "test_acc = evaluate(model, data_loaders.test_loader)\n",
    "result = f'''train_size: {train_size}, train_loss: {train_loss},\n",
    "                val_loss: {val_loss}, test_loss: {test_loss},\n",
    "                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
    "                '''\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDcry9eArLx6"
   },
   "source": [
    "# 18-digit addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m-8QY2kMrN5o",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650980056790,
     "user_tz": 240,
     "elapsed": 491192,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "ca4b8445-d59e-4c74-cc61-3d5b082b2cb3"
   },
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_size: 277522, train_set_size: 370176\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 0, train loss=2.096,lr=0.00020: 100%|██████████| 1446/1446 [00:38<00:00, 37.10it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 0: train_loss: 2.28885, val_loss: 2.06631\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 1, train loss=1.960,lr=0.00041: 100%|██████████| 1446/1446 [00:38<00:00, 37.14it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 1: train_loss: 2.03282, val_loss: 1.93960\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 2, train loss=1.807,lr=0.00062: 100%|██████████| 1446/1446 [00:38<00:00, 37.21it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 2: train_loss: 1.88473, val_loss: 1.79065\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 3, train loss=1.537,lr=0.00083: 100%|██████████| 1446/1446 [00:38<00:00, 37.18it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 3: train_loss: 1.76677, val_loss: 1.45359\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 4, train loss=0.489,lr=0.00103: 100%|██████████| 1446/1446 [00:38<00:00, 37.15it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 4: train_loss: 0.82969, val_loss: 0.39867\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 5, train loss=0.083,lr=0.00095: 100%|██████████| 1446/1446 [00:38<00:00, 37.19it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 5: train_loss: 0.22921, val_loss: 0.03232\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 6, train loss=0.049,lr=0.00088: 100%|██████████| 1446/1446 [00:38<00:00, 37.21it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 6: train_loss: 0.06458, val_loss: 0.02105\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 7, train loss=0.043,lr=0.00082: 100%|██████████| 1446/1446 [00:38<00:00, 37.21it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 7: train_loss: 0.04325, val_loss: 0.01776\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 8, train loss=0.036,lr=0.00078: 100%|██████████| 1446/1446 [00:38<00:00, 37.13it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 8: train_loss: 0.03480, val_loss: 0.01582\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 9, train loss=0.020,lr=0.00074: 100%|██████████| 1446/1446 [00:38<00:00, 37.23it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 9: train_loss: 0.03010, val_loss: 0.01396\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 10, train loss=0.026,lr=0.00070: 100%|██████████| 1446/1446 [00:38<00:00, 37.08it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 10: train_loss: 0.02628, val_loss: 0.01287\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 11, train loss=0.030,lr=0.00067: 100%|██████████| 1446/1446 [00:39<00:00, 37.04it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 11: train_loss: 0.02355, val_loss: 0.01112\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 12, train loss=0.020,lr=0.00065: 100%|██████████| 1446/1446 [00:38<00:00, 37.15it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 12: train_loss: 0.02127, val_loss: 0.01131\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 13, train loss=0.020,lr=0.00062: 100%|██████████| 1446/1446 [00:38<00:00, 37.14it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 13: train_loss: 0.01980, val_loss: 0.01057\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 14, train loss=0.016,lr=0.00060: 100%|██████████| 1446/1446 [00:38<00:00, 37.11it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 14: train_loss: 0.01870, val_loss: 0.01111\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 15, train loss=0.017,lr=0.00058: 100%|██████████| 1446/1446 [00:39<00:00, 36.82it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 15: train_loss: 0.01762, val_loss: 0.00967\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 16, train loss=0.018,lr=0.00056: 100%|██████████| 1446/1446 [00:40<00:00, 35.79it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 16: train_loss: 0.01695, val_loss: 0.00929\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 17, train loss=0.013,lr=0.00055: 100%|██████████| 1446/1446 [00:39<00:00, 36.46it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 17: train_loss: 0.01605, val_loss: 0.00939\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 18, train loss=0.015,lr=0.00053: 100%|██████████| 1446/1446 [00:39<00:00, 36.43it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 18: train_loss: 0.01547, val_loss: 0.00886\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 19, train loss=0.015,lr=0.00052: 100%|██████████| 1446/1446 [00:39<00:00, 36.62it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 19: train_loss: 0.01507, val_loss: 0.00905\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 20, train loss=0.011,lr=0.00051: 100%|██████████| 1446/1446 [00:39<00:00, 36.71it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 20: train_loss: 0.01462, val_loss: 0.00906\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 21, train loss=0.017,lr=0.00050: 100%|██████████| 1446/1446 [00:39<00:00, 36.64it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 21: train_loss: 0.01410, val_loss: 0.00880\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 22, train loss=0.014,lr=0.00048: 100%|██████████| 1446/1446 [00:39<00:00, 36.78it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 22: train_loss: 0.01382, val_loss: 0.00877\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 23, train loss=0.015,lr=0.00047: 100%|██████████| 1446/1446 [00:39<00:00, 36.86it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 23: train_loss: 0.01337, val_loss: 0.00837\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 24, train loss=0.014,lr=0.00047: 100%|██████████| 1446/1446 [00:39<00:00, 36.61it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 24: train_loss: 0.01300, val_loss: 0.00816\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 25, train loss=0.010,lr=0.00046: 100%|██████████| 1446/1446 [00:39<00:00, 36.49it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 25: train_loss: 0.01283, val_loss: 0.00851\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 26, train loss=0.015,lr=0.00045: 100%|██████████| 1446/1446 [00:39<00:00, 36.37it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 26: train_loss: 0.01252, val_loss: 0.00813\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 27, train loss=0.011,lr=0.00044: 100%|██████████| 1446/1446 [00:39<00:00, 36.30it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 27: train_loss: 0.01193, val_loss: 0.00673\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 28, train loss=0.012,lr=0.00043: 100%|██████████| 1446/1446 [00:39<00:00, 36.42it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 28: train_loss: 0.01069, val_loss: 0.00611\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 29, train loss=0.014,lr=0.00042: 100%|██████████| 1446/1446 [00:39<00:00, 36.51it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 29: train_loss: 0.01008, val_loss: 0.00514\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 30, train loss=0.012,lr=0.00042: 100%|██████████| 1446/1446 [00:39<00:00, 36.72it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 30: train_loss: 0.00953, val_loss: 0.00506\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 31, train loss=0.013,lr=0.00041: 100%|██████████| 1446/1446 [00:39<00:00, 36.57it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 31: train_loss: 0.00919, val_loss: 0.00495\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 32, train loss=0.010,lr=0.00040: 100%|██████████| 1446/1446 [00:39<00:00, 36.65it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 32: train_loss: 0.00888, val_loss: 0.00467\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 33, train loss=0.010,lr=0.00040: 100%|██████████| 1446/1446 [00:39<00:00, 36.68it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 33: train_loss: 0.00861, val_loss: 0.00501\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 34, train loss=0.011,lr=0.00039: 100%|██████████| 1446/1446 [00:39<00:00, 36.69it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 34: train_loss: 0.00841, val_loss: 0.00489\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 35, train loss=0.010,lr=0.00039: 100%|██████████| 1446/1446 [00:39<00:00, 36.51it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 35: train_loss: 0.00820, val_loss: 0.00463\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep: 36, train loss=0.009,lr=0.00038: 100%|██████████| 1446/1446 [00:39<00:00, 36.63it/s]\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep 36: train_loss: 0.00810, val_loss: 0.00476\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 37, train loss=0.007,lr=0.00038: 100%|██████████| 1446/1446 [00:39<00:00, 36.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 37: train_loss: 0.00795, val_loss: 0.00471\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 38, train loss=0.004,lr=0.00037: 100%|██████████| 1446/1446 [00:39<00:00, 36.45it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 38: train_loss: 0.00787, val_loss: 0.00480\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 39, train loss=0.007,lr=0.00037: 100%|██████████| 1446/1446 [00:39<00:00, 36.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 39: train_loss: 0.00766, val_loss: 0.00503\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 40, train loss=0.008,lr=0.00036: 100%|██████████| 1446/1446 [00:39<00:00, 36.52it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 40: train_loss: 0.00750, val_loss: 0.00462\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 41, train loss=0.008,lr=0.00036: 100%|██████████| 1446/1446 [00:39<00:00, 36.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 41: train_loss: 0.00751, val_loss: 0.00474\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 42, train loss=0.011,lr=0.00035: 100%|██████████| 1446/1446 [00:39<00:00, 36.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 42: train_loss: 0.00731, val_loss: 0.00459\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 43, train loss=0.007,lr=0.00035: 100%|██████████| 1446/1446 [00:39<00:00, 36.52it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 43: train_loss: 0.00728, val_loss: 0.00473\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 44, train loss=0.006,lr=0.00035: 100%|██████████| 1446/1446 [00:39<00:00, 36.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 44: train_loss: 0.00717, val_loss: 0.00465\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 45, train loss=0.008,lr=0.00034: 100%|██████████| 1446/1446 [00:39<00:00, 36.52it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 45: train_loss: 0.00697, val_loss: 0.00448\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 46, train loss=0.004,lr=0.00034: 100%|██████████| 1446/1446 [00:39<00:00, 36.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 46: train_loss: 0.00697, val_loss: 0.00434\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 47, train loss=0.009,lr=0.00034: 100%|██████████| 1446/1446 [00:39<00:00, 36.44it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 47: train_loss: 0.00684, val_loss: 0.00416\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 48, train loss=0.007,lr=0.00033: 100%|██████████| 1446/1446 [00:39<00:00, 36.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 48: train_loss: 0.00694, val_loss: 0.00431\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ep: 49, train loss=0.004,lr=0.00033: 100%|██████████| 1446/1446 [00:39<00:00, 36.48it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ep 49: train_loss: 0.00675, val_loss: 0.00430\n"
     ]
    }
   ],
   "source": [
    "max_ndigits = 18\n",
    "# max_len is determined by 1+ max_ndigits + 1 + max_ndigits + 1 + max_ndigits +1 +1\n",
    "max_len = 3*max_ndigits + 6\n",
    "config = ModelConfig(decoder_vocab_size= vocab_size,\n",
    "                     d_embed=128,\n",
    "                     d_ff=256,\n",
    "                     h=4,\n",
    "                     N_decoder=2,\n",
    "                     max_seq_len= max_len,\n",
    "                     dropout=0.1)\n",
    "dataset_size = 400000\n",
    "data_loaders = DataLoaders(max_ndigits, dataset_size, padQ=True)\n",
    "data_loaders.split_data(split=[10000, 20000])\n",
    "train_size = len(data_loaders.train_loader)*batch_size\n",
    "model = make_GPT(config)\n",
    "model_size = sum([p.numel() for p in model.parameters()])\n",
    "print(f'model_size: {model_size}, train_set_size: {train_size}')\n",
    "warmup_steps = 5*len(data_loaders.train_loader)\n",
    "# lr first increases in the warmup steps, and then decreases\n",
    "lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n",
    "\n",
    "train_loss, val_loss = train(model, data_loaders, epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "usZg_i57ra9g",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1650981184114,
     "user_tz": 240,
     "elapsed": 1127325,
     "user": {
      "displayName": "Hongbin Chen",
      "userId": "14161707569992931612"
     }
    },
    "outputId": "531b791e-72a1-4cef-cdce-3dfabda4a7e1"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training set examples the model gives an incorrect result:\n",
      "correct equation: 981032270596811016+441027710402717948=1422059980999528964\n",
      "predicted:        981032270596811016+441027710402717948=1422059981999528964\n",
      "correct equation: 016450324225214967+900569997274624451=917020321499839418\n",
      "predicted:        016450324225214967+900569997274624451=917020321599839418\n",
      "correct equation: 160302195048473699+117821422051169265=278123617099642964\n",
      "predicted:        160302195048473699+117821422051169265=278123617199642964\n",
      "correct equation: 460436849321738648+060481920177649533=520918769499388181\n",
      "predicted:        460436849321738648+060481920177649533=520918769599388181\n",
      "correct equation: 677132007489206030+743341927832790797=1420473935321996827\n",
      "predicted:        677132007489206030+743341927832790797=1420473935322996827\n",
      "validataion set examples the model gives an incorrect result:\n",
      "correct equation: 052868694601456094+251576304088699597=304444998690155691\n",
      "predicted:        052868694601456094+251576304088699597=304445998690155691\n",
      "correct equation: 291708652324722975+677910284259176640=969618936583899615\n",
      "predicted:        291708652324722975+677910284259176640=969618936583999615\n",
      "correct equation: 139215901730739717+483124000690532950=622339902421272667\n",
      "predicted:        139215901730739717+483124000690532950=622349902421272667\n",
      "correct equation: 154482922054700992+207399598410697534=361882520465398526\n",
      "predicted:        154482922054700992+207399598410697534=361882520465498526\n",
      "correct equation: 084513908680669189+149358494618674927=233872403299344116\n",
      "predicted:        084513908680669189+149358494618674927=233872403399344116\n",
      "test set examples the model gives an incorrect result:\n",
      "correct equation: 033205119081582599+063440380585111482=096645499666694081\n",
      "predicted:        033205119081582599+063440380585111482=096645599666694081\n",
      "correct equation: 689056598277258334+117343134415659996=806399732692918330\n",
      "predicted:        689056598277258334+117343134415659996=806499732692918330\n",
      "correct equation: 687869345087141765+216324054479969152=904193399567110917\n",
      "predicted:        687869345087141765+216324054479969152=904193499567110917\n",
      "correct equation: 755500493251139866+197181504969644970=952681998220784836\n",
      "predicted:        755500493251139866+197181504969644970=952682998220784836\n",
      "correct equation: 401776853261051677+866059121456947439=1267835974717999116\n",
      "predicted:        401776853261051677+866059121456947439=1267835974718999116\n",
      "train_size: 370176, train_loss: 0.006746966140937282,\n",
      "                val_loss: 0.004303365992882391, test_loss: 0.0038383938180565646,\n",
      "                test_acc: 0.9659, val_acc: 0.9659, train_acc: 0.9705255681818182\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "test_loss = validate(model, data_loaders.test_loader)\n",
    "print('training set examples the model gives an incorrect result:')\n",
    "train_acc = evaluate(model, data_loaders.train_loader, 20)\n",
    "print('validataion set examples the model gives an incorrect result:')\n",
    "val_acc = evaluate(model, data_loaders.test_loader)\n",
    "print('test set examples the model gives an incorrect result:')\n",
    "test_acc = evaluate(model, data_loaders.test_loader)\n",
    "result = f'''train_size: {train_size}, train_loss: {train_loss},\n",
    "                val_loss: {val_loss}, test_loss: {test_loss},\n",
    "                test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
    "                '''\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "GPT_Addition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}