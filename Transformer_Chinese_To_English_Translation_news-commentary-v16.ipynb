{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Transformer_Chinese_To_English_Translation_news-commentary-v16.ipynb","provenance":[{"file_id":"1YhqP5st0yiBt4FJofOwY7g6GrzGZWQNW","timestamp":1649105742866},{"file_id":"1P7oU2EWQ1Qk17N9NutZv9FV1a_hMGUoR","timestamp":1647373127550}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["In this notebook, I train a transformer model on the news-commentary-v16 dataset. The main purpose of this notebook is to study how the performance of the model changes as training set size increases. The result is shown in the plots at the end of this notebook."],"metadata":{"id":"yd1lsrsvrbOB"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My\\ Drive/ML/Transformers\n","!ls"],"metadata":{"id":"ToFDXgFP5fys","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651015065084,"user_tz":240,"elapsed":2096,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"a40c47d8-b383-489c-b4ac-9ef548758a5a"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/My Drive/ML/Transformers\n"," Annotated_Transformer_English_to_Chinese_Translator.py\n","'Copy of Transformer_Chinese_To_English_Translation_v4_scaling_dataset_size.ipynb'\n"," data\n"," data.json\n"," data.pkl\n","'Encoder_decoder_transformer (1).ipynb'\n"," Encoder_decoder_transformer1.ipynb\n"," Encoder_decoder_transformer.ipynb\n"," EncoderOnlyTransformer\n"," Encoder_only_transformer_AG_News.ipynb\n"," Encoder_only_transformer_ArXiv.ipynb\n","'Encoder_only Transformer_MovieReviews_2.ipynb'\n","'Encoder_only Transformer_MovieReviews.ipynb'\n"," Encoder_only_transformer_Prime.ipynb\n"," Encoder_only_transformer_v2.ipynb\n","'Encoder_only_transformer_v3 copy.ipynb'\n"," en.model\n","'en_sp_model 2.model'\n","'en_sp_model 2.vocab'\n"," en_sp_model.model\n"," en_sp_model.vocab\n"," en_to_zh_model.pt\n"," en.vocab\n"," FullTransformerModel.py\n"," main.py\n"," m.model\n"," models\n"," m.vocab\n"," newsdata\n"," __pycache__\n"," results_model_size_34155312.txt\n"," results_news-commentary-v16_only_3.json\n"," results_news-commentary-v16_only.json\n"," results.text\n"," results.txt\n"," saved_models\n"," saved_models_news-commentary-v16_only\n"," saved_models_news-commentary-v16_only_3\n"," saved_models_news-commentary-v16_only_4\n"," saveresults1.json\n"," saveresults.json\n"," scratch\n"," Transformer_Chinese_English_Translation.ipynb\n"," Transformer_Chinese_English_Translation_v3.ipynb\n"," Transformer_Chinese_To_English_Translation_large_dataset.ipynb\n"," Transformer_Chinese_To_English_Translation_Large_data_set.ipynb\n"," Transformer_Chinese_To_English_Translation_news-commentary-v16.ipynb\n"," Transformer_Chinese_To_English_Translation_news-commentary-v16_with_other_test_set.ipynb\n"," Transformer_Chinese_To_English_Translation_v2.ipynb\n"," Transformer_Chinese_To_English_Translation_v2_TPU.ipynb\n","'Transformer_Chinese_To_English_Translation_v3 copy.ipynb'\n"," Transformer_Chinese_To_English_Translation_v4_scaling_dataset_size.ipynb\n"," Transformer_Chinese_To_English_Translation_v5_scaling_dataset_size_33k_news.ipynb\n"," Transformer_English_to_Chinese_Translation_v5_scaling_dataset_size_33k_news.ipynb\n"," Transformer_English_to_Chinese_Translation_v6_scaling_dataset_size_33k_news.ipynb\n","'Transformer_multi30k_de_to_en 2'\n"," Transformer_Multi30k_German_to_English.ipynb\n"," Transformer_multi30k.ipynb\n"," transformer_tutorial.ipynb\n"," zh.model\n","'zh_sp_model 2.model'\n","'zh_sp_model 2.vocab'\n"," zh_sp_model.model\n"," zh_sp_model.vocab\n"," zh.vocab\n"]}]},{"cell_type":"code","source":["!pip install sentencepiece --quiet\n","!pip install sacrebleu --quiet\n","!pip install torchinfo"],"metadata":{"id":"0sqP4-qcOb4o","executionInfo":{"status":"ok","timestamp":1651015074475,"user_tz":240,"elapsed":9392,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2801e8ed-d051-4ae7-f74e-5ac8ac340c0b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.6.5)\n"]}]},{"cell_type":"code","source":["import math\n","from dataclasses import dataclass\n","\n","import numpy as np\n","import sacrebleu\n","import sentencepiece as spm\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset\n","from tqdm import tqdm\n","import pandas\n","torch.manual_seed(0)\n","import random\n","random.seed(0)\n","import  pathlib\n","import json\n","import matplotlib.pyplot as plt\n","from torchinfo import summary\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(DEVICE)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6q1qOB9VZzEE","executionInfo":{"status":"ok","timestamp":1651015076496,"user_tz":240,"elapsed":2025,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"e94a6c73-4632-4bc6-9897-710ac7af0947"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","execution_count":4,"outputs":[],"source":["SRC = \"zh\"\n","TRG = \"en\"\n","en_vocab_size = 30000\n","zh_vocab_size = 30000\n","vocab_sizes = {\"en\": en_vocab_size, \"zh\": zh_vocab_size}\n","max_seq_len = 50"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"D0IsEl-22pHS","executionInfo":{"status":"ok","timestamp":1651015076497,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["# Get English and Chinese tokenizers\n","\n","I use [SentencePiece](https://github.com/google/sentencepiece) to get both the Chinese and English tokenizers. \n","\n","The news-commentary-v16 dataset can be downloaded from https://data.statmt.org/news-commentary/v16/training/.\n","\n","The validation set and test set I used are simply sampled from the news-commentary-v16 dataset, both with a size of 5000.\n"],"metadata":{"id":"Jq10RHNKZTDo"}},{"cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["303674 5000 5000\n","('Unfortunately, the outcome could be similar: the entire banking system sent into a tailspin.', '不幸的是结果可能重蹈覆辙： 整个银行系统可能因此陷入一片狼藉。')\n","('First, “genetic engineering cannot solve the hunger and food insecurity problem.”', '想一想汽车的发明就造成了多少轮下冤魂，更不用说各种药物的副作用了。')\n","('Indeed, the time is ripe to offer assurances to the isolated Syrian regime that blocking Hezbollah’s rearmament, stopping Islamist fighters’ passage into Iraq, and improving the country’s appalling human rights record would bring valuable diplomatic and economic benefits, including a strengthened association agreement with the EU.', '的确，给备受孤立的叙利亚政权一些安慰的时机已经成熟。 要让其明白封锁真主党的军备，阻止伊斯兰好战分子进入伊拉克并改善自身触目惊心的人权记录会给它带来外交和经济上的实惠，其中包括强化与欧盟的联合协定。')\n"]}],"source":["full_set = pandas.read_csv('data/news-commentary-v16.en-zh.tsv',\n","                           sep='\\t', header=None)\n","full_set = [(full_set[0][i], full_set[1][i]) for i in range(len(full_set[0]))\n","          if not isinstance(full_set[0][i], float) and not isinstance(full_set[1][i], float)]\n","random.shuffle(full_set)\n","# Note that some translations are really bad, and somehow news-commentary-v16 seems to \n","# be one of the popular (small) training set...\n","full_train_set, valid_set, test_set= torch.utils.data.random_split(\n","                                        full_set, [len(full_set)-10000, 5000, 5000],\n","                                        generator=torch.Generator().manual_seed(42))\n","print(len(full_train_set), len(valid_set), len(test_set))\n","for i in range(3):\n","    print(full_train_set[i])"],"metadata":{"pycharm":{"name":"#%%\n"},"colab":{"base_uri":"https://localhost:8080/"},"id":"uYeNHJeo2pHV","executionInfo":{"status":"ok","timestamp":1651015087724,"user_tz":240,"elapsed":11231,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"2bd3dd97-423f-44ad-a29f-39ddab2a3c7e"}},{"cell_type":"code","execution_count":6,"outputs":[],"source":["def get_tokenizers(dataset, train_set_size):\n","    en_file = f'data/zh-en_corpus_en_trainsize_{train_set_size}.txt'\n","    zh_file = f'data/zh-en_corpus_zh_trainsize_{train_set_size}.txt'\n","    en_sp_model = f'zh-en_en_trainsize_{train_set_size}'\n","    zh_sp_model = f'zh-en_zh_trainsize_{train_set_size}'\n","    f_en = open(en_file, \"w\")\n","    f_zh = open(zh_file, \"w\")\n","    for pair in list(dataset)[0:train_set_size]:\n","        f_en.write(pair[0] + '\\n')\n","        f_zh.write(pair[1] + '\\n')\n","    f_en.close()\n","    f_zh.close()\n","    # train sentencepiece models to get tokenizers\n","    spm.SentencePieceTrainer.train\\\n","        (f'--input={en_file} --model_prefix=en_sp_model  --user_defined_symbols=<pad> --vocab_size={en_vocab_size}')\n","    spm.SentencePieceTrainer.train\\\n","        (f'--input={zh_file} --model_prefix=zh_sp_model --user_defined_symbols=<pad> --vocab_size={zh_vocab_size}')\n","\n","    # make SentencePieceProcessor instances and load the model files\n","    en_sp = spm.SentencePieceProcessor()\n","    en_sp.load(f'en_sp_model.model')\n","    zh_sp = spm.SentencePieceProcessor()\n","    zh_sp.load(f'zh_sp_model.model')\n","\n","    tokenizers = {\"en\": en_sp.encode_as_ids, \"zh\": zh_sp.encode_as_ids}\n","    detokenizers = {\"en\":en_sp.decode_ids, \"zh\":zh_sp.decode_ids}\n","    id_to_pieces = {\"en\":en_sp.id_to_piece, \"zh\":zh_sp.id_to_piece}\n","    return tokenizers, detokenizers, id_to_pieces"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"sx8FQyqr2pHW","executionInfo":{"status":"ok","timestamp":1651015087724,"user_tz":240,"elapsed":9,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[4352, 2036, 5]\n","[90, 14, 10, 1551, 6]\n","['<unk>', '<s>', '</s>', '<pad>', ',', '。', '▁', '的', '▁—', '和', '、', '在', '(', '是', '“', ')', '了', '对', '年', '而']\n","['<unk>', '<s>', '</s>', '<pad>', ',', '▁the', '.', '▁to', '▁of', '▁and', '▁a', '▁in', 's', '▁that', '▁is', '-', '’', '▁', '▁for', '▁–']\n"]}],"source":["tokenizers, detokenizers, id_to_pieces = get_tokenizers(full_train_set, 50000)\n","print(tokenizers['zh']('这是一个测试。'))\n","print(tokenizers['en']('This is a test.'))\n","print([id_to_pieces['zh'](id) for id in range(20)])\n","print([id_to_pieces['en'](id) for id in range(20)])"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"VYTeASBf2pHX","executionInfo":{"status":"ok","timestamp":1651015105778,"user_tz":240,"elapsed":18062,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6d503997-870f-48a1-ca0e-dbb83eeef2ef"}},{"cell_type":"code","execution_count":8,"outputs":[],"source":["# indexes of special symbols\n","UNK, BOS, EOS, PAD = 0, 1, 2, 3"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"_ZPPGzun2pHY","executionInfo":{"status":"ok","timestamp":1651015105779,"user_tz":240,"elapsed":5,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["# Data processing"],"metadata":{"collapsed":false,"id":"OuOHh7fF5Tn8"}},{"cell_type":"code","source":["def tokenize_dataset(dataset):\n","    'tokenize a dataset and add [BOS] and [EOS] to the beginning and end of the sentences'\n","    if SRC == \"zh\":\n","        return [(torch.tensor([BOS]+tokenizers[SRC](src_text)[0:max_seq_len-2]+[EOS]),\n","                 torch.tensor([BOS]+tokenizers[TRG](trg_text)[0:max_seq_len-2]+[EOS]))\n","                 for trg_text, src_text in dataset]\n","    else:\n","        return [(torch.tensor([BOS]+tokenizers[SRC](src_text)[0:max_seq_len-2]+[EOS]),\n","                 torch.tensor([BOS]+tokenizers[TRG](trg_text)[0:max_seq_len-2]+[EOS]))\n","                 for src_text, trg_text in dataset]\n"],"metadata":{"id":"jh3Nxm7VaHIQ","executionInfo":{"status":"ok","timestamp":1651015105779,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","execution_count":10,"outputs":[],"source":["class TranslationDataset(Dataset):\n","    'create a dataset for torch.utils.data.DataLoader() '\n","    def __init__(self, data):\n","        self.data = data\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        return self.data[idx]\n","\n","\n","def pad_sequence(batch):\n","    'collate function for padding sentences such that all \\\n","    the sentences in the batch have the same length'\n","    src_seqs  = [src for src, trg in batch]\n","    trg_seqs  = [trg for src, trg in batch]\n","    src_padded = torch.nn.utils.rnn.pad_sequence(src_seqs,\n","                                batch_first=True, padding_value = PAD)\n","    trg_padded = torch.nn.utils.rnn.pad_sequence(trg_seqs,\n","                                batch_first=True, padding_value = PAD)\n","    return src_padded, trg_padded\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"LECqNTzf2pHZ","executionInfo":{"status":"ok","timestamp":1651015105779,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":11,"outputs":[],"source":["batch_size = 128\n","\n","class Dataloaders:\n","    'Dataloaders contains train_loader, test_loader and valid_loader for training and evaluation '\n","    def __init__(self, train_set_size):\n","        train_set = list(full_train_set)[0:train_set_size]\n","        train_dataset = TranslationDataset(tokenize_dataset(train_set))\n","        valid_dataset = TranslationDataset(tokenize_dataset(valid_set))\n","        test_dataset  = TranslationDataset(tokenize_dataset(test_set))\n","\n","        # each batch returned by dataloader will be padded such that all the texts in\n","        # that batch have the same length as the longest text in that batch\n","        self.train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n","                                                shuffle=True, collate_fn = pad_sequence)\n","\n","        self.test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n","                                                shuffle=True, collate_fn=pad_sequence)\n","\n","        self.valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size,\n","                                                shuffle=True, collate_fn=pad_sequence)\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"8KeJiWat5ToD","executionInfo":{"status":"ok","timestamp":1651015105780,"user_tz":240,"elapsed":5,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["# Transformer Model"],"metadata":{"id":"6t5Bkt_LOu0p"}},{"cell_type":"code","source":["class MultiHeadedAttention(nn.Module):\n","    def __init__(self, h, d_embed, dropout=0.0):\n","        super(MultiHeadedAttention, self).__init__()\n","        assert d_embed % h == 0 # check the h number\n","        self.d_k = d_embed//h\n","        self.d_embed = d_embed\n","        self.h = h\n","        self.WQ = nn.Linear(d_embed, d_embed)\n","        self.WK = nn.Linear(d_embed, d_embed)\n","        self.WV = nn.Linear(d_embed, d_embed)\n","        self.linear = nn.Linear(d_embed, d_embed)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x_query, x_key, x_value, mask=None):\n","        nbatch = x_query.size(0) # get batch size\n","        # 1) Linear projections to get the multi-head query, key and value tensors\n","        # x_query, x_key, x_value dimension: nbatch * seq_len * d_embed\n","        # LHS query, key, value dimensions: nbatch * h * seq_len * d_k\n","        query = self.WQ(x_query).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        key   = self.WK(x_key).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        value = self.WV(x_value).view(nbatch, -1, self.h, self.d_k).transpose(1,2)\n","        # 2) Attention\n","        # scores has dimensions: nbatch * h * seq_len * seq_len\n","        scores = torch.matmul(query, key.transpose(-2, -1))/math.sqrt(self.d_k)\n","        # 3) Mask out padding tokens and future tokens\n","        if mask is not None:\n","            scores = scores.masked_fill(mask, float('-inf'))\n","        # p_atten dimensions: nbatch * h * seq_len * seq_len\n","        p_atten = torch.nn.functional.softmax(scores, dim=-1)\n","        p_atten = self.dropout(p_atten)\n","        # x dimensions: nbatch * h * seq_len * d_k\n","        x = torch.matmul(p_atten, value)\n","        # x now has dimensions:nbtach * seq_len * d_embed\n","        x = x.transpose(1, 2).contiguous().view(nbatch, -1, self.d_embed)\n","        return self.linear(x) # final linear layer\n","\n","\n","class ResidualConnection(nn.Module):\n","  '''residual connection: x + dropout(sublayer(layernorm(x))) '''\n","  def __init__(self, dim, dropout):\n","      super().__init__()\n","      self.drop = nn.Dropout(dropout)\n","      self.norm = nn.LayerNorm(dim)\n","\n","  def forward(self, x, sublayer):\n","      return x + self.drop(sublayer(self.norm(x)))\n","\n","# I simply let the model learn the positional embeddings in this notebook, since this \n","# almost produces identital results as using sin/cosin functions embeddings, as claimed\n","# in the original transformer paper. Note also that in the original paper, they multiplied \n","# the token embeddings by a factor of sqrt(d_embed), which I do not do here. \n","\n","class Encoder(nn.Module):\n","    '''Encoder = token embedding + positional embedding -> a stack of N EncoderBlock -> layer norm'''\n","    def __init__(self, config):\n","        super().__init__()\n","        self.d_embed = config.d_embed\n","        self.tok_embed = nn.Embedding(config.encoder_vocab_size, config.d_embed) \n","        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n","        self.encoder_blocks = nn.ModuleList([EncoderBlock(config) for _ in range(config.N_encoder)])\n","        self.dropout = nn.Dropout(config.dropout)\n","        self.norm = nn.LayerNorm(config.d_embed)\n","\n","    def forward(self, input, mask=None):\n","        x = self.tok_embed(input)\n","        x_pos = self.pos_embed[:, :x.size(1), :]\n","        x = self.dropout(x + x_pos)\n","        for layer in self.encoder_blocks:\n","            x = layer(x, mask)\n","        return self.norm(x)\n","\n","\n","class EncoderBlock(nn.Module):\n","    '''EncoderBlock: self-attention -> position-wise fully connected feed-forward layer'''\n","    def __init__(self, config):\n","        super(EncoderBlock, self).__init__()\n","        self.atten = MultiHeadedAttention(config.h, config.d_embed, config.dropout)\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(config.d_embed, config.d_ff),\n","            nn.ReLU(),\n","            nn.Dropout(config.dropout),\n","            nn.Linear(config.d_ff, config.d_embed)\n","        )\n","        self.residual1 = ResidualConnection(config.d_embed, config.dropout)\n","        self.residual2 = ResidualConnection(config.d_embed, config.dropout)\n","\n","    def forward(self, x, mask=None):\n","        # self-attention\n","        x = self.residual1(x, lambda x: self.atten(x, x, x, mask=mask))\n","        # position-wise fully connected feed-forward layer\n","        return self.residual2(x, self.feed_forward)\n","\n","\n","class Decoder(nn.Module):\n","    '''Decoder = token embedding + positional embedding -> a stack of N DecoderBlock -> fully-connected layer'''\n","    def __init__(self, config):\n","        super().__init__()\n","        self.d_embed = config.d_embed\n","        self.tok_embed = nn.Embedding(config.decoder_vocab_size, config.d_embed)\n","        self.pos_embed = nn.Parameter(torch.zeros(1, config.max_seq_len, config.d_embed)) \n","        self.dropout = nn.Dropout(config.dropout)\n","        self.decoder_blocks = nn.ModuleList([DecoderBlock(config) for _ in range(config.N_decoder)])\n","        self.norm = nn.LayerNorm(config.d_embed)\n","        self.linear = nn.Linear(config.d_embed, config.decoder_vocab_size)\n","    \n","    def future_mask(self, seq_len):\n","        '''mask out tokens at future positions'''\n","        mask = (torch.triu(torch.ones(seq_len, seq_len, requires_grad=False), diagonal=1)!=0).to(DEVICE)\n","        return mask.view(1, 1, seq_len, seq_len)\n","\n","    def forward(self, memory, src_mask, trg, trg_pad_mask):\n","        seq_len = trg.size(1)\n","        trg_mask = torch.logical_or(trg_pad_mask, self.future_mask(seq_len))\n","        x = self.tok_embed(trg) + self.pos_embed[:, :trg.size(1), :]\n","        x = self.dropout(x)\n","        for layer in self.decoder_blocks:\n","            x = layer(memory, src_mask, x, trg_mask)\n","        x = self.norm(x)\n","        logits = self.linear(x)\n","        return logits\n","\n","\n","class DecoderBlock(nn.Module):\n","    ''' EncoderBlock: self-attention -> position-wise feed-forward (fully connected) layer'''\n","    def __init__(self, config):\n","        super().__init__()\n","        self.atten1 = MultiHeadedAttention(config.h, config.d_embed)\n","        self.atten2 = MultiHeadedAttention(config.h, config.d_embed)\n","        self.feed_forward = nn.Sequential(\n","            nn.Linear(config.d_embed, config.d_ff),\n","            nn.ReLU(),\n","            nn.Dropout(config.dropout),\n","            nn.Linear(config.d_ff, config.d_embed)\n","        )\n","        self.residuals = nn.ModuleList([ResidualConnection(config.d_embed, config.dropout) \n","                                       for i in range(3)])\n","\n","    def forward(self, memory, src_mask, decoder_layer_input, trg_mask):\n","        x = memory\n","        y = decoder_layer_input\n","        y = self.residuals[0](y, lambda y: self.atten1(y, y, y, mask=trg_mask))\n","        # keys and values are from the encoder output\n","        y = self.residuals[1](y, lambda y: self.atten2(y, x, x, mask=src_mask))\n","        return self.residuals[2](y, self.feed_forward)\n","\n","\n","class Transformer(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src, src_mask, trg, trg_pad_mask):\n","        return self.decoder(self.encoder(src, src_mask), src_mask, trg, trg_pad_mask)"],"metadata":{"id":"NEDuoQWT6nZA","executionInfo":{"status":"ok","timestamp":1651015106322,"user_tz":240,"elapsed":547,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["@dataclass\n","class ModelConfig:\n","    encoder_vocab_size: int\n","    decoder_vocab_size: int\n","    d_embed: int\n","    # d_ff is the dimension of the fully-connected  feed-forward layer\n","    d_ff: int\n","    # h is the number of attention head\n","    h: int\n","    N_encoder: int\n","    N_decoder: int\n","    max_seq_len: int\n","    dropout: float\n","\n","def make_model(config):\n","    model = Transformer(Encoder(config), Decoder(config)).to(DEVICE)\n","\n","    # initialize model parameters\n","    # it seems that this initialization is very important!\n","    for p in model.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","    return model"],"metadata":{"id":"gxYYnrC-FAgI","executionInfo":{"status":"ok","timestamp":1651015106323,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Training and evaluation helper functions"],"metadata":{"id":"g0Gxt98hyuad"}},{"cell_type":"code","execution_count":14,"outputs":[],"source":["def make_batch_input(x, y):\n","        src = x.to(DEVICE)\n","        trg_in = y[:, :-1].to(DEVICE)\n","        trg_out = y[:, 1:].contiguous().view(-1).to(DEVICE)\n","        src_pad_mask = (src == PAD).view(src.size(0), 1, 1, src.size(-1))\n","        trg_pad_mask = (trg_in == PAD).view(trg_in.size(0), 1, 1, trg_in.size(-1))\n","        return src, trg_in, trg_out, src_pad_mask, trg_pad_mask"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"1Bv9bdWZ2pHa","executionInfo":{"status":"ok","timestamp":1651015106323,"user_tz":240,"elapsed":3,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":15,"outputs":[],"source":["def train_epoch(model, dataloaders):\n","    model.train()\n","    grad_norm_clip = 1.0\n","    losses, acc, count = [], 0, 0\n","    num_batches = len(dataloaders.train_loader)\n","    pbar = tqdm(enumerate(dataloaders.train_loader), total=num_batches)\n","    for idx, (x, y)  in  pbar:\n","        optimizer.zero_grad()\n","        src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n","        pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n","        pred = pred.view(-1, pred.size(-1))\n","        loss = loss_fn(pred, trg_out).to(DEVICE)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_norm_clip)\n","        optimizer.step()\n","        scheduler.step()\n","        losses.append(loss.item())\n","        # report progress\n","        if idx>0 and idx%50 == 0:\n","            pbar.set_description(f'train loss={loss.item():.3f}, lr={scheduler.get_last_lr()[0]:.5f}')\n","    return np.mean(losses)\n","\n","\n","def train(model, dataloaders, epochs = 10):\n","    global early_stop_count\n","    best_valid_loss = float('inf')\n","    train_size = len(dataloaders.train_loader)*batch_size\n","    for ep in range(epochs):\n","        train_loss = train_epoch(model, dataloaders)\n","        valid_loss = validate(model, dataloaders.valid_loader)\n","\n","        print(f'ep: {ep}: train_loss={train_loss:.5f}, valid_loss={valid_loss:.5f}')\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","        else:\n","            if scheduler.last_epoch>1.5*warmup_steps:\n","                early_stop_count -= 1\n","                if early_stop_count<=0:\n","                    return train_loss, valid_loss\n","    return train_loss, valid_loss\n","\n","\n","def validate(model, dataloder):\n","    'compute the validation loss'\n","    model.eval()\n","    losses = []\n","    with torch.no_grad():\n","        for i, (x, y) in enumerate(dataloder):\n","            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n","            pred = model(src, src_pad_mask, trg_in, trg_pad_mask).to(DEVICE)\n","            pred = pred.view(-1, pred.size(-1))\n","            losses.append(loss_fn(pred, trg_out).item())\n","    return np.mean(losses)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"WN20AeRw2pHa","executionInfo":{"status":"ok","timestamp":1651015106323,"user_tz":240,"elapsed":3,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":16,"outputs":[],"source":["def translate(model, x):\n","    'translate source sentences into the target language, without looking at the answer'\n","    with torch.no_grad():\n","        dB = x.size(0)\n","        y = torch.tensor([[BOS]*dB]).view(dB, 1).to(DEVICE)\n","        x_pad_mask = (x == PAD).view(x.size(0), 1, 1, x.size(-1)).to(DEVICE)\n","        memory = model.encoder(x, x_pad_mask)\n","        for i in range(max_seq_len):\n","            y_pad_mask = (y == PAD).view(y.size(0), 1, 1, y.size(-1)).to(DEVICE)\n","            logits = model.decoder(memory, x_pad_mask, y, y_pad_mask)\n","            last_output = logits.argmax(-1)[:, -1]\n","            last_output = last_output.view(dB, 1)\n","            y = torch.cat((y, last_output), 1).to(DEVICE)\n","    return y"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"krLExLOU2pHa","executionInfo":{"status":"ok","timestamp":1651015106323,"user_tz":240,"elapsed":3,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"code","execution_count":17,"outputs":[],"source":["def remove_pad(sent):\n","    '''truncate the sentence if BOS is in it,\n","     otherwise simply remove the padding tokens at the end'''\n","    if sent.count(EOS)>0:\n","      sent = sent[0:sent.index(EOS)+1]\n","    while sent and sent[-1] == PAD:\n","            sent = sent[:-1]\n","    return sent\n","\n","def decode_sentence(detokenizer, sentence_ids):\n","    'convert a tokenized sentence (a list of numbers) to a literal string'\n","    if not isinstance(sentence_ids, list):\n","        sentence_ids = sentence_ids.tolist()\n","    sentence_ids = remove_pad(sentence_ids)\n","    return detokenizer(sentence_ids).replace(\"<bos>\", \"\")\\\n","           .replace(\"<eos>\", \"\").strip().replace(\" .\", \".\")\n","\n","def evaluate(model, dataloader, num_batch=None):\n","    'evaluate the model, and compute the BLEU score'\n","    model.eval()\n","    refs, cans, bleus = [], [], []\n","    with torch.no_grad():\n","        for idx, (x, y) in enumerate(dataloader):\n","            src, trg_in, trg_out, src_pad_mask, trg_pad_mask = make_batch_input(x,y)\n","            translation = translate(model, src)\n","            trg_out = trg_out.view(x.size(0), -1)\n","            refs = refs + [decode_sentence(detokenizers[TRG], trg_out[i]) for i in range(len(src))]\n","            cans = cans + [decode_sentence(detokenizers[TRG], translation[i]) for i in range(len(src))]\n","            if num_batch and idx>=num_batch:\n","                break\n","        bleus.append(sacrebleu.corpus_bleu(cans, [refs]).score)\n","        # print some examples\n","        for i in range(3):\n","            print(f'src:  {decode_sentence(detokenizers[SRC], src[i])}')\n","            print(f'trg:  {decode_sentence(detokenizers[TRG], trg_out[i])}')\n","            print(f'pred: {decode_sentence(detokenizers[TRG], translation[i])}')\n","        return np.mean(bleus)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"dUsGrq6fOKbC","executionInfo":{"status":"ok","timestamp":1651015106324,"user_tz":240,"elapsed":4,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}}},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"TDwtARkfyxFT"}},{"cell_type":"code","execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size: 90301744, train_set_size: 50000\n"]},{"output_type":"stream","name":"stderr","text":["train loss=5.803, lr=0.00025: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 0: train_loss=7.16572, valid_loss=5.70710\n"]},{"output_type":"stream","name":"stderr","text":["train loss=4.925, lr=0.00053: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 1: train_loss=5.28044, valid_loss=4.96857\n"]},{"output_type":"stream","name":"stderr","text":["train loss=4.586, lr=0.00081: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 2: train_loss=4.61512, valid_loss=4.56164\n"]},{"output_type":"stream","name":"stderr","text":["train loss=4.222, lr=0.00109: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 3: train_loss=4.13859, valid_loss=4.31094\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.724, lr=0.00101: 100%|██████████| 391/391 [02:53<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 4: train_loss=3.70600, valid_loss=4.03408\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.425, lr=0.00092: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 5: train_loss=3.23047, valid_loss=3.84232\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.776, lr=0.00085: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 6: train_loss=2.81466, valid_loss=3.75483\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.572, lr=0.00080: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 7: train_loss=2.44972, valid_loss=3.72455\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.179, lr=0.00075: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 8: train_loss=2.12793, valid_loss=3.76023\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.872, lr=0.00071: 100%|██████████| 391/391 [02:54<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 9: train_loss=1.84212, valid_loss=3.83727\n","train set examples:\n","src:  为改革进程融资 — — 更不要说筹集高达2万亿规模的公共投资资金以支持后石油时期经济 — — 将需要提高工作效率、实现快速私有化、建立有效的公私伙伴关系、采纳基础广泛的税收制度(包括将于2018年开始实行的5%\n","trg:  Financing the reforms – not to mention a massive $2 trillion public investment fund to support a post-oil economy – will require improved efficiency, rapid privatization, effective public-private partnerships, broad-based taxation (including a value-added tax\n","pred: To establish such a program – not to mention a $1 trillion investment fund the economy’s economy – will require rapid public investment, increase efficiency, and establish basic public-private partnerships (by accompanied rapid institutional reform, creating effective public-\n","src:  在职业女性这一方面,日本就好像是发达国家中的沙特阿拉伯。\n","trg:  For women in the workplace, Japan remains the Saudi Arabia of the developed world.\n","pred: In this sense, women are seeking to do so in the developed world, as if Saudi Arabia is Saudi Arabia.\n","src:  这相当于亲西方势力在中东地区获胜。\n","trg:  This would amount to a win for pro-Western forces in the Middle East.\n","pred: That would be a win-win bloc in the Middle East.\n","validation set examples:\n","src:  当中国的贸易顺差规模已经大幅缩小,经济增长对出口的依赖也进一步减轻之时,人民币的升值本应更早更快的启动,但这一进程的延迟令通过人民币升值来重新平衡经常账户所付出的代价更大。\n","trg:  RMB appreciation should have started earlier and at a faster pace, when China’s trade surplus was much smaller and its growth was much less dependent on exports. Delay has made current-account rebalancing via RMB appreciation costly.\n","pred: As China’s surplus has been falling sharply, the overall contribution of its overall dependence on exports is to further closing, but the process should be reached over time by removing the renminbi from a more immediate intervention.\n","src:  这是一项巨大的工程,包括一个拥有液化天然气船坞的港口和400公里的管道。\n","trg:  This is a huge endeavor, as it also includes a port with an LNG dock and a 400-kilometer pipeline.\n","pred: This is a major project, including a natural oil, which includes a soil-trading plant and a total of groundwater.\n","src:  尽管茶党的追随者 — — 早先的一份民调显示89%为白人,只有1%是黑人 — — 以压倒一切的重要性反对的是政府支出,但他们也接受政府对他们自己的帮助。\n","trg:  Though the Tea Party’s followers – a group that one early opinion poll identified as 89% white and just 1% black – claim to oppose government spending above all else, they accept government help for themselves.\n","pred: While Tea Party supporters – indicate that only 14% of the black white population – are the responsibility of the white white, whose government spending is also the responsibility of the government, despite having the responsibility for having the responsibility of its own\n","test set examples:\n","src:  最大限度地追求一小部分人的利润,而非全球发展和大多数人的福祉,也没有什么意义 — — 除了在当下的权力动态方面。\n","trg:  Maximizing profits for a few, rather than global development and welfare for the many, didn’t make much sense then, either – except in terms of the power dynamics at the time.\n","pred: To maximize the extent of the profits and profits of a single middle class, not to mention the wellbeing of the wellbeing of the global development and most of the global development, is actually capable factor skilled power dynamic.\n","src:  “市场经济”地位绝非小事,因为这意味着更难将中国企业在海外市场的倾销行为视为非法。\n","trg:  That status matters, because achieving it will make it more difficult for Chinese firms to be found guilty of dumping goods on overseas markets.\n","pred: “The market economy is not actually a small, because it means doing more than a Chinese renminbi-made Chinese foreign markets,” which would be regarded as illegal.\n","src:  通缩威胁 — — 以及此前措施的无效 — — 让欧洲央行别无选择。\n","trg:  The threat of deflation – and the ineffectiveness of its previous measures – leaves it no choice.\n","pred: The threat of deflation – and the absence of a bit of previously measures – has made the ECB no choice but to blame.\n","train_loss: 1.8421, valid_loss: 3.8373, test_loss: 3.8281\n","test_bleu: 8.5087, valid_bleu: 8.5102 train_bleu: 19.0236\n","model_size: 90301744, train_set_size: 100000\n"]},{"output_type":"stream","name":"stderr","text":["train loss=5.549, lr=0.00019: 100%|██████████| 782/782 [05:48<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 0: train_loss=6.88474, valid_loss=5.45820\n"]},{"output_type":"stream","name":"stderr","text":["train loss=4.645, lr=0.00039: 100%|██████████| 782/782 [05:48<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 1: train_loss=4.95905, valid_loss=4.47964\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.878, lr=0.00059: 100%|██████████| 782/782 [05:47<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 2: train_loss=4.09503, valid_loss=3.83931\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.285, lr=0.00078: 100%|██████████| 782/782 [05:48<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 3: train_loss=3.45347, valid_loss=3.41427\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.809, lr=0.00071: 100%|██████████| 782/782 [05:49<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 4: train_loss=2.96044, valid_loss=3.03198\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.541, lr=0.00065: 100%|██████████| 782/782 [05:48<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 5: train_loss=2.53580, valid_loss=2.84268\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.181, lr=0.00060: 100%|██████████| 782/782 [05:48<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 6: train_loss=2.21805, valid_loss=2.74874\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.983, lr=0.00056: 100%|██████████| 782/782 [05:48<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 7: train_loss=1.96270, valid_loss=2.71522\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.839, lr=0.00053: 100%|██████████| 782/782 [05:48<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 8: train_loss=1.74683, valid_loss=2.74545\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.652, lr=0.00050: 100%|██████████| 782/782 [05:48<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 9: train_loss=1.56001, valid_loss=2.74348\n","train set examples:\n","src:  它可能是一个例外,反映了各种因素,包括欧元危机、欧洲国家经济持续萎靡、大宗商品价格暴跌、巴西、俄罗斯和其他新兴经济体大幅放缓、国际银行监管收紧(可能拖累贸易融资)等。\n","trg:  It may have been a singular occurrence that reflected a variety of factors, including the euro crisis; continued economic weakness in many European countries; the sharp decline in commodity prices; dramatic slowdowns in Brazil, Russia, and other emerging economies; and\n","pred: It may be a case in which different factors, including the euro crisis, continued economic weakness in Europe, continued commodity prices, a sharp slowdown in Brazil, Russia, and other emerging economies, tighter controls (which may be possible to be\n","src:  中等收入的非经合组织国家 — — 尤其是中国和印度 — — 正逐渐成为高技术劳动力越来越重要的目标国。\n","trg:  Middle-income non-OECD countries – particularly China and India – are becoming an increasingly important destination for high-skilled labor.\n","pred: Non-income countries – especially China and India – are gradually becoming a high-tech labor force.\n","src:  有些分析家甚至预测希腊经济将走向“慢性死亡 ” 。\n","trg:  Some analysts have even predicted a “slow death” of the Greek economy.\n","pred: Some analysts even predict that the Greek economy will move toward a “ persistent death.”\n","validation set examples:\n","src:  没有这一天翻地覆的变化,欧洲就不可能和平、民主地实现统一。\n","trg:  Europe could not have united in peace and democracy without that sea change.\n","pred: Without this shift in the quality of change, Europe is unlikely to be able to achieve peace, democracy.\n","src:  当然,一带一路不是习近平对日益老化的西方主导的国际秩序所提出的唯一挑战。\n","trg:  Of course, OBOR is not the only challenge  ⁇ i has mounted against an aging Western-dominated international order.\n","pred: Of course, the one thing is not  ⁇ i’s only challenge to the increasingly aging Western-dominated international order.\n","src:  矿日持久的欧债危机爆发及充满痛苦的紧缩政策接踵而至后,今天的民粹主义者同样利用了类似的恐惧心理,这样的恐惧心理主要存在于老年劳动者和其他的弱势群体当中。\n","trg:  In the wake of the protracted euro crisis, and the painful austerity that followed, today’s populists have been able to play on similar fears, again primarily among older workers and other vulnerable groups.\n","pred: After the protracted crisis of mining and painful austerity, today’s populists are similarly well suited to the fear that fear is the primary and vulnerable facing older workers and other vulnerable parts.\n","test set examples:\n","src:  按照此类说法,这些国家对资产的需求(无论从数量还是质量上)都无法在国内得到满足,因此他们只得将部分储蓄配置到以美国为首的国家,因为这些国家拥有更多样化的优质资产可供选择。\n","trg:  According to this view, these countries’ demand for assets cannot be met – in terms of both quantity and quality – at home, so they deploy part of their savings to countries like the US, which can offer a more diverse array of quality\n","pred: According to these claims, these countries’ demand for assets (if the number of theirs are at home or at the quality) is not met, so they will have to be repaid, owing to the US-led countries with more diverse\n","src:  他似乎认为,镇压自由主义有利于他推进这一目标的反腐运动。\n","trg:  A crackdown on liberalism, he seems to believe, will work alongside his anti-corruption campaign to advance this goal.\n","pred: He seems to believe that the liberal-democratic drive he has benefited from his bold approach to advance this goal.\n","src:  这就是他们做出的全部许诺。\n","trg:  But not anymore.\n","pred: That is their full promise.\n","train_loss: 1.5600, valid_loss: 2.7435, test_loss: 2.7614\n","test_bleu: 15.9337, valid_bleu: 15.7579 train_bleu: 29.1721\n","model_size: 90301744, train_set_size: 150000\n"]},{"output_type":"stream","name":"stderr","text":["train loss=5.371, lr=0.00016: 100%|██████████| 1172/1172 [08:43<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 0: train_loss=6.71223, valid_loss=5.30126\n"]},{"output_type":"stream","name":"stderr","text":["train loss=4.325, lr=0.00032: 100%|██████████| 1172/1172 [08:43<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 1: train_loss=4.74675, valid_loss=4.16335\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.442, lr=0.00048: 100%|██████████| 1172/1172 [08:43<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 2: train_loss=3.73672, valid_loss=3.37008\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.027, lr=0.00064: 100%|██████████| 1172/1172 [08:43<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 3: train_loss=3.08052, valid_loss=2.95855\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.695, lr=0.00058: 100%|██████████| 1172/1172 [08:42<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 4: train_loss=2.65891, valid_loss=2.64468\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.283, lr=0.00053: 100%|██████████| 1172/1172 [08:43<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 5: train_loss=2.31216, valid_loss=2.49785\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.075, lr=0.00049: 100%|██████████| 1172/1172 [08:42<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 6: train_loss=2.05969, valid_loss=2.43421\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.006, lr=0.00046: 100%|██████████| 1172/1172 [08:41<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 7: train_loss=1.86149, valid_loss=2.35552\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.883, lr=0.00043: 100%|██████████| 1172/1172 [08:41<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 8: train_loss=1.69569, valid_loss=2.35692\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.531, lr=0.00041: 100%|██████████| 1172/1172 [08:41<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 9: train_loss=1.55302, valid_loss=2.37370\n","train set examples:\n","src:  这种约定俗成的责任意识就可以解释为什么哈米德·卡尔扎伊总统的那么多亲信依然在位,也可以解释塔利班领导人为什么仍然安全。\n","trg:  This sense of customary obligation is why so many of President Hamid Karzai’s cronies remain in place and Taliban leaders remain safe.\n","pred: This sense of accountability can explain why so many cronies of President Hamid Karzai remain in office, and why Taliban leaders continue to be safe.\n","src:  如果政客们热衷于互相指责的话,就更加难上加难了。\n","trg:  It becomes harder still when politicians are actively playing the blame game.\n","pred: If politicians are to blame each other, it becomes even harder to do so.\n","src:  而这个情况之所以没有在希腊身上发生就是因为希腊被单一货币捆住了手脚。\n","trg:  It hasn’t happened in Greece only because Greece is trapped in the single currency.\n","pred: This is not what happened in Greece because Greece is trapped by the single currency.\n","validation set examples:\n","src:  无论如何,巴勒斯坦人中间的分歧绝非此次谈判失败的原因。\n","trg:  Regardless, the division among Palestinians cannot be blamed for the talks’ failure this time.\n","pred: In any case, the Palestinians’ differences are not the cause of failure to negotiate.\n","src:  六年后的2016年,税收收入将达6,790亿美元,而退休金总支出将高达7,690亿美元。\n","trg:  Six years later, in 2016, the tax revenue was up to $679 billion and the benefits were up to $769 billion.\n","pred: Six years later, tax revenues will reach $67 billion, and total spending of pensions will amount to $750 billion.\n","src:  此外,保护主义和财政扩张都在强化美元,从而压迫美国出口商以及借入美元的外国人。\n","trg:  Moreover, both protectionism and fiscal expansion are strengthening the dollar, and thus squeezing US exporters and foreigners who have borrowed in dollars.\n","pred: Moreover, protectionism and fiscal expansion are strengthening the dollar, thereby constraining American exporters and borrowing against foreigners in dollars.\n","test set examples:\n","src:  如果特朗普统治威尼斯\n","trg:  If Trump Ruled Venice\n","pred: Trump Chooses Venice\n","src:  随着食品供应量增长的减缓,需求却出现持续增长,而这并不完全是人口的增长所造成的。\n","trg:  As food supply growth slowed, demand continued to grow, and not only due to population increase.\n","pred: As food-supply growth slows, demand continues to rise, which is not fully caused by growth in the population.\n","src:  作为世界上唯一的超级大国的美国对超国家的国际组织表现得不屑一顾并且不遗余力地削弱它们。\n","trg:  The world’s lone superpower, the US, has demonstrated its disdain for supranational institutions and worked assiduously to undermine them.\n","pred: The US, the sole superpower of the world, has been indifferent to the supranational organization and aggressively weakened them.\n","train_loss: 1.5530, valid_loss: 2.3737, test_loss: 2.3639\n","test_bleu: 19.1103, valid_bleu: 18.9378 train_bleu: 29.8618\n","model_size: 90301744, train_set_size: 200000\n"]},{"output_type":"stream","name":"stderr","text":["train loss=5.110, lr=0.00014: 100%|██████████| 1563/1563 [11:34<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 0: train_loss=6.60322, valid_loss=5.19853\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.986, lr=0.00028: 100%|██████████| 1563/1563 [11:34<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 1: train_loss=4.57244, valid_loss=3.92268\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.220, lr=0.00042: 100%|██████████| 1563/1563 [11:34<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 2: train_loss=3.48024, valid_loss=3.07887\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.932, lr=0.00056: 100%|██████████| 1563/1563 [11:33<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 3: train_loss=2.85324, valid_loss=2.75454\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.387, lr=0.00050: 100%|██████████| 1563/1563 [11:33<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 4: train_loss=2.47821, valid_loss=2.44443\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.167, lr=0.00046: 100%|██████████| 1563/1563 [11:34<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 5: train_loss=2.17633, valid_loss=2.32082\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.120, lr=0.00042: 100%|██████████| 1563/1563 [11:35<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 6: train_loss=1.96161, valid_loss=2.24451\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.921, lr=0.00040: 100%|██████████| 1563/1563 [11:34<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 7: train_loss=1.79288, valid_loss=2.21627\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.700, lr=0.00037: 100%|██████████| 1563/1563 [11:33<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 8: train_loss=1.65366, valid_loss=2.20177\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.642, lr=0.00035: 100%|██████████| 1563/1563 [11:33<00:00,  2.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 9: train_loss=1.53369, valid_loss=2.19280\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.495, lr=0.00034: 100%|██████████| 1563/1563 [11:33<00:00,  2.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 10: train_loss=1.42787, valid_loss=2.23528\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.379, lr=0.00032: 100%|██████████| 1563/1563 [11:34<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 11: train_loss=1.33488, valid_loss=2.22834\n","train set examples:\n","src:  鉴于议程所涉及的范畴(我能想到至少有六大主题需要单独谈判 ) , 谈判过程可能需要数年才能完成。\n","trg:  Given the scope of the agenda (I can think of at least six major topics that will demand their own negotiations), the process could take several years.\n","pred: Given the scale of the agenda (which I can imagine at least six topics that need to negotiate separately), the process could take years to complete.\n","src:  你在加沙看到的惊人数量的孩子将会继承一个什么样的世界? 集体惩罚能否将他们变成温和、守法的希洛奴隶?\n","trg:  What type of world will the children you see in such prodigious numbers in Gaza inherit? Will collective punishment make them moderate, law-abiding helots?\n","pred: What will happen to the world that one child of the terrible number of children in Gaza will inherit? Will collective punishment make them moderate, law-abiding?\n","src:  对领导能力的学习有许多种途径,从经验中学习是其中最常见、也是最有力的方式,它带给人们在危机中至关重要的习惯知识。\n","trg:  Learning leadership occurs in a variety of ways. Learning from experience is the most common and most powerful.\n","pred: There are many ways to learn from leadership, and to learn from experience is one of the most common and most powerful ways that bring about the most critical habits of people in a crisis.\n","validation set examples:\n","src:  如今基本的模式并未改变,改善的只是传播虚假信息的速度和成本。\n","trg:  What is new is not the basic model, but the high speed and low cost of spreading disinformation.\n","pred: Now the base pattern has changed, and improving is simply the speed and cost of disinformation.\n","src:  随后,俄罗斯新闻报道,中国、俄罗斯和印度将在今年底前举行代号为“因德拉2005”的三国军事演习。\n","trg:  This was followed by Russian news reports that China, Russia, and India would conduct trilateral military exercises, named “Indira 2005,” on the same scale before the end of this year.\n","pred: Then, Russian news reports indicate that China, Russia, and India will host the “Mangle” military exercise before the end of this year.\n","src:  巴勒斯坦也有强大的妇女运动(巴勒斯坦是第一个给予妇女投票权的阿拉伯国家,1946年)\n","trg:  Palestine also has a powerful women’s movement (Palestine being the first Arab country to give women the vote, in 1946).\n","pred: Palestine also has a strong women movement (the first Arab country to give women the right vote in 1946), and the Palestinians were the only Asian country that they had the right to vote.\n","test set examples:\n","src:  美国顶尖1%家庭的金融财富上涨了50 % , 而底层90%家庭只获得12%的利润。\n","trg:  The top 1% of US households have enjoyed a 50% gain in their financial wealth, while the bottom 90% have registered only a 12% profit.\n","pred: Financial wealth for the top 1% of households is now about 50%, while the bottom 90% receive only 12% of the profits.\n","src:  哥本哈根共识中心研究者在考察孟加拉国应对全球变暖的方法时发现,增加农业劳动力生产率“是加强孟加拉国面对气候变化的恢复力、实现长期发展目标的唯一方法 。 ”\n","trg:  When Copenhagen Consensus researchers examined responses to global warming in Bangladesh, they found that increasing agricultural labor productivity “is the only way to increase the resilience of Bangladesh to climate change and to meet long-term development goals.”\n","pred: As the Copenhagen Consensus researchers learned in examining ways to tackle global warming, increasing agricultural productivity “the only way to strengthen Bangladesh’s resilience against climate change and achieve its long-term development goals.”\n","src:  ICTY做出了公平的裁决,提供了有意义的上诉机会,既做出了重大的有罪判决,也做出了重大的无罪赦免判决。\n","trg:  It has conducted fair trials and has provided a meaningful appellate process that has led to significant convictions and equally significant acquittals.\n","pred: The ICTY’s fair ruling, which provided opportunities for meaningful appeal, has made a major criminal decision, and has offered a major pardon for the verdicts.\n","train_loss: 1.3349, valid_loss: 2.2283, test_loss: 2.2352\n","test_bleu: 20.8973, valid_bleu: 20.7770 train_bleu: 35.1290\n","model_size: 90301744, train_set_size: 250000\n"]},{"output_type":"stream","name":"stderr","text":["train loss=5.095, lr=0.00012: 100%|██████████| 1954/1954 [14:28<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 0: train_loss=6.51223, valid_loss=5.11890\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.841, lr=0.00025: 100%|██████████| 1954/1954 [14:30<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 1: train_loss=4.43651, valid_loss=3.70764\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.984, lr=0.00037: 100%|██████████| 1954/1954 [14:28<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 2: train_loss=3.28879, valid_loss=2.91204\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.649, lr=0.00050: 100%|██████████| 1954/1954 [14:29<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 3: train_loss=2.70645, valid_loss=2.57289\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.453, lr=0.00045: 100%|██████████| 1954/1954 [14:30<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 4: train_loss=2.37184, valid_loss=2.32862\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.026, lr=0.00041: 100%|██████████| 1954/1954 [14:30<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 5: train_loss=2.10098, valid_loss=2.20752\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.874, lr=0.00038: 100%|██████████| 1954/1954 [14:30<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 6: train_loss=1.91169, valid_loss=2.14728\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.857, lr=0.00035: 100%|██████████| 1954/1954 [14:30<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 7: train_loss=1.76378, valid_loss=2.12538\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.874, lr=0.00033: 100%|██████████| 1954/1954 [14:30<00:00,  2.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 8: train_loss=1.64139, valid_loss=2.09337\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.675, lr=0.00032: 100%|██████████| 1954/1954 [14:29<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 9: train_loss=1.53845, valid_loss=2.06323\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.487, lr=0.00030: 100%|██████████| 1954/1954 [14:28<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 10: train_loss=1.44684, valid_loss=2.09922\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.449, lr=0.00029: 100%|██████████| 1954/1954 [14:27<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 11: train_loss=1.36696, valid_loss=2.11025\n","train set examples:\n","src:  因此,20世纪90年代初英镑和里拉贬值后,法国和德国受到了消极的贸易冲击,人们从中汲取的教训是需要单一货币来防止这类不同冲击再次发生。\n","trg:  Thus, in the aftermath of the sterling and lira devaluations of the early 1990’s, with their resulting adverse trade shocks to France and Germany, the lesson that was drawn was that a single currency was needed to prevent such disparate shocks from recurring\n","pred: So, since the fall of the pound and the lira in the early 1990’s, France and Germany were hit by negative trade shocks, and the lesson that the single currency needed to prevent such disparate shocks is to prevent such a scenario.\n","src:  此外,由于相近物种间的杂交是普遍现象,有可能对一种蚊子的修改会逐步地、不可控地扩大到其他物种。\n","trg:  Moreover, given the ubiquity of hybridization among neighboring species, it is possible that the modification of a mosquito species would also spread progressively and uncontrollably to other species.\n","pred: Moreover, because the hybridization among neighboring species is common, it threatens to extend, without control, to a mosquito species.\n","src:  可以肯定,法庭命令在美国媒体上发布“修正声明”的确代表了真相的胜利。\n","trg:  To be sure, the court-ordered airing of “corrective statements” in American media does represent a victory for truth.\n","pred: To be sure, court orders to publish “de-Reported statements” in American media do represent a victory for truth.\n","validation set examples:\n","src:  这需要时间,但是可以找到的最佳选择。\n","trg:  That takes time, but it might be the best option left.\n","pred: This will take time, but the best options can be found.\n","src:  由于当下的投资(特别是能源系统方面的投资)将决定未来几十年内的发展道路,因此必须做更多的工作以确保现在和未来的投资不会破坏我们应对气候变化的努力。\n","trg:  Because today’s investments, particularly in energy systems, will lock in development paths for decades to come, more must be done to ensure that investments now, and in the future, do not undermine our efforts to address climate change.\n","pred: Because current investment, especially in the energy system, will determine the course of development in the coming decades, must do more to ensure that current and future investments will not undermine our efforts to address climate change.\n","src:  美国的俄罗斯专家比二十年前减少了很多,因为大部分美国对外决策者更多关注的是中国、印度和中东。\n","trg:  The US has far fewer Russia experts in politics today than it did two decades ago, because most American foreign policymakers have been paying far more attention to China, India, and the Middle East.\n","pred: American pundits have been much lower than they were two decades ago, because much of America’s foreign policymakers have more to do with China, India, and the Middle East.\n","test set examples:\n","src:  其结果是,天空通常在人们心目中通常只是一种交通的概念。\n","trg:  As a result, the sky is usually conceptualized in terms of traffic.\n","pred: As a result, the sky is typically a mere concept of transportation in people’s minds.\n","src:  世界在一个世纪内不断增加排放量,并在此过程中实现了成百上千亿人的脱贫。\n","trg:  The world has increased emissions constantly over a century, lifting billions out of poverty in the process.\n","pred: The world has been growing steadily over the century, and has lifted hundreds of millions of people out of poverty in the process.\n","src:  当然,以同死亡行刑队作战的名义袭击阿萨德的救世主军有可能将美国的军事力量拖入城市巷战之中,其规模是自2004年和2005年法鲁贾战役以来最大的。\n","trg:  Of course, attacking Moqtada al-Sadr’s Mahdi Army in the name of fighting militia death squads has the potential to draw American military forces into a level of urban warfare unseen since the Falluja assaults of 2004 and 2005.\n","pred: Of course, the Mahdi army, whose war against Assad in the name of the same death squadron, threatens to push American military forces into open warfare in cities, the largest since the 2004 and 2005 French-Barja battle.\n","train_loss: 1.3670, valid_loss: 2.1102, test_loss: 2.0908\n","test_bleu: 22.0446, valid_bleu: 22.2254 train_bleu: 34.0714\n","model_size: 90301744, train_set_size: 300000\n"]},{"output_type":"stream","name":"stderr","text":["train loss=5.104, lr=0.00011: 100%|██████████| 2344/2344 [17:19<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 0: train_loss=6.43990, valid_loss=5.02557\n"]},{"output_type":"stream","name":"stderr","text":["train loss=3.593, lr=0.00023: 100%|██████████| 2344/2344 [17:21<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 1: train_loss=4.29827, valid_loss=3.51074\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.828, lr=0.00034: 100%|██████████| 2344/2344 [17:21<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 2: train_loss=3.11869, valid_loss=2.74352\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.586, lr=0.00045: 100%|██████████| 2344/2344 [17:21<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 3: train_loss=2.58255, valid_loss=2.43550\n"]},{"output_type":"stream","name":"stderr","text":["train loss=2.140, lr=0.00041: 100%|██████████| 2344/2344 [17:20<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 4: train_loss=2.27976, valid_loss=2.22763\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.994, lr=0.00037: 100%|██████████| 2344/2344 [17:20<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 5: train_loss=2.03613, valid_loss=2.10520\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.876, lr=0.00035: 100%|██████████| 2344/2344 [17:18<00:00,  2.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 6: train_loss=1.86511, valid_loss=2.07317\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.736, lr=0.00032: 100%|██████████| 2344/2344 [17:21<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 7: train_loss=1.73330, valid_loss=2.00812\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.682, lr=0.00030: 100%|██████████| 2344/2344 [17:21<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 8: train_loss=1.62570, valid_loss=1.98915\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.588, lr=0.00029: 100%|██████████| 2344/2344 [17:19<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 9: train_loss=1.53431, valid_loss=2.00509\n"]},{"output_type":"stream","name":"stderr","text":["train loss=1.535, lr=0.00028: 100%|██████████| 2344/2344 [17:21<00:00,  2.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["ep: 10: train_loss=1.45357, valid_loss=1.99438\n","train set examples:\n","src:  与此同时,各国民众将对方视作不值得信赖的敌人的做法必须停止。\n","trg:  At the same time, people worldwide must stop regarding one another as untrustworthy enemies.\n","pred: At the same time, it must stop national citizens from viewing the other as a trusted enemy.\n","src:  所有这些,用梅不会用的话说,感觉就好像是一场非常不友好的离婚。\n","trg:  All of this, to return to the word May won’t use, feels like a rather unamicable divorce.\n","pred: All of this, in May’s words, feels like a very bad divorce.\n","src:  中国问题足以让世界经济和股市在这个十年的剩余几年中一蹶不振。\n","trg:  China is surely a big enough problem to throw the world economy and equity markets off the rails for the rest of this decade.\n","pred: China’s problems are enough to perpetuate the world economy and equity markets in the rest of the decade.\n","validation set examples:\n","src:  但我们必须采取措施避免发生最坏情况,而不是沉迷于宿命论。\n","trg:  But, rather than wallow in fatalism, we must take steps to avert the worst.\n","pred: But we must take steps to avoid the worst, not relying on fatalism.\n","src:  她的选举前夜演讲充斥着对团结和对话的呼吁,应承诺“采取紧急措施”重塑增长。\n","trg:  Her election-night speech was full of calls for unity and dialogue, and included a pledge to “take urgent action” to resume growth.\n","pred: Her campaign speech was mired in a call for solidarity and dialogue, and she pledged “to take urgent measures” to restore growth.\n","src:  然而,尽管奥巴马可能是在通过追求无条件正常化 — — 所谓的“立约 ” ( engagement ) — —留下他自己的光辉遗产,但他并没有保证古巴发生任何实际变化。\n","trg:  But while Obama may be burnishing his legacy by pursuing unconditional normalization – so-called “engagement” – what he is not doing is securing any actual change in Cuba.\n","pred: But, while Obama may be pursuing unconditional normalization – the so-called “Jordu” – to remain his own reputation, he has not guaranteed any real change in Cuba.\n","test set examples:\n","src:  仅仅是预期会发生这一结果,便令石油价格节节攀升 — — 而这也是特朗普给普京的礼物。\n","trg:  The mere expectation of that outcome has already driven up oil prices – another gift from Trump to Putin.\n","pred: The result is simply expected, which has fueled a rise in oil prices – and Trump’s gift to Putin.\n","src:  辩论必须继续,即使从表面看来法国和荷兰的公投已经扼杀了宪法条约。\n","trg:  That debate must continue, even if the French and Dutch referenda appear to have killed the Constitutional Treaty.\n","pred: The debate must continue, even as the French and Dutch referendums ostensibly have stifled the Constitutional Treaty.\n","src:  于是在世界汇率体系中出现了一种新的秩序。\n","trg:  A new type of order emerged in the world’s exchange rate system.\n","pred: So a new order has emerged in the world’s exchange-rate system.\n","train_loss: 1.4536, valid_loss: 1.9944, test_loss: 2.0015\n","test_bleu: 23.1614, valid_bleu: 23.0209 train_bleu: 32.2559\n"]}],"source":["config = ModelConfig(encoder_vocab_size = vocab_sizes[SRC],\n","                     decoder_vocab_size=vocab_sizes[TRG],\n","                     d_embed=512,\n","                     d_ff=2048,\n","                     h=8,\n","                     N_encoder=6,\n","                     N_decoder=6,\n","                     max_seq_len=max_seq_len,\n","                     dropout=0.1\n","                     )\n","results = {}\n","for train_size in  np.array([5, 10, 15, 20, 25, 30])*10000:\n","    tokenizers, detokenizers, id_to_pieces = get_tokenizers(full_train_set, train_size)\n","    data_loaders = Dataloaders(train_size)\n","    model = make_model(config)\n","    model_size = sum([p.numel() for p in model.parameters()])\n","    print(f'model_size: {model_size}, train_set_size: {train_size}')\n","    warmup_steps = 4*len(data_loaders.train_loader)\n","    # lr first increases in the warmup steps, and then descreases\n","    lr_fn = lambda step: config.d_embed**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1, betas=(0.9, 0.98), eps=1e-9)\n","    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n","    loss_fn = nn.CrossEntropyLoss(ignore_index=PAD)\n","    early_stop_count = 2\n","    train_loss, valid_loss = train(model, data_loaders, epochs=30)\n","    test_loss  = validate(model, data_loaders.test_loader)\n","\n","    print(\"train set examples:\")\n","    train_bleu = evaluate(model, data_loaders.train_loader, 20)\n","    print(\"validation set examples:\")\n","    valid_bleu = evaluate(model, data_loaders.valid_loader)\n","    print(\"test set examples:\")\n","    test_bleu  = evaluate(model, data_loaders.test_loader)\n","    results[f'model_size={model_size}, train_size={train_size}'] = {\n","                                        'train_loss': train_loss,\n","                                        'valid_loss': valid_loss,\n","                                        'test_loss' : test_loss,\n","                                        'train_bleu': train_bleu,\n","                                        'valid_bleu': valid_bleu,\n","                                        'test_bleu': test_bleu}\n","    f = open('results_news-commentary-v16_only.json', 'w')\n","    json.dump(results, f)\n","    f.close()\n","    torch.save(model, f'saved_models_news-commentary-v16_only/{SRC}_to_{TRG}_dataset_size_{train_size}_model_size_{model_size}.pt')\n","    print(f'train_loss: {train_loss:.4f}, valid_loss: {valid_loss:.4f}, test_loss: {test_loss:.4f}')\n","    print(f'test_bleu: {test_bleu:.4f}, valid_bleu: {valid_bleu:.4f} train_bleu: {train_bleu:.4f}')"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"T51zR33b5ToF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651058264683,"user_tz":240,"elapsed":43158362,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"de64af50-b925-4b20-a4dc-e9d88b620d6b"}},{"cell_type":"code","source":["summary(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tC2YSNVlyJic","executionInfo":{"status":"ok","timestamp":1651060215834,"user_tz":240,"elapsed":604,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"2c5d6981-1332-4e44-f69c-37560f453997"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["================================================================================\n","Layer (type:depth-idx)                                  Param #\n","================================================================================\n","Transformer                                             --\n","├─Encoder: 1-1                                          --\n","│    └─Embedding: 2-1                                   15,360,000\n","│    └─ModuleList: 2-2                                  --\n","│    │    └─EncoderBlock: 3-1                           3,152,384\n","│    │    └─EncoderBlock: 3-2                           3,152,384\n","│    │    └─EncoderBlock: 3-3                           3,152,384\n","│    │    └─EncoderBlock: 3-4                           3,152,384\n","│    │    └─EncoderBlock: 3-5                           3,152,384\n","│    │    └─EncoderBlock: 3-6                           3,152,384\n","│    └─Dropout: 2-3                                     --\n","│    └─LayerNorm: 2-4                                   1,024\n","├─Decoder: 1-2                                          --\n","│    └─Embedding: 2-5                                   15,360,000\n","│    └─Dropout: 2-6                                     --\n","│    └─ModuleList: 2-7                                  --\n","│    │    └─DecoderBlock: 3-7                           4,204,032\n","│    │    └─DecoderBlock: 3-8                           4,204,032\n","│    │    └─DecoderBlock: 3-9                           4,204,032\n","│    │    └─DecoderBlock: 3-10                          4,204,032\n","│    │    └─DecoderBlock: 3-11                          4,204,032\n","│    │    └─DecoderBlock: 3-12                          4,204,032\n","│    └─LayerNorm: 2-8                                   1,024\n","│    └─Linear: 2-9                                      15,390,000\n","================================================================================\n","Total params: 90,250,544\n","Trainable params: 90,250,544\n","Non-trainable params: 0\n","================================================================================"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["# Scaling and extrapolation"],"metadata":{"id":"JkukiSGAffK1"}},{"cell_type":"code","source":["from scipy.optimize import curve_fit"],"metadata":{"id":"-TMoLoXlp1fi","executionInfo":{"status":"ok","timestamp":1651060221745,"user_tz":240,"elapsed":547,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["{'model_size=90301744, train_size=50000': {'train_loss': 1.8421159223522372, 'valid_loss': 3.837266540527344, 'test_loss': 3.8280940890312194, 'train_bleu': 19.023623151437462, 'valid_bleu': 8.510183855099791, 'test_bleu': 8.508660093282119}, 'model_size=90301744, train_size=100000': {'train_loss': 1.5600060982167567, 'valid_loss': 2.7434798538684846, 'test_loss': 2.7614079296588896, 'train_bleu': 29.17207959108856, 'valid_bleu': 15.757918281499656, 'test_bleu': 15.93365605634247}, 'model_size=90301744, train_size=150000': {'train_loss': 1.5530199392256883, 'valid_loss': 2.373695957660675, 'test_loss': 2.363886374235153, 'train_bleu': 29.861842815546225, 'valid_bleu': 18.937841110164882, 'test_bleu': 19.11025427731958}, 'model_size=90301744, train_size=200000': {'train_loss': 1.334876204558999, 'valid_loss': 2.2283440828323364, 'test_loss': 2.235159456729889, 'train_bleu': 35.1289746663993, 'valid_bleu': 20.77695943977966, 'test_bleu': 20.8972762873247}, 'model_size=90301744, train_size=250000': {'train_loss': 1.3669633949547244, 'valid_loss': 2.110249787569046, 'test_loss': 2.0907986164093018, 'train_bleu': 34.071402883424746, 'valid_bleu': 22.225430647948535, 'test_bleu': 22.044592684533214}, 'model_size=90301744, train_size=300000': {'train_loss': 1.453574165651009, 'valid_loss': 1.9943774133920669, 'test_loss': 2.001501640677452, 'train_bleu': 32.25588738165268, 'valid_bleu': 23.02092104769359, 'test_bleu': 23.16141453449445}}\n"]}],"source":["f = open('results_news-commentary-v16_only.json', 'r')\n","res = json.load(f)\n","print(res)"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"EbGP6GgHkHcS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651060226172,"user_tz":240,"elapsed":297,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"46bb3ee9-be91-4b4d-af52-0c3a470bc289"}},{"cell_type":"code","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["model_size=90301744, train_size=50000:\n","{'train_loss': 1.8421159223522372, 'valid_loss': 3.837266540527344, 'test_loss': 3.8280940890312194, 'train_bleu': 19.023623151437462, 'valid_bleu': 8.510183855099791, 'test_bleu': 8.508660093282119}\n","model_size=90301744, train_size=100000:\n","{'train_loss': 1.5600060982167567, 'valid_loss': 2.7434798538684846, 'test_loss': 2.7614079296588896, 'train_bleu': 29.17207959108856, 'valid_bleu': 15.757918281499656, 'test_bleu': 15.93365605634247}\n","model_size=90301744, train_size=150000:\n","{'train_loss': 1.5530199392256883, 'valid_loss': 2.373695957660675, 'test_loss': 2.363886374235153, 'train_bleu': 29.861842815546225, 'valid_bleu': 18.937841110164882, 'test_bleu': 19.11025427731958}\n","model_size=90301744, train_size=200000:\n","{'train_loss': 1.334876204558999, 'valid_loss': 2.2283440828323364, 'test_loss': 2.235159456729889, 'train_bleu': 35.1289746663993, 'valid_bleu': 20.77695943977966, 'test_bleu': 20.8972762873247}\n","model_size=90301744, train_size=250000:\n","{'train_loss': 1.3669633949547244, 'valid_loss': 2.110249787569046, 'test_loss': 2.0907986164093018, 'train_bleu': 34.071402883424746, 'valid_bleu': 22.225430647948535, 'test_bleu': 22.044592684533214}\n","model_size=90301744, train_size=300000:\n","{'train_loss': 1.453574165651009, 'valid_loss': 1.9943774133920669, 'test_loss': 2.001501640677452, 'train_bleu': 32.25588738165268, 'valid_bleu': 23.02092104769359, 'test_bleu': 23.16141453449445}\n"]}],"source":["sizes = []\n","test_losses = []\n","test_bleus = []\n","\n","for size in np.array([5, 10, 15, 20, 25, 30])*10000:\n","    result = res['model_size=90301744, train_size='+str(size)]\n","    print(f'model_size=90301744, train_size={str(size)}:')\n","    print(result)\n","    sizes.append(size)\n","    test_losses.append(result['test_loss'])\n","    test_bleus.append(result['test_bleu'])\n"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"DrF8zFfqkHcT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651060228703,"user_tz":240,"elapsed":211,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"691d1cb7-3522-481a-bf0e-8fcdee69bbdb"}},{"cell_type":"code","source":["num_tokens = []\n","for num_sentences in np.array([5, 10, 15, 20, 25, 30])*10000:\n","    num_tokens.append(sum([len(x[0]) for x in tokenize_dataset(list(full_train_set)[0:num_sentences])]))\n","sizes = num_tokens"],"metadata":{"id":"p499hTi3mfGl","executionInfo":{"status":"ok","timestamp":1651060329876,"user_tz":240,"elapsed":98200,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.24270145  4.52026597]\n","[-2.73705745e+07  2.69088414e+01]\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1440x360 with 2 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["def linear_fn(x, a, b):\n","    return a*x + b\n","\n","fig, ax = plt.subplots(1, 2, figsize=(20,5))\n","\n","logsize = np.log(sizes)\n","logloss = np.log(test_losses)\n","fit_params, _ = curve_fit(linear_fn, logsize[2:], logloss[2:])\n","print(fit_params)\n","\n","loss_fitted_data = linear_fn(logsize, fit_params[0], fit_params[1])\n","ax[0].scatter(logsize, logloss, label='data')\n","ax[0].plot(logsize, loss_fitted_data, label='fit')\n","ax[0].set_xlabel('log of training set size')\n","ax[0].set_ylabel('log of test loss')\n","ax[0].legend()\n","\n","oneoversizes = np.reciprocal(np.array(sizes, dtype=float))\n","fit_params, _ =curve_fit(linear_fn, oneoversizes[2:], test_bleus[2:])\n","print(fit_params)\n","bleu_fitted_data = linear_fn(np.insert(oneoversizes, 0, 0, 0), fit_params[0], fit_params[1])\n","\n","ax[1].plot(np.insert(oneoversizes, 0, 0, 0), bleu_fitted_data, label='fit')\n","ax[1].scatter(np.reciprocal(np.array(sizes, dtype=float)), test_bleus,  label='data')\n","ax[1].set_xlabel('1/training set size')\n","ax[1].set_ylabel('test bleu score')\n","ax[1].legend()\n","plt.show()"],"metadata":{"pycharm":{"name":"#%%\n"},"id":"lA4fllkwkHcT","colab":{"base_uri":"https://localhost:8080/","height":366},"executionInfo":{"status":"ok","timestamp":1651060582243,"user_tz":240,"elapsed":768,"user":{"displayName":"Hongbin Chen","userId":"14161707569992931612"}},"outputId":"3f00a59c-e524-4584-b403-9b13ed3a6175"}},{"cell_type":"markdown","source":["Training set size in the above plots are defined as the number of tokens in the English sentences in the training set. The fits above are from the last four data points. From the first plot above, the test loss and the training set size kind of follow a power law. And from the second plot, the BLEU score seems to improve as a linear function of 1/train_set_size, and approaches 26.9 as the training set size goes to infinity. But of course, I only have six data points from the range of 50k training examples to 300k training examples, it is hard to say what would happen if I use a much larger training set, and the fits above are not perfect. "],"metadata":{"id":"CL6ItuZ9amz3"}}]}